{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVVv7krSRegn",
        "outputId": "832e95da-ea0b-4cd4-df03-32443bbb105b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1uLiPtiP_eWo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, DataCollatorForSeq2Seq\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X8VYRP8p_eWq"
      },
      "outputs": [],
      "source": [
        "NEWS_DATA_PATH = 'drive/My Drive/Colab Notebooks/期末/BBC News Summary/News Articles'\n",
        "SUMMARIES_DATA_PATH = 'drive/My Drive/Colab Notebooks/期末/BBC News Summary/Summaries'\n",
        "\n",
        "# 設定模型儲存路徑\n",
        "MODEL_SAVE_PTH = 'drive/My Drive/Colab Notebooks/期末/5.五個分類_2個epoch_滑動平均損失和動態調整權重'\n",
        "\n",
        "# 設定設備為 GPU (如果可用的話) 或 CPU\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 設定輸入和目標(摘要)的最大長度\n",
        "MAX_INPUT_LENGTH = 512\n",
        "MAX_TARGET_LENGTH = 128\n",
        "\n",
        "# 設定批次大小\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# 定義情緒標籤\n",
        "SENTIMENT_LABELS = [\"happy\", \"sad\", \"warn\", \"angry\", \"sorrow\", \"alert\", \"neutral\"]\n",
        "\n",
        "# 建立情緒標籤到索引的對應字典\n",
        "SENTIMENT_LABELS_MAP = {label: index for index, label in enumerate(SENTIMENT_LABELS)}\n",
        "\n",
        "\n",
        "\n",
        "# 加入權重\n",
        "summary_loss_weight = 0.5\n",
        "sentiment_loss_weight = 0.5\n",
        "prev_summary_loss = None\n",
        "prev_sentiment_loss = None\n",
        "avg_summary_loss = 0\n",
        "avg_sentiment_loss = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**從root_path 加載數據**\n",
        "\n",
        "根路徑下的每個子目錄(代表一個類別)，子目錄中的每個文件包含新聞內容。\n",
        "\n",
        "返回一個包含所有新聞內容的 numpy 字符串數組。"
      ],
      "metadata": {
        "id": "i1Y_KhBvHPDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "News Articles：包含不同類別的新聞文章，每個類別是一個子資料夾，內有多個文件。\n",
        "\n",
        "Summaries：包含每篇新聞文章的五個摘要。"
      ],
      "metadata": {
        "id": "K19OZaFCfDaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pbar = tqdm(os.listdir(news_dir_path))：\n",
        "\n",
        "這行程式碼將 news_dir_path 目錄中的所有文件名稱傳遞給 tqdm，以初始化進度條 pbar。在迴圈中使用 pbar 可以在迴圈每次迭代時更新進度條。"
      ],
      "metadata": {
        "id": "FrkfF3HPgHo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   os.listdir(root_path) 返回根目錄下的所有子目錄名稱，假設每個子目錄代表一個類別。\n",
        "*   os.path.join(root_path, cls) 獲取每個子目錄的完整路徑。\n"
      ],
      "metadata": {
        "id": "imcPa0CGhja1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sfhyinWi_eWr"
      },
      "outputs": [],
      "source": [
        "# 定義資料載入函數\n",
        "def load_data(root_path):\n",
        "    print('Loading: {}'.format(root_path))  # 打印正在載入的路徑\n",
        "\n",
        "    data = []  # 初始化數據列表，用來存儲加載的數據\n",
        "    classes = sorted(os.listdir(root_path))  # 確保類別按順序排序\n",
        "    # 遍歷根目錄下的每個子目錄，假設每個子目錄代表一個類別。\n",
        "    # for cls in os.listdir(root_path):\n",
        "    for cls in classes:  # 確保類別的順序一致\n",
        "        news_dir_path = os.path.join(root_path, cls)  # 獲取類別資料夾的路徑\n",
        "\n",
        "        files = sorted(os.listdir(news_dir_path))  # 確保文件按順序排序\n",
        "\n",
        "        pbar = tqdm(files)   # 初始化進度條，用來顯示加載每個子目錄中文件的進度。\n",
        "\n",
        "        # 遍歷類別資料夾中的文件\n",
        "        for news_file_name in pbar:\n",
        "            news_file_path = os.path.join(news_dir_path, news_file_name)  # 獲取新聞文件的路徑\n",
        "\n",
        "            # 打開新聞文件並讀取內容\n",
        "            with open(news_file_path, 'r', encoding='unicode_escape') as file:\n",
        "                lines = file.read().strip()\n",
        "                if lines:\n",
        "                    data.append(lines.replace('\\n', ' '))  # 將內容中的換行符替換為空格，並添加到數據列表中。\n",
        "                else:\n",
        "                    print(f\"Empty file found: {news_file_path}\")\n",
        "\n",
        "            # 更新進度條的後綴資訊\n",
        "            if news_file_name == pbar.iterable[-1]: # 如果當前文件是目錄中的最後一個文件，更新進度條的後綴信息。\n",
        "                pbar.set_postfix_str('{} class loaded'.format(cls)) # 設置進度條的後綴信息，顯示當前類別已加載完成。\n",
        "\n",
        "    return np.array(data, dtype=str)  # 返回數據陣列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aj3s3RgU_eWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1c7bca-4827-4b41-b9ed-e6bedc7decba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: drive/My Drive/Colab Notebooks/期末/BBC News Summary/News Articles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 510/510 [00:36<00:00, 14.02it/s, business class loaded]\n",
            "100%|██████████| 386/386 [00:04<00:00, 91.77it/s, entertainment class loaded] \n",
            "100%|██████████| 417/417 [00:23<00:00, 17.43it/s, politics class loaded]\n",
            "100%|██████████| 511/511 [00:46<00:00, 10.96it/s, sport class loaded]\n",
            "100%|██████████| 401/401 [00:34<00:00, 11.61it/s, tech class loaded]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: drive/My Drive/Colab Notebooks/期末/BBC News Summary/Summaries\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 510/510 [00:55<00:00,  9.13it/s, business class loaded]\n",
            "100%|██████████| 386/386 [00:34<00:00, 11.33it/s, entertainment class loaded]\n",
            "100%|██████████| 417/417 [00:52<00:00,  7.98it/s, politics class loaded]\n",
            "100%|██████████| 511/511 [00:16<00:00, 30.19it/s, sport class loaded]\n",
            "100%|██████████| 401/401 [00:18<00:00, 21.33it/s, tech class loaded]\n"
          ]
        }
      ],
      "source": [
        "# 載入新聞語料\n",
        "news_corpus = load_data(NEWS_DATA_PATH)\n",
        "\n",
        "# 載入摘要語料\n",
        "summaries_corpus = load_data(SUMMARIES_DATA_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EZV1-GX7_eWr"
      },
      "outputs": [],
      "source": [
        "# 分割資料集為訓練集和測試集\n",
        "# 5% 的資料用作測試集，剩下的 95% 用作訓練集\n",
        "X_train, X_test, y_train, y_test = train_test_split(news_corpus, summaries_corpus, test_size=0.05, random_state=42)\n",
        "\n",
        "# 將訓練集進一步分割為訓練集和驗證集\n",
        "# 之前的訓練集再一次分割成新的訓練集和驗證集。\n",
        "# test_size=0.05 表示將 5% 的訓練集數據用作驗證集，剩下的 95% 繼續用作訓練集。\n",
        "X_train, X_vaild, y_train, y_vaild = train_test_split(X_train, y_train, test_size=0.05, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CEAxHmVI_eWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f3cfb8f-87c6-4277-c53e-f777c8e0ea2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 106, 2007)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 計算測試集、驗證集和訓練集的長度\n",
        "len(X_test), len(X_vaild), len(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**自定義 PyTorch 的 Dataset 類，用於處理新聞和摘要數據。**\n",
        "\n",
        "初始化數據集，包括輸入數據（新聞）和目標數據（摘要）。\n",
        "定義數據集的大小和索引操作。\n",
        "\n",
        "返回值：\n",
        "\n",
        "    __len__ 返回數據集的大小。\n",
        "\n",
        "    __getitem__ 根據索引返回對應的數據對（新聞和摘要）。"
      ],
      "metadata": {
        "id": "6Vge55AbHI6T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ijAUVEvL_eWs"
      },
      "outputs": [],
      "source": [
        "# 定義資料集類別\n",
        "class CorpusDataset(Dataset):\n",
        "    def __init__(self, X_corpus, y_corpus):\n",
        "        self.X_corpus = X_corpus  # 輸入數據\n",
        "        self.y_corpus = y_corpus  # 目標數據\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_corpus)  # 返回數據集的大小\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_corpus[index], self.y_corpus[index]  # 根據索引返回對應的數據對\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H8iPw-G__eWs"
      },
      "outputs": [],
      "source": [
        "# 創建訓練、驗證和測試資料集\n",
        "train_model_inputs = CorpusDataset(X_train, y_train)\n",
        "vaild_model_inputs = CorpusDataset(X_vaild, y_vaild)\n",
        "test_model_inputs = CorpusDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 程式碼初始化已定義 BATCH_SIZE = 8\n",
        "\n",
        "\n",
        "2. drop_last=True\n",
        "\n",
        "*   如果最後一個批次數據不夠，則丟棄\n",
        "*   如果最後一個批次數據不夠，則丟棄\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xskkcpebljdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pinned memory（固定內存）\n",
        "\n",
        " page-locked memory。內存的數據不會被交換到磁盤上（即不會被置換出內存），因此 GPU 可以更快地訪問和複製這些數據。\n",
        "\n",
        "*   GPU 進行深度學習訓練，需要將數據從 CPU 內存複製到 GPU 內存\n",
        "*   CPU 固定內存（pinned memory）確保資料不會被置換出內存\n",
        "*   更高效的 DMA（Direct Memory Access，直接內存訪問）操作\n",
        "*   載入資料DataLoader 會將數據預先加載到 CPU 的固定內存區域，可以更快地傳輸到 GPU 內存中進行計算\n",
        "\n",
        "**什麼情況下使用** `pin_memory=True` 有幫助\n",
        "\n",
        "1. **頻繁數據傳輸**：需要頻繁地將大批量數據從 CPU 傳輸到 GPU，例如在每個訓練批次中，使用 `pin_memory=True` 可以顯著提高數據傳輸速度。\n",
        "   \n",
        "2. **大數據量**：當處理的數據量非常大時，固定內存可以減少數據傳輸過程中的瓶頸。\n",
        "\n",
        "3. **使用GPU**：當使用 GPU 進行訓練時，`pin_memory=True` 尤其有幫助，可以加速數據從 CPU 到 GPU 的傳輸。\n",
        "\n",
        "使用 `pin_memory=True` 時，確實可以提高數據從 CPU 傳輸到 GPU 的速度，但這並不意味著在所有情況下都能顯著提升性能。\n",
        "\n",
        "1. **內存消耗**：使用 `pin_memory=True` 會佔用更多的 CPU 內存，如果你的系統內存有限，這可能會導致內存不足的情況。\n",
        "\n",
        "2. **小批次數據**：如果你的批次大小很小，或者數據傳輸的頻率不高，使用 `pin_memory=True` 可能不會帶來顯著的性能提升。\n",
        "\n",
        "3. **數據加載瓶頸**：`pin_memory=True` 主要優化的是數據從 CPU 到 GPU 的傳輸速度。如果你的數據加載過程（例如從磁盤讀取數據）是主要瓶頸，這個選項不會對這部分的性能產生影響。\n",
        "\n",
        "**內存資源允許的情況下，這是一個很好的選擇，可以減少數據傳輸的延遲，提升整體訓練效率。**\n",
        "\n",
        "**然而，對於小批次數據或內存有限的環境，提升效果可能不明顯。**\n"
      ],
      "metadata": {
        "id": "R2L65n4Lr2zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 創建訓練資料加載器\n",
        "train_dataloader = DataLoader(\n",
        "    train_model_inputs,\n",
        "    # 避免局部最小\n",
        "    shuffle=True,  # 訓練時打亂數據\n",
        "    batch_size=BATCH_SIZE,  # 每個批次的大小\n",
        "    drop_last=True,  # 如果最後一個批次數據不夠，則丟棄\n",
        "    pin_memory=True  # 將數據複製到 CUDA 固定內存\n",
        ")\n",
        "\n",
        "# 創建驗證資料加載器\n",
        "eval_dataloader = DataLoader(\n",
        "    vaild_model_inputs,\n",
        "    shuffle=False,  # 驗證時不打亂數據\n",
        "    batch_size=BATCH_SIZE,  # 每個批次的大小\n",
        "    drop_last=True,  # 如果最後一個批次數據不夠，則丟棄\n",
        "    pin_memory=True  # 將數據複製到 CUDA 固定內存\n",
        ")\n",
        "\n",
        "# 創建測試資料加載器\n",
        "test_dataloader = DataLoader(\n",
        "    test_model_inputs,\n",
        "    shuffle=False,  # 測試時不打亂數據\n",
        "    batch_size=1,  # 每個批次的大小為1\n",
        "    drop_last=True,  # 如果最後一個批次數據不夠，則丟棄\n",
        "    pin_memory=True  # 將數據複製到 CUDA 固定內存\n",
        ")"
      ],
      "metadata": {
        "id": "8CG3hhswp3Mp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "初始化:設定設備為 GPU (如果可用的話) 或 CPU\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "*   torch.cuda.is_available() 檢查當前系統是否有可用的 GPU。\n",
        "*   有可用的 GPU（torch.cuda.is_available() 返回 True），則 DEVICE 被設置為 torch.device(\"cuda\")，這表示後續的運算將在 GPU 上進行。\n",
        "*   沒有可用的 GPU，則 DEVICE 被設置為 torch.device(\"cpu\")，這表示後續的運算將在 CPU 上進行。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CfbHturdrd0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**pipeline 支持多種 NLP 任務，自動處理文本標記化和模型推理。**\n",
        "\n",
        "使用方法：pipeline(\"任務名稱\")\n",
        "\n",
        "**零樣本分類（zero-shot classification） 可以在沒有專門針對目標類別進行訓練的情況下進行分類。**\n",
        "\n",
        "*   透過自然語言推理（Natural Language Inference, NLI）判斷輸入文本與候選標籤之間的關係，語義理解來進行分類\n",
        "\n",
        "\n",
        "**已經定義好的情緒分析模型（如 TextBlob 或 VADER），不需要使用零樣本分類**\n"
      ],
      "metadata": {
        "id": "TPlrrmcNjmUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 加載 BART 摘要生成模型的標記器\n",
        "# 'facebook/bart-large-cnn' 模型\n",
        "summary_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn', device=DEVICE)\n",
        "\n",
        "# 加載並初始化 BART 摘要生成模型\n",
        "# 生成條件摘要\n",
        "summary_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(DEVICE)\n",
        "\n",
        "# 加載並初始化 BART 的情感分類模型\n",
        "sentiment_model = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=DEVICE)"
      ],
      "metadata": {
        "id": "Z0HBLXfirBmp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525,
          "referenced_widgets": [
            "bed5908306af40509e39ec366c87c2fc",
            "6d7ce3a46b3f423689d75ecd844f2530",
            "0ff98051fabc4003a11c2b412d1de122",
            "5108e6c975214e40b8ad74d14f9d2ceb",
            "a3cad6b75863496ab3f6ade4b46ac1aa",
            "fa92a5d9f258469b8c6c34a745a3b659",
            "a896372101a64135aa01d5d9f1f8ba83",
            "10614a7b6431466faad49b702530d335",
            "20e2c97a023748dd92d89acdef09e66e",
            "fbf5cc97fd174e34988340681f81ea3b",
            "749b69f9049e401a8949045a91811074",
            "09f363234e524cb0af8df25fa4c5d72d",
            "bd39327be2f04ae4b8d582b5ebb2e79e",
            "34bd2274169f46dfa91c746171e7ad57",
            "5eb59dc464b744818f79951df6e077d3",
            "a49002afbb66496fbef9ea24f2a9fdad",
            "8d98e4e8ffe044fbb61a4a55dc10aaa1",
            "d08d96a69d3f4221aec2daeb3e2a1ae8",
            "9f09972e4c5b4194bcef2128bd786698",
            "0479125e43604229b88476337c01c5c4",
            "abdc5d6d3c8b4ce99a9135f0cb957d0d",
            "289b97abadba46b19fb6edd34f72e4a0",
            "80d5ee30893142f38ad7b4c6e7ae9775",
            "612a6dc7fbf84165b6d22048ee686f8e",
            "3e56d5a481554d5aa17b426c49970799",
            "9c8ecc5fd7a14952b29ff186d49818fb",
            "ee5ff25d870e4cc3a69ca1b8de5a59c3",
            "231fb27d26a840eca0cbb0d1e662ff2b",
            "9f3297aab7534b6188244f52538f0527",
            "b8e463d2dd024dadb2b180e1500a1290",
            "d925aa33f7b6424cb9f02c5956a7a2e6",
            "120e4eae01934212adacb53e38cf953d",
            "1158a7d60ed340daa2b11186f5c8bc5d",
            "4c8648d3f41b4a178a6480161eecffac",
            "001b97f5adda4f7c837705ef128155b0",
            "004a24186f2544bc944f9a4d6d86f273",
            "13a2c0c13ecf42e9b30f7f501f3f2571",
            "0491884ec12b4961b87c1a59cea58ccb",
            "b61342a33c68409baba11777182d8e34",
            "6800c12bd4344823ac693c1c51e1e3af",
            "ce3d62fa44ef4fa089cd0058fc13c9af",
            "dad7d22251e24a42a3d80ce58ae45f43",
            "9cecc6897e344f5e9d6db6050bf21024",
            "1baf39dc539c4952a90912a4ab15a3e9",
            "035ae60252374d7085150739d4737874",
            "b53ec3b79a75496aa0c3ae4ea655f8aa",
            "32d4570dc5bd47dcbb41cbcff1bd8d7a",
            "a3a037c5250a440680b45c79536b2986",
            "42ac301f03bf404088957a7553097a48",
            "5124625edb944eb5a8a0f65243ad7144",
            "6ef4b8d6783d4a9ababc8448aafa86e7",
            "f88c823765044c588d2887ae442712d7",
            "71149297964e45239c65f61196c160ad",
            "31da0d3ed9ae4b74a2525c8e7937a924",
            "cd4954b587494f8080c868d949955a15",
            "3d554bd4c367421b8d01acb6a63d7a4b",
            "e3ea3d838eb842b684e90649ba10f840",
            "94a87508ab9048199907f7a8ab08ba39",
            "6def3522aa5f4ec0a286e484038b7625",
            "66c9dcf05c95448ea1c53528c4d230e7",
            "62a2394b2b89437a89a6642d0dad5e45",
            "455abd056f264c1f8b325951ed1da922",
            "b56c799c22154c5fa70a8b181bb92784",
            "00ea55c65f5043b3b0df7500dd569242",
            "0eaf6b08b1f14ed6b63979fc139135f4",
            "cd3e96f969bf43e097e645696e897dbf",
            "02ef6427c12346caaeb26108fea72a3e",
            "ce934e1fabf74ce6aa7c8e27e56cd9ff",
            "ea1ec34746df45228418875c95a8bd40",
            "d01e02ec1d714db896b769690a27944c",
            "91714566a5894db49c9c1831a499e263",
            "9b01013cba11412b9f10e0a1916e0e21",
            "d206c204f2e64c479679a4c7a097b515",
            "84e05229873c45979162a5e71a123617",
            "dd8fa9205e314071aea03e92ac0b7565",
            "e409c1b3ba7f41de982baadd38787b2a",
            "b16a1444449b41a693299865b63b1096",
            "30326e7ef90548dda1164cd69bf25e76",
            "9e503661a0a744aeb46a1ad9ae7996b6",
            "47d70bfd3a8c499c906611c4975cb721",
            "6e4a07948bb744c1bcb36d0ce3628c24",
            "374e85eefd1241d4aa4821a9e9018af4",
            "518637e08a0448488fcafe5bc2f76870",
            "b4f79dba23be455d85d02e87a241f60f",
            "a0608f1c6f134dc9b7a15a7aa3c6de67",
            "651fd81be92a4b1fb44cbeff70ad6a0c",
            "bf67905540c4442db5528512013bddbd",
            "7570e0018d5244b79beb6cbbda66bcac",
            "451fdef93cb34f03aa3cbaa8c3e837d2",
            "496c7244c097421fb7e1aec090ecadf8",
            "981c71dc8ac940ea8abbe00a38867b06",
            "23de10e5256e4b9ab5ed0ffdd66833d1",
            "2533e88168a047f4b78eb10435c2ce30",
            "ca3597ef90114f6ca29462e4e3d681a9",
            "b8059b260991433ea7d060b0a47e6698",
            "c939ef86a107453bb3a6b020fe708881",
            "f49b4191735a4aada61bc1ddbfd98857",
            "a62a0e1ba8e14b7cac4cd30cdfd58d70",
            "8d590228478b455998402125d1c7fca0",
            "be8b1d56492142aba8789fcf5738a0fc",
            "41ca3d7279fe491fa1dacedfafa46a5a",
            "2d16c0ea19024b869c1dc81518d2f9f9",
            "ec72de63ed7f4ba9956ebcce77f11bab",
            "4b796527db0047c68c619a02fd0b722c",
            "c2ccce1e6a344f2f9dce9f749ae87c09",
            "c8c0eff9769e451592ffc12320945175",
            "51cd2c40b7624fcaaff6bc19abcff282",
            "2baeaeddac684cb2814a82f3aa72f8d0",
            "74d49d5a8b3a43f59ab59bc3bfc0209a",
            "49a2720d01854e349f7367215e87698c",
            "42df65d2e6b842709b1eabb5a2438075",
            "9645447f1dd8419db8d98562ac58b474",
            "65a0b5406d9347eab8da89b42ef107ee",
            "e78af2a831574a3982b225bb659fee67",
            "adb887efeacd41919240dfb430500064",
            "883cff7b97634e2a89c011d0b5a85a30",
            "10b163d77395420d972ad33ae92785ab",
            "c6bb026d0d5748469a643d89ec56309d",
            "b0e3e61fa2074c75a85f366010750d9d",
            "2ac1d43e7a964b46b6136cee86deac97",
            "4ce94df8274046db942ee5a2e00ee754",
            "a1829f08568740f397ed397d5000ddde",
            "bdffc401ff5145b7824d3fe1971ffb0e",
            "fcd3c2f82f2342d98146dcd8cf178046",
            "a623a59c3f104e9bab2c767b17952527",
            "fcb11585d0d94fffae6ada2ad0f40d6a",
            "3e425b1862144ebdb4174281ea2d2eeb",
            "3ecd105f1dd549b2aecaba400b7d3030",
            "fcaa961ea9dc43e380216f089016fdd3",
            "ef404330657a4a39981e9f67bd617567",
            "1d8f0438e28a4d7ea7a83d3076840c8b",
            "3f1e7401b3824a369c1866b20120b7fd"
          ]
        },
        "outputId": "52370153-ef8f-47c2-9838-6a28e79b2cdb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bed5908306af40509e39ec366c87c2fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09f363234e524cb0af8df25fa4c5d72d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80d5ee30893142f38ad7b4c6e7ae9775"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c8648d3f41b4a178a6480161eecffac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "035ae60252374d7085150739d4737874"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d554bd4c367421b8d01acb6a63d7a4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02ef6427c12346caaeb26108fea72a3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30326e7ef90548dda1164cd69bf25e76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "451fdef93cb34f03aa3cbaa8c3e837d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be8b1d56492142aba8789fcf5738a0fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42df65d2e6b842709b1eabb5a2438075"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1829f08568740f397ed397d5000ddde"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train_dataloader用於將訓練數據分成多個小批次**\n",
        "\n",
        "訓練數據集有 1000 個樣本，每個批次大小為 32，則 train_dataloader 的長度約為 1000 / 32 = 31.25，這裡取整後即為 31 或 32。\n",
        "\n",
        "**num_update_steps_per_epoch：每個週期中需要更新模型參數的步數**\n",
        "\n",
        "**num_training_steps：表示總的訓練步數，即所有訓練週期中的總更新次數。**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XGhkKZykl2L3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loss_fcn = CrossEntropyLoss()**\n",
        "輸入的預測分布（logits 或 softmax probabilities）：\n",
        "\n",
        "形狀：(𝑁,𝐶)\n",
        "\n",
        "*   𝑁是批次大小。\n",
        "\n",
        "*   𝐶是每個輸入樣本的類別數。\n",
        "\n",
        "\n",
        "每個元素是模型對某一類別的預測值（logits）。這些值可以是未經 softmax 函數轉換的原始 logits，也可以是已經轉換過的概率值。\n",
        "\n",
        "目標標籤（ground truth labels）：\n",
        "\n",
        "形狀：(𝑁)每個元素是對應於輸入樣本的真實類別索引（長度為 𝑁，每個值是\n",
        "0 到 𝐶−1 之間的整數）。"
      ],
      "metadata": {
        "id": "HDPl4jsQJdm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**num_train_epochs**"
      ],
      "metadata": {
        "id": "rjaiUes_pp4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 設定訓練的週期數，每個週期包括對整個訓練數據集的一次完整遍歷。\n",
        "num_train_epochs = 2\n",
        "\n",
        "# 計算每個週期的更新步數\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "# 總的訓練步數\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "# 定義數據整理器\n",
        "# **DataCollatorForSeq2Seq 是專門為序列到序列（Seq2Seq），包含標記化、填充\n",
        "data_collator = DataCollatorForSeq2Seq(summary_tokenizer, model=summary_model)\n",
        "\n",
        "# 定義優化器\n",
        "# **summary_model.parameters()：將 summary_model 的所有參數傳遞給優化器\n",
        "optimizer = AdamW(summary_model.parameters(), lr=2e-5)\n",
        "\n",
        "# 損失函數\n",
        "# 計算模型預測結果與實際標籤之間的差異\n",
        "loss_fcn = CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "CBWqeWMMrDGY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**get_model_inputs 函數:將摘要文本轉換為模型的目標輸入格式**"
      ],
      "metadata": {
        "id": "kiCyCTca6ngF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   tokenizer：用於標記化文本的 tokenizer，通常是預訓練模型的 tokenizer，例如 BART 或 BERT。\n",
        "*   corpus：一個包含多個文本的列表，每個文本都需要進行標記化處理。\n",
        "*   is_summaries：一個布爾值，指示是否處理的是摘要。如果是摘要，則使用不同的最大長度。\n"
      ],
      "metadata": {
        "id": "C_hE-7q_IeMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kaRoqzD2_eWt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2b05ab8b-dae8-489c-ddfb-436e59eefec4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n像是\\n{\\n    'input_ids': tensor([[101, 2023, 2003, 1037, 7099,  ...], [101, 2129, 2079, 2017, 2424, ...]]),\\n    'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, ...], [1, 1, 1, 1, 1, 1, 1, ...]])\\n}\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# 定義資料處理函數\n",
        "def get_model_inputs(tokenizer, corpus, is_summaries=False):\n",
        "    model_inputs = []  # 初始化模型輸入列表\n",
        "\n",
        "    # 設定最大長度，摘要用 MAX_TARGET_LENGTH，其他用 MAX_INPUT_LENGTH\n",
        "    # MAX_TARGET_LENGTH與MAX_INPUT_LENGTH在最前面定義了\n",
        "    max_length = MAX_INPUT_LENGTH if not is_summaries else MAX_TARGET_LENGTH\n",
        "\n",
        "    # 對每個文本進行標記\n",
        "    for text in corpus:\n",
        "        model_inputs.append(tokenizer(\n",
        "            text,\n",
        "            max_length=max_length,\n",
        "            truncation=True,  # 超過最大長度時進行截斷\n",
        "        ))\n",
        "\n",
        "    return model_inputs  # 返回標記化的輸入數據\n",
        "\n",
        "# labels 是經過 get_model_inputs 函數和 data_collator 函數處理後的輸出\n",
        "# 包含了轉換為標記 ID 的摘要文本（input_ids）和相應的注意力掩碼（attention_mask）。\n",
        "# 這些張量將被用作目標數據，傳遞給模型用於計算損失。\n",
        "\n",
        "'''\n",
        "像是\n",
        "{\n",
        "    'input_ids': tensor([[101, 2023, 2003, 1037, 7099,  ...], [101, 2129, 2079, 2017, 2424, ...]]),\n",
        "    'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, ...], [1, 1, 1, 1, 1, 1, 1, ...]])\n",
        "}\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**get_sentiment_probs(sentiment_model, texts)**\n",
        "\n",
        "情感分析模型 sentiment_model 對文本 texts 進行情感分類，獲取\"**情感概率**\"分數。\n",
        "\n",
        "*   遍歷每個文本，使用情感分析模型對其進行分類。\n",
        "*   獲取每個情感標籤的概率分數。\n",
        "\n",
        "返回一個包含每個文本情感概率分數的張量。"
      ],
      "metadata": {
        "id": "8NFesm9NKni7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**get_sentiment_labels(sentiment_model, texts)**\n",
        "\n",
        "情感分析模型 sentiment_model 對文本 texts 進行情感分類，獲取\"**情感標籤**\"\n",
        "\n",
        "*   遍歷每個文本，使用情感分析模型對其進行分類。\n",
        "*   將分類結果映射為情感標籤。\n",
        "\n",
        "返回一個包含每個文本情感標籤的張量。\n"
      ],
      "metadata": {
        "id": "9mTicH1jIKQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**with torch.no_grad() 反向傳播（Backpropagation）是計算梯度並更新模型參數的過程。當我們只需要進行推理（inference）或評估模型而不需要進行訓練時，我們可以禁用梯度計算以節省內存和計算資源。**\n",
        "\n",
        "torch 提供的功能和方法，包括定義張量、進行數學運算、自動微分等。"
      ],
      "metadata": {
        "id": "YIWH8T4qVaFA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "zhc2AbVQ_eWt"
      },
      "outputs": [],
      "source": [
        "def get_sentiment_logits(sentiment_model, corpus):\n",
        "    corpus_logits = []  # 存儲每個文本的情感 logits。\n",
        "\n",
        "    with torch.no_grad():  # 不計算梯度(不需要進行反向傳播)，節省內存和計算資源\n",
        "        for text in corpus:\n",
        "            if text:  # 新增檢查空文本的邏輯\n",
        "              sentiment = sentiment_model(text, return_all_scores=True)  # 獲取情感分析結果，返回所有分數。\n",
        "              logits = [score['score'] for score in sentiment]  # 獲取每個情感標籤的分數作為 logits。\n",
        "              corpus_logits.append(torch.tensor(logits))  # 將 logits 轉換為張量並添加到列表\n",
        "            else:\n",
        "                print(f\"Empty text found in corpus\")  # 新增警告信息\n",
        "    return torch.stack(corpus_logits)  # 將所有 logits 張量堆疊成一個張量\n",
        "\n",
        "\n",
        "'''\n",
        "CrossEntropyLoss 的預期輸入（即 logits）\n",
        "但 gen_summaries_sentiment_probs 經過 softmax 轉換為概率分數。\n",
        "不符合CrossEntropyLoss 的預期輸入（即 logits）\n",
        "'''\n",
        "# 定義情感機率，返回每個情感標籤的概率分數。\n",
        "def get_sentiment_probs(sentiment_model, corpus):\n",
        "    corpus_scores = [] # 存儲每個文本的情感分數。\n",
        "\n",
        "    with torch.no_grad():  # 不計算梯度(不需要進行反向傳播)，節省內存和計算資源\n",
        "        for text in corpus:\n",
        "            sentiment = sentiment_model(text, SENTIMENT_LABELS)  # 獲取情感分析結果，返回一個包含情感標籤和分數的字典。\n",
        "            labels = sentiment['labels']\n",
        "            scores = sentiment['scores']\n",
        "            sorted_scores = [scores[labels.index(label)] for label in SENTIMENT_LABELS]  # 按情感標籤順序排列分數\n",
        "            corpus_scores.append(torch.tensor(sorted_scores))  # 將分數轉換為張量並添加到列表\n",
        "\n",
        "    return torch.stack(corpus_scores)  # 將所有分數張量堆疊成一個張量\n",
        "\n",
        "# 將機率轉為情感標籤\n",
        "def get_sentiment_labels(sentiment_model, corpus):\n",
        "    corpus_scores = []\n",
        "\n",
        "    with torch.no_grad():  # 禁用梯度計算，節省內存和計算資源\n",
        "        for text in corpus:\n",
        "            if text:  # 新增檢查空文本的邏輯\n",
        "              sentiment = sentiment_model(text, SENTIMENT_LABELS)  # 使用情感模型進行情感分析，輸出結果包含各情感標籤的分數。\n",
        "              label = sentiment['labels'][0]  # 獲取最高機率的情感標籤\n",
        "              corpus_scores.append(SENTIMENT_LABELS_MAP[label])  # 將獲取到的情感標籤轉換為數字並添加到列表\n",
        "            # SENTIMENT_LABELS_MAP 是一個字典，將情感標籤轉換為數字。\n",
        "            else:\n",
        "                print(f\"Empty text found in corpus\")  # 新增警告信息\n",
        "    return torch.tensor(corpus_scores)  # 將所有標籤轉換為張量"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(自己)測試**"
      ],
      "metadata": {
        "id": "ZmdCz7sMv9fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def labels_to_probs(labels, num_classes):\n",
        "    \"\"\"\n",
        "    將標籤轉換為one-hot機率\n",
        "    \"\"\"\n",
        "    one_hot = F.one_hot(labels, num_classes).float()\n",
        "    return one_hot\n",
        "\n",
        "def probs_to_logits(probs):\n",
        "    \"\"\"\n",
        "    將機率轉換為logits\n",
        "    \"\"\"\n",
        "    logits = torch.log(probs + 1e-9)  # 加上1e-9以避免log(0)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "S6WX8LeZq4TL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_probs(sentiment_model, corpus):\n",
        "    corpus_scores = []\n",
        "    with torch.no_grad():\n",
        "        for text in corpus:\n",
        "            if text:\n",
        "                try:\n",
        "                    sentiment = sentiment_model(text, SENTIMENT_LABELS)\n",
        "                    if sentiment:\n",
        "                        labels = sentiment['labels']\n",
        "                        scores = sentiment['scores']\n",
        "                        sorted_scores = [scores[labels.index(label)] for label in SENTIMENT_LABELS]\n",
        "                        corpus_scores.append(torch.tensor(sorted_scores))\n",
        "                    else:\n",
        "                        print(f\"Error: Sentiment model returned invalid result for text: {text}\")\n",
        "                        corpus_scores.append(torch.ones(len(SENTIMENT_LABELS)) / len(SENTIMENT_LABELS))  # 使用均等張量作為默认值\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing text: {text}, error: {e}\")\n",
        "                    corpus_scores.append(torch.ones(len(SENTIMENT_LABELS)) / len(SENTIMENT_LABELS))  # 使用均等張量作為默认值\n",
        "            else:\n",
        "                print(f\"Error: Empty text found in corpus\")\n",
        "                corpus_scores.append(torch.ones(len(SENTIMENT_LABELS)) / len(SENTIMENT_LABELS))  # 使用均等張量作為默认值\n",
        "    return torch.stack(corpus_scores)\n",
        "\n",
        "def get_sentiment_labels(sentiment_model, corpus):\n",
        "    corpus_scores = []\n",
        "    with torch.no_grad():\n",
        "        for text in corpus:\n",
        "            if text:\n",
        "                try:\n",
        "                    sentiment = sentiment_model(text, SENTIMENT_LABELS)\n",
        "                    if sentiment and 'labels' in sentiment and len(sentiment['labels']) > 0:\n",
        "                        label = sentiment['labels'][0]\n",
        "                        corpus_scores.append(SENTIMENT_LABELS_MAP.get(label, -1))  # 使用 -1 作为未知标签\n",
        "                    else:\n",
        "                        print(f\"Error: Sentiment model returned invalid result for text: {text}\")\n",
        "                        corpus_scores.append(-1)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing text: {text}, error: {e}\")\n",
        "                    corpus_scores.append(-1)\n",
        "            else:\n",
        "                print(f\"Error: Empty text found in corpus\")\n",
        "                corpus_scores.append(-1)\n",
        "    return torch.tensor(corpus_scores)\n"
      ],
      "metadata": {
        "id": "yUKQJSuIv9P7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**生成文本摘要，並比較摘要與原始新聞的情感標籤是否一致，然後顯示一致的比例。**\n",
        "\n",
        "**pbar = tqdm(test_dataloader)：初始化進度條，用於顯示測試過程中的進度。**\n",
        "\n",
        "\n",
        "*   set_description 或 set_description_str 方法來設置進度條的描述信息\n",
        "\n",
        "  pbar.set_description_str('[Epoch {}] Training'.format(epoch))\n",
        "*   set_postfix_str 後綴信息來顯示一些動態數據，例如當前批次的損失和平均損失\n",
        "\n",
        "  pbar.set_postfix_str('Batch Loss: {:.6f}, Average Loss: {:.6f}'.format(batch_loss, avg_loss))\n",
        "\n",
        "\n",
        "*   自定義進度條的顯示格式，例如修改進度條的寬度、顏色和樣式\n",
        "\n",
        "  tqdm(total=100, ncols=80, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**test_dataloader 是測試數據的加載器。**"
      ],
      "metadata": {
        "id": "D-YU7iRHXlIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ".to(DEVICE)\n",
        "          將 input_ids 張量移動到指定的設備上，以便利用 GPU 加速運算。如果有 GPU 可用就使用 GPU，否則使用 CPU。\n",
        "\n",
        "          # 檢查是否有可用的 CUDA 設備（即 GPU），如果有，就將 DEVICE 設置為 \"cuda\"；如果沒有，就設置為 \"cpu\"。\n",
        "          DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "XSrCmAC7hrPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****3. 標準化損失和動態調整權重****"
      ],
      "metadata": {
        "id": "xQTKwIwTRL6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_weights(avg_summary_loss, avg_sentiment_loss, min_step=0.1):\n",
        "    if avg_summary_loss > avg_sentiment_loss:\n",
        "        return max(0.5 + min_step, 0.9), min(0.5 - min_step, 0.1)\n",
        "    else:\n",
        "        return min(0.5 - min_step, 0.1), max(0.5 + min_step, 0.9)\n",
        "\n",
        "def standardize_loss(loss, mean_loss):\n",
        "    if mean_loss == 0:\n",
        "        return loss\n",
        "    standardized_loss = (loss - mean_loss) / (abs(mean_loss) + 1e-9)\n",
        "    return standardized_loss\n"
      ],
      "metadata": {
        "id": "GkF82OslRKWD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**檢查數據集中情感標籤的分布是否均衡。**"
      ],
      "metadata": {
        "id": "QODPc_AbT18_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "def check_sentiment_distribution(corpus):\n",
        "    sentiment_labels = get_sentiment_labels(sentiment_model, corpus)\n",
        "    sentiment_counts = Counter(sentiment_labels.tolist())\n",
        "    print(\"Sentiment distribution:\")\n",
        "    for label, count in sentiment_counts.items():\n",
        "        print(f\"{label}: {count}\")\n",
        "    return sentiment_counts\n",
        "\n",
        "# 假設 train_dataloader 已經存在\n",
        "all_news = []\n",
        "for news, _ in tqdm(train_dataloader, desc=\"Collecting all news\"):\n",
        "    all_news.extend(news)\n",
        "\n",
        "check_sentiment_distribution(all_news)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "O3PjQWa2T0bJ",
        "outputId": "e974b65f-4489-4b6d-eb3a-430813ac2aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Collecting all news: 100%|██████████| 149/149 [00:00<00:00, 970.01it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7df7cb5bf058>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mall_news\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcheck_sentiment_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_news\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-7df7cb5bf058>\u001b[0m in \u001b[0;36mcheck_sentiment_distribution\u001b[0;34m(corpus)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_sentiment_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msentiment_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sentiment_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msentiment_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sentiment distribution:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-76d471230f8f>\u001b[0m in \u001b[0;36mget_sentiment_labels\u001b[0;34m(sentiment_model, corpus)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 新增檢查空文本的邏輯\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m               \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSENTIMENT_LABELS\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 使用情感模型進行情感分析，輸出結果包含各情感標籤的分數。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m               \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 獲取最高機率的情感標籤\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m               \u001b[0mcorpus_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSENTIMENT_LABELS_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 將獲取到的情感標籤轉換為數字並添加到列表\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unable to understand extra arguments {args}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"This example is {}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChunkPipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m             return next(\n\u001b[0m\u001b[1;32m   1235\u001b[0m                 iter(\n\u001b[1;32m   1236\u001b[0m                     self.get_iterator(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"use_cache\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_cache\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         model_outputs = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1886\u001b[0m             )\n\u001b[1;32m   1887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1888\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1889\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1597\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                     )\n\u001b[1;32m   1203\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m                     layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m   1205\u001b[0m                         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \"\"\"\n\u001b[1;32m    658\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         hidden_states, attn_weights, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    660\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;31m# self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36m_shape\u001b[0;34m(self, tensor, seq_len, bsz)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     def forward(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**測試與評估模型在測試數據集上的性能。**\n",
        "\n",
        "*   遍歷測試數據集，對每個批次進行處理：\n",
        "    *   生成模型輸入。\n",
        "    *   生成摘要並獲取情感標籤。\n",
        "    *   打印生成的摘要和情感標籤。\n",
        "\n",
        "評估模型在測試數據集上的生成效果。"
      ],
      "metadata": {
        "id": "iN4yXDOqH8XP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BART生成文本時，模型生成的 ID 序列是指模型在每個時間步生成的標記（token）的整數表示。這些 ID 序列是根據模型的詞彙表（vocabulary）進行編碼的，表示生成的每個標記在詞彙表中的索引。**\n",
        "\n",
        "\n",
        "*   詞彙表可能包含以下映射：{\"hello\": 0, \"world\": 1,\"\\<s>\": 2, \"\\</s>\": 3, ...}。\n",
        "*   \"\\<s> Deep learning is great \\</s>\"模型生成的 ID 序列可能是 [2, 451, 987, 123, 3]，其中每個整數對應於詞彙表中的一個標記。\n",
        "\n"
      ],
      "metadata": {
        "id": "S1hyTGO7shOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loss = summary_model(**).loss**\n",
        "\n",
        "使用方法及參數可以看\n",
        "\n",
        "\n",
        "*   官方文檔，例如 Hugging Face Transformers 文檔。\n",
        "\n",
        "*   查閱模型的源碼，通常可以在模型類的 forward 方法中找到所需的參數。\n",
        "\n"
      ],
      "metadata": {
        "id": "LwdRBrPs7C8l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3F37qFQ4_eWt"
      },
      "outputs": [],
      "source": [
        "def test_step():\n",
        "    # eval() 是 torch.nn.Module 類的一個方法，用於將模型設置為評估模式。\n",
        "    summary_model.eval()  # 設置模型為評估模式\n",
        "\n",
        "    result = []\n",
        "\n",
        "    # tqdm: 顯示迴圈的進度條\n",
        "    # test_dataloader: DataLoader迭代測試數據集，能夠在小批次中加載數據\n",
        "    pbar = tqdm(test_dataloader)  # 初始化進度條\n",
        "\n",
        "    for index, (news, _) in enumerate(pbar): # 遍歷測試數據加載器中的每個批次數據。news 是新聞文本，忽略其對應的標籤 _。\n",
        "        # 獲取輸入數據的ID並移動到設備\n",
        "        '''\n",
        "        *data_collator\n",
        "          是一個函數或對象，用於將多個樣本整理成一個批次（batch）。\n",
        "          在 NLP 任務中，這通常包括填充（padding）不同長度的序列以使它們具有相同的長度，以及創建注意掩碼。\n",
        "          data_collator 返回的結果通常是一個字典，其中包括多個鍵，例如 input_ids、attention_mask 等。\n",
        "        *['input_ids']\n",
        "          模型的實際輸入數據，即每個詞語對應的 token IDs\n",
        "        *.to(DEVICE)\n",
        "          將 input_ids 張量移動到指定的設備上，以便利用 GPU 加速運算。\n",
        "        '''\n",
        "        summary_model_inputs = data_collator(get_model_inputs(summary_tokenizer, news))['input_ids'].to(DEVICE)\n",
        "        # 生成摘要\n",
        "        # generate 是 transformers 庫中預訓練模型的內建方法\n",
        "        # 輸出是一個包含 token IDs 的張量或列表。這些 token IDs 是模型生成的摘要。\n",
        "        summary_model_outputs = summary_model.generate(summary_model_inputs)\n",
        "\n",
        "        # 解碼生成的摘要文本\n",
        "        '''batch_decode 是 tokenizer 的一個方法，用於將一批 token IDs 解碼為對應的文本。\n",
        "            skip_special_tokens=True 跳過特殊標記（special tokens），如 <s>, </s>, <pad> 等。\n",
        "        '''\n",
        "        summarized_text = summary_tokenizer.batch_decode(summary_model_outputs, skip_special_tokens=True)\n",
        "\n",
        "        # 獲取新聞的情感標籤\n",
        "        news_sentiment_label = get_sentiment_labels(sentiment_model, news)[0]\n",
        "        # 獲取摘要的情感標籤\n",
        "        summarized_sentiment_label = get_sentiment_labels(sentiment_model, summarized_text)[0]\n",
        "        # 比較新聞和摘要的情感標籤是否一致\n",
        "        # 新聞和摘要的情感如果一樣就是1，不一樣是0\n",
        "        result.append(1 if news_sentiment_label == summarized_sentiment_label else 0)\n",
        "\n",
        "        # 更新進度條後綴，顯示相同情感標籤的比例\n",
        "        # 當index是test_dataloader的最後一個要素。\n",
        "        if index == len(test_dataloader)-1:\n",
        "            '''進度條的後綴中顯示 \"Same Sentiment Rate\"\n",
        "               Same Sentiment Rate: result 中為 1 的比例，越高，代表生成摘要與原始新聞的情緒一致性越高\n",
        "                result.count(1):計算 result 列表中值為 1 的元素數量\n",
        "                代表\"摘要與原始新聞的情感標籤\"一致的情況\n",
        "            '''\n",
        "            pbar.set_postfix_str('Same Sentiment Rate: {:.3f}'.format(result.count(1) / len(result)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**在每個訓練週期（epoch）中訓練模型**\n",
        "\n",
        "*   生成模型輸入。\n",
        "*   計算損失，包括生成摘要的損失和情感匹配損失。\n",
        "*   反向傳播和參數更新。\n",
        "*   記錄和打印損失。\n",
        "\n",
        "主要作用是更新模型參數。"
      ],
      "metadata": {
        "id": "VoUMcTCReMZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**計算損失並更新參數**\n",
        "\n",
        "\n",
        "*   loss = summary_model(input_ids/attention_mask/labels).loss：計算訓練摘要模型的損失。\n",
        "*   optimizer.zero_grad()：清空優化器的梯度。\n",
        "*   loss.backward()：進行反向傳播，計算每個參數的梯度。\n",
        "*   optimizer.step()：更新模型參數。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FlZdLuRB89cS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**可以試早停跟學習率與loss**\n",
        "\n",
        "\\# 自己定義EarlyStopping函數\n",
        "\n",
        "early_stopping = EarlyStopping(patience=3, verbose=True)\n",
        "\n",
        "\\# 修改 scheduler\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                      num_warmup_steps=total_steps * 0.1,  # 暖身步驟數\n",
        "                      num_training_steps=total_steps,  # 總訓練步驟\n",
        "                      last_epoch=-1)"
      ],
      "metadata": {
        "id": "ukZJkv4iCKdz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZB-jHQR_eWu"
      },
      "outputs": [],
      "source": [
        "def train_step(epoch):\n",
        "    # 初始化列表來存儲每個批次的訓練損失\n",
        "    total_training_loss = []\n",
        "\n",
        "    # 將模型設置為訓練模式（啟用dropout等訓練專用層）\n",
        "    # BartForConditionalGeneration 模型中啟用的層(Dropout、Layer Normalization、自注意力機制、Embeddings 層)\n",
        "    summary_model.train()\n",
        "\n",
        "    # pbar = tqdm(train_dataloader): tqdm 包裝 train_dataloader 來顯示訓練進度。\n",
        "    # 設置進度條的描述，顯示當前的訓練週期(epoch 數)。\n",
        "    pbar = tqdm(train_dataloader)\n",
        "    pbar.set_description_str('[Epoch {}] Training'.format(epoch))\n",
        "\n",
        "    # 訓練數據加載器中的每個批次\n",
        "    for news, summaries in pbar:\n",
        "        # 使用 summary_tokenizer 和 data_collator 處理新聞文本，生成模型的輸入數據。\n",
        "        # 獲取訓練數據\n",
        "        inputs = data_collator(get_model_inputs(summary_tokenizer, news))\n",
        "\n",
        "        # 將輸入的 ID 和注意力掩碼移動到設備（例如 GPU）。\n",
        "        # 這些張量包含了模型的輸入數據（input IDs 和 attention masks），移動到指定（CPU 或 GPU）上，以便後續的模型計算。\n",
        "        X_input_ids = inputs['input_ids'].to(DEVICE)\n",
        "        X_attention_mask = inputs['attention_mask'].to(DEVICE)\n",
        "\n",
        "        # labels: 使用 summary_tokenizer 和 data_collator 處理資料集摘要，生成目標數據。\n",
        "        # y_input_ids: 將目標輸入 ID 移動到設備。\n",
        "        # 模型的真實摘要（target input IDs），移動到指定的設備上，以便在計算損失時使用。\n",
        "        labels = data_collator(get_model_inputs(summary_tokenizer, summaries, is_summaries=True))\n",
        "        y_input_ids = labels['input_ids'].to(DEVICE)\n",
        "\n",
        "\n",
        "        # 計算損失並更新模型參數-> 模型生成的輸出與目標輸入 ID 計算損失\n",
        "        # loss 變數:將輸入 ID、注意力掩碼和目標標籤傳遞給 summary_model (進行\"前向傳播\"計算)，衡量\"生成的摘要與真實摘要\"之間的差異\n",
        "        # .loss：\n",
        "          #   (在 Hugging Face 的 Transformers 庫中，當傳遞 labels 給模型時，會自動計算損失並包含在輸出中)\n",
        "          #   基於目標標籤（labels）和模型預測（input_ids 和 attention_mask 的前向傳播結果）之間的交叉熵損失，差異計算出來的\n",
        "        '''\n",
        "        input_ids=X_input_ids：模型的輸入 ID。(將新聞轉換為模型可讀的 ID 後的結果)\n",
        "        attention_mask=X_attention_mask：指示哪些位置是有效的（應該關注的），哪些是填充（padding）的\n",
        "        labels=y_input_ids：模型的目標標籤(摘要文本的 ID)。(將目標摘要轉換為模型可讀的 ID 後的結果)\n",
        "        '''\n",
        "        loss = summary_model(input_ids=X_input_ids,\n",
        "                             attention_mask=X_attention_mask,\n",
        "                             labels=y_input_ids).loss\n",
        "\n",
        "\n",
        "        # gen_summaries: 使用模型生成摘要文本，並解碼為可讀格式。\n",
        "        '''\n",
        "        summary_model.generate(X_input_ids)：這行程式碼使用模型來生成摘要\n",
        "        summary_tokenizer.batch_decode：這個方法將模型生成的 ID 序列轉換回人類可讀的文本。\n",
        "        '''\n",
        "        gen_summaries = summary_tokenizer.batch_decode(summary_model.generate(X_input_ids), skip_special_tokens=True)  # 生成摘要\n",
        "\n",
        "        # 獲取新聞的情感標籤\n",
        "        '''\n",
        "        get_sentiment_labels(sentiment_model, news)：\n",
        "          使用情感分析模型 sentiment_model 對新聞文本 news 進行分類，獲取情感標籤(根據你定義的情感標籤映射 (SENTIMENT_LABELS_MAP))。\n",
        "        .to(DEVICE)：將獲取的情感標籤張量移動到指定的設備上（DEVICE），這樣可以在訓練過程中使用 GPU 加速計算。\n",
        "        '''\n",
        "        news_sentiment_labels = get_sentiment_labels(sentiment_model, news).to(DEVICE)\n",
        "\n",
        "        # 獲取摘要的情感概率\n",
        "        '''\n",
        "        get_sentiment_probs(sentiment_model, gen_summaries)：\n",
        "          用情感分析模型 sentiment_model 對生成的摘要 gen_summaries 進行分類，獲取情感概率分數(各個情感標籤的概率。\n",
        "        .to(DEVICE)：將獲取的情感概率分數張量移動到指定的設備上（DEVICE），這樣可以在訓練過程中使用 GPU 加速計算。\n",
        "        '''\n",
        "        '''get_sentiment_probs輸出是機率，不符CrossEntropyLoss 的預期輸入（即 logits）'''\n",
        "        '''為了要符合 CrossEntropyLoss 的預期輸入（即 logits），get_sentiment_logits返回logits'''\n",
        "        gen_summaries_sentiment_probs = get_sentiment_probs(sentiment_model, gen_summaries).to(DEVICE)\n",
        "        # .clamp(min=1e-9) 是一個張量操作，將 gen_summaries_sentiment_probs 的值限制在至少 1×10−9的範圍內。防止概率值過小（接近於零），以避免在後續計算中出現數值不穩定或錯誤。\n",
        "        gen_summaries_sentiment_probs = gen_summaries_sentiment_probs.clamp(min=1e-9)\n",
        "        gen_summaries_sentiment_logits = torch.log(gen_summaries_sentiment_probs)\n",
        "\n",
        "        # 加上情感匹配損失\n",
        "        # 找到新聞情感的對應摘要機率，帶入損失函數做計算\n",
        "        # 原本loss生成摘要與新聞的損失\n",
        "        # loss_fcn基於\"生成摘要的情感分布\"與\"原始新聞文本的情感標籤\"之間的差異。\n",
        "        '''輸入方式是機率，不符CrossEntropyLoss 的預期輸入（即 logits）\n",
        "        loss = loss + loss_fcn(gen_summaries_sentiment_probs, news_sentiment_labels)'''\n",
        "        loss = loss + loss_fcn(gen_summaries_sentiment_logits, news_sentiment_labels)\n",
        "\n",
        "        '''\n",
        "        每個訓練批次中梯度清除、反向傳播和模型參數更新，並且記錄和顯示訓練過程中的損失值。\n",
        "        '''\n",
        "        # 清除上一個批次的梯度為0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 反向傳播計算梯度(鏈式法則)，基於損失值 loss 計算模型所有參數的梯度\n",
        "        # 這些梯度將存儲在每個參數的 grad 屬性中。\n",
        "        loss.backward()\n",
        "\n",
        "        # 更新模型參數\n",
        "        '''\n",
        "        程式碼預設是Adam，通常有較好的收斂性能，並且對於不同問題的參數設定不太敏感\n",
        "        '''\n",
        "        optimizer.step()  # 更新參數\n",
        "\n",
        "        # 將當前批次的損失值添加到總損失列表中\n",
        "        # loss.item() 會將損失張量轉換為標量值，當前批次的損失值\n",
        "        total_training_loss.append(loss.item())\n",
        "\n",
        "        # 更新進度條後綴，顯示當前批次的損失和平均損失\n",
        "        pbar.set_postfix_str('Batch Loss: {:.6f}, Average Loss: {:.6f}'.format(loss.item(), sum(total_training_loss) / len(total_training_loss)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**有調整loss權重的訓練過程**"
      ],
      "metadata": {
        "id": "3lWl0xiPwcVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(epoch):\n",
        "    global prev_summary_loss, prev_sentiment_loss\n",
        "    total_training_loss = []\n",
        "    total_summary_loss = []\n",
        "    total_sentiment_loss = []\n",
        "\n",
        "    summary_model.train()\n",
        "    pbar = tqdm(train_dataloader)\n",
        "    pbar.set_description_str('[Epoch {}] Training'.format(epoch))\n",
        "\n",
        "    for news, summaries in pbar:\n",
        "        inputs = data_collator(get_model_inputs(summary_tokenizer, news))\n",
        "        X_input_ids = inputs['input_ids'].to(DEVICE)\n",
        "        X_attention_mask = inputs['attention_mask'].to(DEVICE)\n",
        "\n",
        "        labels = data_collator(get_model_inputs(summary_tokenizer, summaries, is_summaries=True))\n",
        "        y_input_ids = labels['input_ids'].to(DEVICE)\n",
        "\n",
        "        summary_loss = summary_model(input_ids=X_input_ids,\n",
        "                                    attention_mask=X_attention_mask,\n",
        "                                    labels=y_input_ids).loss\n",
        "\n",
        "        gen_summaries = summary_tokenizer.batch_decode(summary_model.generate(X_input_ids), skip_special_tokens=True)\n",
        "\n",
        "        if any(not gs for gs in gen_summaries):\n",
        "            print(f\"Empty generated summary found: {gen_summaries}\")\n",
        "\n",
        "        news_sentiment_labels = get_sentiment_labels(sentiment_model, news).to(DEVICE)\n",
        "        gen_summaries_sentiment_probs = get_sentiment_probs(sentiment_model, gen_summaries).to(DEVICE)\n",
        "        # .clamp(min=1e-9) 是一個張量操作，將 gen_summaries_sentiment_probs 的值限制在至少 1×10−9的範圍內。防止概率值過小（接近於零），以避免在後續計算中出現數值不穩定或錯誤。\n",
        "        gen_summaries_sentiment_probs = gen_summaries_sentiment_probs.clamp(min=1e-9)\n",
        "        gen_summaries_sentiment_logits = torch.log(gen_summaries_sentiment_probs)\n",
        "        sentiment_loss = loss_fcn(gen_summaries_sentiment_logits, news_sentiment_labels)\n",
        "\n",
        "\n",
        "        total_loss = summary_loss_weight * summary_loss + sentiment_loss_weight * sentiment_loss\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_training_loss.append(total_loss.item())\n",
        "        total_summary_loss.append(summary_loss.item())\n",
        "        total_sentiment_loss.append(sentiment_loss.item())\n",
        "        pbar.set_postfix_str('Batch Loss: {:.6f}, Average Loss: {:.6f}'.format(\n",
        "            total_loss.item(), sum(total_training_loss) / len(total_training_loss)))\n",
        "\n",
        "    # 計算摘要損失的平均值\n",
        "    avg_summary_loss = sum(total_summary_loss) / len(total_summary_loss)\n",
        "    # 計算情感損失的平均值\n",
        "    avg_sentiment_loss = sum(total_sentiment_loss) / len(total_sentiment_loss)"
      ],
      "metadata": {
        "id": "EIIzu1_6u1O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. 標準化損失和動態調整權重**"
      ],
      "metadata": {
        "id": "UZJ8LhqqJmzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(epoch, avg_summary_loss, avg_sentiment_loss):\n",
        "    global prev_summary_loss, prev_sentiment_loss\n",
        "    total_training_loss = []\n",
        "    total_summary_loss = []\n",
        "    total_sentiment_loss = []\n",
        "    summary_model.train()\n",
        "    pbar = tqdm(train_dataloader)\n",
        "    pbar.set_description_str('[Epoch {}] Training'.format(epoch))\n",
        "\n",
        "    for news, summaries in pbar:\n",
        "        if news is None or summaries is None:\n",
        "            print(\"Error: News or Summaries is None\")\n",
        "            continue\n",
        "        inputs = data_collator(get_model_inputs(summary_tokenizer, news))\n",
        "        X_input_ids = inputs['input_ids'].to(DEVICE)\n",
        "        X_attention_mask = inputs['attention_mask'].to(DEVICE)\n",
        "        labels = data_collator(get_model_inputs(summary_tokenizer, summaries, is_summaries=True))\n",
        "        y_input_ids = labels['input_ids'].to(DEVICE)\n",
        "\n",
        "        summary_loss = summary_model(input_ids=X_input_ids, attention_mask=X_attention_mask, labels=y_input_ids).loss\n",
        "        gen_summaries = summary_tokenizer.batch_decode(summary_model.generate(X_input_ids), skip_special_tokens=True)\n",
        "        if gen_summaries is None:\n",
        "            print(\"Error: Generated summaries is None\")\n",
        "            continue\n",
        "\n",
        "        news_sentiment_labels = get_sentiment_labels(sentiment_model, news).to(DEVICE)\n",
        "        gen_summaries_sentiment_probs = get_sentiment_probs(sentiment_model, gen_summaries).to(DEVICE)\n",
        "        sentiment_loss = loss_fcn(gen_summaries_sentiment_probs, news_sentiment_labels)\n",
        "\n",
        "        # 標準化損失\n",
        "        standardized_summary_loss = standardize_loss(summary_loss.item(), avg_summary_loss)\n",
        "        standardized_sentiment_loss = standardize_loss(sentiment_loss.item(), avg_sentiment_loss)\n",
        "\n",
        "        total_loss = summary_loss_weight * summary_loss + sentiment_loss_weight * sentiment_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_training_loss.append(total_loss.item())\n",
        "        total_summary_loss.append(summary_loss.item())\n",
        "        total_sentiment_loss.append(sentiment_loss.item())\n",
        "        pbar.set_postfix_str('Batch Loss: {:.6f}, Average Loss: {:.6f}'.format(total_loss.item(), sum(total_training_loss) / len(total_training_loss)))\n",
        "\n",
        "    avg_summary_loss = 0.9 * avg_summary_loss + 0.1 * (sum(total_summary_loss) / len(total_summary_loss))\n",
        "    avg_sentiment_loss = 0.9 * avg_sentiment_loss + 0.1 * (sum(total_sentiment_loss) / len(total_sentiment_loss))\n",
        "    return avg_summary_loss, avg_sentiment_loss\n"
      ],
      "metadata": {
        "id": "M7RcSDCfJO_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. 滑動平均能夠平滑損失值，減少波動，使得損失值變得更加穩定和可追踪。**"
      ],
      "metadata": {
        "id": "7sO916IH-LRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(epoch, avg_summary_loss, avg_sentiment_loss):\n",
        "    global prev_summary_loss, prev_sentiment_loss, summary_loss_weight, sentiment_loss_weight\n",
        "    total_training_loss = []\n",
        "    total_summary_loss = []\n",
        "    total_sentiment_loss = []\n",
        "    same_sentiment_count = 0\n",
        "    total_count = 0\n",
        "    summary_model.train()\n",
        "    pbar = tqdm(train_dataloader)\n",
        "    pbar.set_description_str('[Epoch {}] Training'.format(epoch))\n",
        "\n",
        "    for news, summaries in pbar:\n",
        "        if news is None or summaries is None:\n",
        "            print(\"Error: News or Summaries is None\")\n",
        "            continue\n",
        "        inputs = data_collator(get_model_inputs(summary_tokenizer, news))\n",
        "        if 'input_ids' not in inputs or 'attention_mask' not in inputs:\n",
        "            print(f\"Error: Invalid inputs from data_collator: {inputs}\")\n",
        "            continue\n",
        "        X_input_ids = inputs['input_ids'].to(DEVICE)\n",
        "        X_attention_mask = inputs['attention_mask'].to(DEVICE)\n",
        "\n",
        "        labels = data_collator(get_model_inputs(summary_tokenizer, summaries, is_summaries=True))\n",
        "        if 'input_ids' not in labels:\n",
        "            print(f\"Error: Invalid labels from data_collator: {labels}\")\n",
        "            continue\n",
        "        y_input_ids = labels['input_ids'].to(DEVICE)\n",
        "\n",
        "        summary_loss = summary_model(input_ids=X_input_ids, attention_mask=X_attention_mask, labels=y_input_ids).loss\n",
        "\n",
        "        gen_summaries = summary_tokenizer.batch_decode(summary_model.generate(X_input_ids), skip_special_tokens=True)\n",
        "        if not gen_summaries:\n",
        "            print(\"Error: Generated summaries are empty\")\n",
        "            continue\n",
        "\n",
        "        news_sentiment_labels = get_sentiment_labels(sentiment_model, news).to(DEVICE)\n",
        "        news_sentiment_probs = labels_to_probs(news_sentiment_labels, len(SENTIMENT_LABELS)).to(DEVICE)\n",
        "        news_sentiment_logits = probs_to_logits(news_sentiment_probs)\n",
        "\n",
        "        gen_summaries_sentiment_probs = get_sentiment_probs(sentiment_model, gen_summaries).to(DEVICE)\n",
        "        gen_summaries_sentiment_logits = probs_to_logits(gen_summaries_sentiment_probs).to(DEVICE)\n",
        "\n",
        "        if news_sentiment_logits.size(0) == 0 or gen_summaries_sentiment_logits.size(0) == 0:\n",
        "            print(\"Error: Sentiment labels or logits are empty\")\n",
        "            continue\n",
        "\n",
        "        sentiment_loss = loss_fcn(gen_summaries_sentiment_logits, news_sentiment_labels)\n",
        "\n",
        "        # 計算相同情感的比例\n",
        "        same_sentiment_count += (torch.argmax(news_sentiment_logits, dim=1) == torch.argmax(gen_summaries_sentiment_logits, dim=1)).sum().item()\n",
        "        total_count += news_sentiment_labels.size(0)\n",
        "\n",
        "        # 標準化損失\n",
        "        standardized_summary_loss = standardize_loss(summary_loss.item(), avg_summary_loss)\n",
        "        standardized_sentiment_loss = standardize_loss(sentiment_loss.item(), avg_sentiment_loss)\n",
        "\n",
        "        # 確保標準化后的損失是浮點數\n",
        "        standardized_summary_loss = torch.tensor(float(standardized_summary_loss), dtype=torch.float32, requires_grad=True).to(DEVICE)\n",
        "        standardized_sentiment_loss = torch.tensor(float(standardized_sentiment_loss), dtype=torch.float32, requires_grad=True).to(DEVICE)\n",
        "\n",
        "        total_loss = summary_loss_weight * standardized_summary_loss + sentiment_loss_weight * standardized_sentiment_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_training_loss.append(total_loss.item())\n",
        "        total_summary_loss.append(summary_loss.item())\n",
        "        total_sentiment_loss.append(sentiment_loss.item())\n",
        "\n",
        "        # 更新進度條的後綴信息，顯示當前批次損失和平均損失\n",
        "        pbar.set_postfix_str('Batch Loss: {:.6f}, Avg Loss: {:.6f}'.format(total_loss.item(), sum(total_training_loss) / len(total_training_loss)))\n",
        "\n",
        "    avg_summary_loss = 0.9 * avg_summary_loss + 0.1 * (sum(total_summary_loss) / len(total_summary_loss))\n",
        "    avg_sentiment_loss = 0.9 * avg_sentiment_loss + 0.1 * (sum(total_sentiment_loss) / len(total_sentiment_loss))\n",
        "    same_sentiment_rate = same_sentiment_count / total_count\n",
        "    print(f\"Same Sentiment Rate: {same_sentiment_rate:.3f}\")\n",
        "    return avg_summary_loss, avg_sentiment_loss, same_sentiment_rate"
      ],
      "metadata": {
        "id": "OUJoRY---Kw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. 直接用logits算loss**"
      ],
      "metadata": {
        "id": "ncyJW08ZEZxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(epoch, avg_summary_loss, avg_sentiment_loss):\n",
        "    global prev_summary_loss, prev_sentiment_loss, summary_loss_weight, sentiment_loss_weight\n",
        "    total_training_loss = []\n",
        "    total_summary_loss = []\n",
        "    total_sentiment_loss = []\n",
        "    same_sentiment_count = 0\n",
        "    total_count = 0\n",
        "    summary_model.train()\n",
        "    pbar = tqdm(train_dataloader)\n",
        "    pbar.set_description_str('[Epoch {}] Training'.format(epoch))\n",
        "\n",
        "    for news, summaries in pbar:\n",
        "        if news is None or summaries is None:\n",
        "            print(\"Error: News or Summaries is None\")\n",
        "            continue\n",
        "        inputs = data_collator(get_model_inputs(summary_tokenizer, news))\n",
        "        if 'input_ids' not in inputs or 'attention_mask' not in inputs:\n",
        "            print(f\"Error: Invalid inputs from data_collator: {inputs}\")\n",
        "            continue\n",
        "        X_input_ids = inputs['input_ids'].to(DEVICE)\n",
        "        X_attention_mask = inputs['attention_mask'].to(DEVICE)\n",
        "\n",
        "        labels = data_collator(get_model_inputs(summary_tokenizer, summaries, is_summaries=True))\n",
        "        if 'input_ids' not in labels:\n",
        "            print(f\"Error: Invalid labels from data_collator: {labels}\")\n",
        "            continue\n",
        "        y_input_ids = labels['input_ids'].to(DEVICE)\n",
        "\n",
        "        summary_loss = summary_model(input_ids=X_input_ids, attention_mask=X_attention_mask, labels=y_input_ids).loss\n",
        "\n",
        "        gen_summaries = summary_tokenizer.batch_decode(summary_model.generate(X_input_ids), skip_special_tokens=True)\n",
        "        if not gen_summaries:\n",
        "            print(\"Error: Generated summaries are empty\")\n",
        "            continue\n",
        "\n",
        "        # 獲取新聞的情緒標籤索引\n",
        "        news_sentiment_labels = get_sentiment_labels(sentiment_model, news).to(DEVICE)\n",
        "        # 獲取生成的摘要的情緒logits\n",
        "        gen_summaries_sentiment_probs = get_sentiment_probs(sentiment_model, gen_summaries).to(DEVICE)\n",
        "        gen_summaries_sentiment_logits = torch.log(gen_summaries_sentiment_probs.clamp(min=1e-9))\n",
        "\n",
        "        # 確保 logits 沒有問題\n",
        "        if gen_summaries_sentiment_logits.size(0) == 0 or news_sentiment_labels.size(0) == 0:\n",
        "            print(\"Error: Sentiment labels or logits are empty\")\n",
        "            continue\n",
        "\n",
        "        # 使用 CrossEntropyLoss 計算情緒損失\n",
        "        sentiment_loss = loss_fcn(gen_summaries_sentiment_logits, news_sentiment_labels)\n",
        "\n",
        "        # 計算相同情感的比例\n",
        "        same_sentiment_count += (torch.argmax(gen_summaries_sentiment_logits, dim=1) == news_sentiment_labels).sum().item()\n",
        "        total_count += news_sentiment_labels.size(0)\n",
        "\n",
        "        # 標準化損失\n",
        "        standardized_summary_loss = standardize_loss(summary_loss.item(), avg_summary_loss)\n",
        "        standardized_sentiment_loss = standardize_loss(sentiment_loss.item(), avg_sentiment_loss)\n",
        "\n",
        "        # 確保標準化后的損失是浮點數\n",
        "        standardized_summary_loss = torch.tensor(float(standardized_summary_loss), dtype=torch.float32, requires_grad=True).to(DEVICE)\n",
        "        standardized_sentiment_loss = torch.tensor(float(standardized_sentiment_loss), dtype=torch.float32, requires_grad=True).to(DEVICE)\n",
        "\n",
        "        total_loss = summary_loss_weight * standardized_summary_loss + sentiment_loss_weight * standardized_sentiment_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_training_loss.append(total_loss.item())\n",
        "        total_summary_loss.append(summary_loss.item())\n",
        "        total_sentiment_loss.append(sentiment_loss.item())\n",
        "\n",
        "        # 更新進度條的後綴信息，顯示當前批次損失和平均損失\n",
        "        pbar.set_postfix_str('Batch Loss: {:.6f}, Avg Loss: {:.6f}'.format(total_loss.item(), sum(total_training_loss) / len(total_training_loss)))\n",
        "\n",
        "    avg_summary_loss = 0.9 * avg_summary_loss + 0.1 * (sum(total_summary_loss) / len(total_summary_loss))\n",
        "    avg_sentiment_loss = 0.9 * avg_sentiment_loss + 0.1 * (sum(total_sentiment_loss) / len(total_sentiment_loss))\n",
        "    same_sentiment_rate = same_sentiment_count / total_count\n",
        "    print(f\"Same Sentiment Rate: {same_sentiment_rate:.3f}\")\n",
        "    return avg_summary_loss, avg_sentiment_loss, same_sentiment_rate"
      ],
      "metadata": {
        "id": "kH2e2jYBEYwG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**執行單個驗證步驟（epoch）。**\n",
        "\n",
        "*   設置模型為評估模式。\n",
        "*   遍歷驗證數據集，對每個批次進行處理：\n",
        "    *   生成模型輸入。\n",
        "    *   計算損失，包括生成摘要的損失和情感匹配損失。\n",
        "    *   記錄和打印損失。\n",
        "\n",
        "主要作用是評估模型在驗證數據集上的性能。"
      ],
      "metadata": {
        "id": "ofpBDK6GHuQG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kl3TW-8P_eWu"
      },
      "outputs": [],
      "source": [
        "def eval_step(epoch):\n",
        "    total_vaild_loss = []  # 初始化存儲總驗證損失的列表\n",
        "\n",
        "    summary_model.eval()  # 設置模型為評估模式\n",
        "\n",
        "    pbar = tqdm(eval_dataloader)  # 初始化進度條\n",
        "    # 設置進度條的描述，顯示當前的驗證週期\n",
        "    pbar.set_description_str('[Epoch {}] Validation'.format(epoch))\n",
        "\n",
        "    # 驗證數據加載器中的每個批次\n",
        "    for news, summaries in pbar:\n",
        "        # 新聞文本轉換為模型輸入格式\n",
        "        inputs = data_collator(get_model_inputs(summary_tokenizer, news))\n",
        "\n",
        "        # 模型的輸入數據 ID 和注意力掩碼移動到設備（例如 GPU）。\n",
        "        X_input_ids = inputs['input_ids'].to(DEVICE)\n",
        "        X_attention_mask = inputs['attention_mask'].to(DEVICE)  # 移動注意力掩碼到設備\n",
        "\n",
        "        # 摘要轉換為模型的目標輸入格式，並移動到設備上\n",
        "        # labels 的輸出張量\n",
        "          # input_ids：轉換後的摘要文本的標記 ID。\n",
        "          # attention_mask：填充的位置，指示哪些位置是填充（0），哪些是有效標記（1）。\n",
        "        labels = data_collator(get_model_inputs(summary_tokenizer, summaries, is_summaries=True))  # 獲取目標數據\n",
        "        y_input_ids = labels['input_ids'].to(DEVICE)  # 移動目標輸入 ID 到設備\n",
        "\n",
        "        # 計算\"新聞文本與對應摘要\"的損失函數。\n",
        "        loss = summary_model(input_ids=X_input_ids,\n",
        "                             attention_mask=X_attention_mask,\n",
        "                             labels=y_input_ids).loss\n",
        "\n",
        "        # 生成摘要\n",
        "        gen_summaries = summary_tokenizer.batch_decode(summary_model.generate(X_input_ids), skip_special_tokens=True)\n",
        "\n",
        "        # 獲取新聞的情感標籤\n",
        "        news_sentiment_labels = get_sentiment_labels(sentiment_model, news).to(DEVICE)\n",
        "        # 獲取摘要的情感概率\n",
        "\n",
        "        '''get_sentiment_probs輸出是機率，不符CrossEntropyLoss 的預期輸入（即 logits）'''\n",
        "        # gen_summaries_sentiment_probs = get_sentiment_probs(sentiment_model, gen_summaries).to(DEVICE)\n",
        "        '''為了要符合 CrossEntropyLoss 的預期輸入（即 logits），get_sentiment_logits返回logits'''\n",
        "        # gen_summaries_sentiment_logits = get_sentiment_logits(sentiment_model, gen_summaries).to(DEVICE)\n",
        "        gen_summaries_sentiment_probs = get_sentiment_probs(sentiment_model, gen_summaries).to(DEVICE)\n",
        "        # .clamp(min=1e-9) 是一個張量操作，將 gen_summaries_sentiment_probs 的值限制在至少 1×10−9的範圍內。防止概率值過小（接近於零），以避免在後續計算中出現數值不穩定或錯誤。\n",
        "        gen_summaries_sentiment_probs = gen_summaries_sentiment_probs.clamp(min=1e-9)\n",
        "        gen_summaries_sentiment_logits = torch.log(gen_summaries_sentiment_probs)\n",
        "\n",
        "        # 加上情感匹配損失\n",
        "        # 找到新聞情感的對應摘要機率，帶入損失函數做計算\n",
        "        # 原本loss生成摘要與新聞的損失\n",
        "        # loss_fcn基於\"生成摘要的情感分布\"與\"原始新聞文本的情感標籤\"之間的差異。\n",
        "        '''輸入方式是機率，不符CrossEntropyLoss 的預期輸入（即 logits）\n",
        "        loss = loss + loss_fcn(gen_summaries_sentiment_probs, news_sentiment_labels)'''\n",
        "        loss = loss + loss_fcn(gen_summaries_sentiment_logits, news_sentiment_labels)\n",
        "\n",
        "        total_vaild_loss.append(loss.item())  # 記錄損失\n",
        "\n",
        "        # 更新進度條後綴，顯示當前批次的損失和平均損失\n",
        "        pbar.set_postfix_str('Batch Loss: {:.6f}, Average Loss: {:.6f}'.format(loss.item(), sum(total_vaild_loss) / len(total_vaild_loss)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.**"
      ],
      "metadata": {
        "id": "gCSf-T1FKGHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_step(epoch):\n",
        "    total_vaild_loss = []  # 初始化存儲總驗證損失的列表\n",
        "\n",
        "    summary_model.eval()  # 設置模型為評估模式\n",
        "\n",
        "    pbar = tqdm(eval_dataloader)  # 初始化進度條\n",
        "    # 設置進度條的描述，顯示當前的驗證週期\n",
        "    pbar.set_description_str('[Epoch {}] Validation'.format(epoch))\n",
        "\n",
        "    # 驗證數據加載器中的每個批次\n",
        "    for news, summaries in pbar:\n",
        "        # 新聞文本轉換為模型輸入格式\n",
        "        inputs = data_collator(get_model_inputs(summary_tokenizer, news))\n",
        "\n",
        "        # 模型的輸入數據 ID 和注意力掩碼移動到設備（例如 GPU）。\n",
        "        X_input_ids = inputs['input_ids'].to(DEVICE)\n",
        "        X_attention_mask = inputs['attention_mask'].to(DEVICE)  # 移動注意力掩碼到設備\n",
        "\n",
        "        # 摘要轉換為模型的目標輸入格式，並移動到設備上\n",
        "        # labels 的輸出張量\n",
        "          # input_ids：轉換後的摘要文本的標記 ID。\n",
        "          # attention_mask：填充的位置，指示哪些位置是填充（0），哪些是有效標記（1）。\n",
        "        labels = data_collator(get_model_inputs(summary_tokenizer, summaries, is_summaries=True))  # 獲取目標數據\n",
        "        y_input_ids = labels['input_ids'].to(DEVICE)  # 移動目標輸入 ID 到設備\n",
        "\n",
        "        # 計算\"新聞文本與對應摘要\"的損失函數。\n",
        "        loss = summary_model(input_ids=X_input_ids,\n",
        "                             attention_mask=X_attention_mask,\n",
        "                             labels=y_input_ids).loss\n",
        "\n",
        "        # 生成摘要\n",
        "        gen_summaries = summary_tokenizer.batch_decode(summary_model.generate(X_input_ids), skip_special_tokens=True)\n",
        "\n",
        "        # 獲取新聞的情感標籤索引\n",
        "        news_sentiment_labels = get_sentiment_labels(sentiment_model, news).to(DEVICE)\n",
        "        # 獲取摘要的情感logits\n",
        "        gen_summaries_sentiment_probs = get_sentiment_probs(sentiment_model, gen_summaries).to(DEVICE)\n",
        "        gen_summaries_sentiment_logits = torch.log(gen_summaries_sentiment_probs.clamp(min=1e-9))\n",
        "\n",
        "        # 確保 logits 沒有問題\n",
        "        if gen_summaries_sentiment_logits.size(0) == 0 or news_sentiment_labels.size(0) == 0:\n",
        "            print(\"Error: Sentiment labels or logits are empty\")\n",
        "            continue\n",
        "\n",
        "        # 使用 CrossEntropyLoss 計算情緒損失\n",
        "        sentiment_loss = loss_fcn(gen_summaries_sentiment_logits, news_sentiment_labels)\n",
        "\n",
        "        # 加上情感匹配損失\n",
        "        loss = loss + sentiment_loss\n",
        "\n",
        "        total_vaild_loss.append(loss.item())  # 記錄損失\n",
        "\n",
        "        # 更新進度條後綴，顯示當前批次的損失和平均損失\n",
        "        pbar.set_postfix_str('Batch Loss: {:.6f}, Average Loss: {:.6f}'.format(loss.item(), sum(total_vaild_loss) / len(total_vaild_loss)))"
      ],
      "metadata": {
        "id": "lAwAvVzjHuF9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**從模型檔案名稱中提取 epoch 編號。**\n",
        "\n",
        "返回提取出的 epoch 編號（整數）。"
      ],
      "metadata": {
        "id": "tBXds-gSHTe-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "oasq9apH_eWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a66bbfc1-2129-44e0-8794-a31a0cda279b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-05005b2022d4>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0m函數將檢查點檔案加載到\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0m變數中\u001b[0m\u001b[0;31m，\u001b[0m\u001b[0m這是一個包含模型狀態和訓練進度的字典\u001b[0m\u001b[0;31m。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     '''\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_SAVE_PTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# 初始化訓練開始的 epoch 數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 return _load(opened_zipfile,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                              \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                              \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverall_storage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstorage_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstorage_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0;31m# swap here if byteswapping is needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbyteorderdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 定義一個函數用來從檔案名中解析出模型訓練的 epoch 數字\n",
        "def get_model_epoch_num(file_name):\n",
        "    # 從檔案名分割出 epoch 數字，並轉換成整數型態返回\n",
        "    '''\n",
        "    model_epoch_10.pt\n",
        "    file_name.split('_') [\"model\", \"epoch\", \"10.pt\"]\n",
        "    file_name.split('_')[-1]  \"10.pt\"\n",
        "    file_name.split('_')[-1][:-3]  \"10\"\n",
        "    '''\n",
        "    return int(file_name.split('_')[-1][:-3])\n",
        "\n",
        "# 用來存儲最新的模型檢查點的字典\n",
        "ckpt = None\n",
        "\n",
        "# 檢查模型儲存路徑是否存在，不存在則創建\n",
        "if not os.path.exists(MODEL_SAVE_PTH):\n",
        "    os.mkdir(MODEL_SAVE_PTH)\n",
        "\n",
        "# 檢查指定路徑下是否有檔案存在\n",
        "if len(os.listdir(MODEL_SAVE_PTH)) != 0:\n",
        "    latest = os.listdir(MODEL_SAVE_PTH)[0]  # 先預設第一個檔案為最新\n",
        "\n",
        "    # 遍歷該路徑下的所有檔案\n",
        "    for file in os.listdir(MODEL_SAVE_PTH):\n",
        "        # 檢查檔案是否為 PyTorch 的模型檔案（以 'pt' 結尾），且檢查是否比已知的最新檔案新\n",
        "        # file[-2:]:倒數第二個字符開始一直到字符串的結尾\n",
        "        if file[-2:] == 'pt' and get_model_epoch_num(file) > get_model_epoch_num(latest):\n",
        "            latest = file  # 更新最新檔案\n",
        "\n",
        "    # 加載最新的模型檢查點\n",
        "    # 模型保存路徑 MODEL_SAVE_PTH 和最新的檔案名 latest 組合成一個完整的文件路徑。\n",
        "    '''\n",
        "    latest 是最新的檢查點\"檔案名稱\"\n",
        "    MODEL_SAVE_PTH 是保存\"檔案的目錄\"\n",
        "    torch.load 函數將檢查點檔案加載到 ckpt 變數中，這是一個包含模型狀態和訓練進度的字典。\n",
        "    '''\n",
        "    ckpt = torch.load(os.path.join(MODEL_SAVE_PTH, latest))\n",
        "\n",
        "start_epoch = 0  # 初始化訓練開始的 epoch 數\n",
        "\n",
        "# 如果 ckpt 不是 None，即成功加載了模型檢查點\n",
        "if ckpt != None:\n",
        "    # 恢復訓練進度，可以從上次訓練結束的地方繼續訓練\n",
        "    start_epoch = ckpt['epoch']  # 從檢查點讀取目前的 epoch 數\n",
        "    # load_state_dict 將檢查點中的模型參數(權重、biases)，加載到 summary_model 模型中\n",
        "    summary_model.load_state_dict(ckpt['model_state_dict'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**全部印出來**"
      ],
      "metadata": {
        "id": "rzYfv_kCkumQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 這裡可以設定epoch要從哪裡開始\n",
        "# 假設我之前訓練到第5個epoch，那我還要繼續10個range，我從這裏的start_epoch改掉就好\n",
        "# start_epoch=5, range=10\n",
        "\n",
        "# 定義一個函數來獲取模型檔案的訓練 epoch 編號\n",
        "def get_model_epoch_num(file_name):\n",
        "    # 假設檔案名稱格式為 \"model_epoch_XX.pt\"，提取最後的數字部分作為 epoch 編號\n",
        "    return int(file_name.split('_')[-1][:-3])\n",
        "\n",
        "# 初始化模型檢查點為 None\n",
        "# 變數 ckpt 是用來存儲最新加載的模型檢查點的。模型檢查點通常包含了訓練過程中的關鍵狀態，\n",
        "# 例如當前的 epoch 編號、模型的參數（狀態字典）和優化器的狀態等。\n",
        "ckpt = None\n",
        "\n",
        "# 如果模型保存路徑不存在，則創建該目錄\n",
        "if not os.path.exists(MODEL_SAVE_PTH):\n",
        "    os.mkdir(MODEL_SAVE_PTH)\n",
        "\n",
        "# 如果模型保存路徑下有檔案\n",
        "if len(os.listdir(MODEL_SAVE_PTH)) != 0:\n",
        "    # 初始化 latest變數為_目錄中的第一個檔案\n",
        "    latest = os.listdir(MODEL_SAVE_PTH)[0]\n",
        "    print(latest) #state_dict_1.pt\n",
        "    # 遍歷模型保存路徑中的所有檔案\n",
        "    for file in os.listdir(MODEL_SAVE_PTH):\n",
        "        # 檢查檔案是否為模型檔案（假設模型檔案的副檔名為 .pt）\n",
        "        if file[-2:] == 'pt':\n",
        "            # 更新 assign 變數為找到的 state_dict_5.pt 檔案\n",
        "            if file == 'state_dict_1.pt':\n",
        "                assign = file\n",
        "            # 如果該檔案的 epoch 編號大於目前的最新檔案，則更新 latest\n",
        "            if get_model_epoch_num(file) > get_model_epoch_num(latest):\n",
        "                latest = file\n",
        "\n",
        "    print(latest) #state_dict_5.pt\n",
        "    print(assign)\n",
        "    # 加載最新的模型檢查點\n",
        "    # torch.save 和 torch.load 來保存和加載模型的參數狀態字典\n",
        "    #ckpt = torch.load(os.path.join(MODEL_SAVE_PTH, latest))\n",
        "    ckpt = torch.load(os.path.join(MODEL_SAVE_PTH, assign)) #我要從第5個epoch開始跑看看\n",
        "    # print(ckpt)\n",
        "\n",
        "# 初始化開始的 epoch 為 0\n",
        "start_epoch = 0\n",
        "\n",
        "# 如果找到了模型檢查點\n",
        "if ckpt != None:\n",
        "    # 更新start_epoch 為檢查點中保存的epoch\n",
        "    start_epoch = ckpt['epoch']\n",
        "    # 加載檢查點中保存的模型狀態字典\n",
        "    summary_model.load_state_dict(ckpt['model_state_dict'])\n",
        "\n",
        "print(start_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soJ8wpvBkl1i",
        "outputId": "b8eb72ad-9b2d-4c41-95f7-e036b99d8760"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state_dict_1.pt\n",
            "state_dict_2.pt\n",
            "state_dict_1.pt\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGAEEAlK_eWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b4387b18-9869-4737-d92c-92508f25d00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 4/67 [00:07<02:04,  1.97s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8872951098ce>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 在訓練開始之前進行一次測試步驟，確定模型的初始性能\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 了解訓練資料集摘要與新聞之間的情緒關係\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 循環遍歷每一個訓練周期（epoch）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-bb949f1cdfad>\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# generate 是 transformers 庫中預訓練模型的內建方法\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# 輸出是一個包含 token IDs 的張量或列表。這些 token IDs 是模型生成的摘要。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0msummary_model_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_model_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 解碼生成的摘要文本\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1653\u001b[0m             )\n\u001b[1;32m   1654\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   1656\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, sequential, **model_kwargs)\u001b[0m\n\u001b[1;32m   3169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3170\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unchanged original behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3171\u001b[0;31m                 outputs = self(\n\u001b[0m\u001b[1;32m   3172\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3173\u001b[0m                     \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1726\u001b[0m                 )\n\u001b[1;32m   1727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1728\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1729\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1465\u001b[0m                 )\n\u001b[1;32m   1466\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1468\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;31m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    758\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 在訓練開始之前進行一次測試步驟，確定模型的初始性能\n",
        "# 了解訓練資料集摘要與新聞之間的情緒關係\n",
        "test_step()\n",
        "\n",
        "# 循環遍歷每一個訓練周期（epoch）\n",
        "# 從上次保存的 epoch 開始，進行訓練、驗證和測試。\n",
        "# start_epoch+1 表示從下一個 epoch 開始\n",
        "# start_epoch+num_train_epochs+1 確保總共訓練的 epoch 總數正確。\n",
        "for epoch in range(start_epoch+1, start_epoch+num_train_epochs+1):\n",
        "    train_step(epoch)  # 執行訓練步驟，傳入當前的 epoch 數，用於訓練模型\n",
        "    eval_step(epoch)   # 執行評估步驟，通常用於在驗證集上評估模型的性能\n",
        "    test_step()        # 執行測試步驟，用於在測試集上評估模型的性能\n",
        "\n",
        "    # 保存當前 epoch 的模型檢查點\n",
        "    torch.save({\n",
        "        'epoch': epoch,  # 存儲當前的 epoch 數\n",
        "        'model_state_dict': summary_model.state_dict()  # 存儲模型的權重和偏置\n",
        "    }, os.path.join(MODEL_SAVE_PTH, f'state_dict_{epoch}.pt'))  # 檢查點保存的文件名及路徑\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**有調整loss權重的**"
      ],
      "metadata": {
        "id": "3SOBN8u6SvTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_step()\n",
        "\n",
        "for epoch in range(start_epoch+1, start_epoch+num_train_epochs+1):\n",
        "    summary_loss_weight, sentiment_loss_weight = adjust_weights(prev_summary_loss, prev_sentiment_loss)\n",
        "    train_step(epoch)\n",
        "    eval_step(epoch)\n",
        "    test_step()\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': summary_model.state_dict()\n",
        "    }, os.path.join(MODEL_SAVE_PTH, f'state_dict_{epoch}.pt'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "AaJ3u3rIwPQ7",
        "outputId": "5271ebd1-689f-4729-83d1-09c2c9806c42"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 5/67 [00:08<01:34,  1.53s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            " 16%|█▋        | 11/67 [00:18<01:36,  1.72s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d2a37cc6c2f0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msummary_loss_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment_loss_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjust_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_summary_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_sentiment_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-bb949f1cdfad>\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# generate 是 transformers 庫中預訓練模型的內建方法\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# 輸出是一個包含 token IDs 的張量或列表。這些 token IDs 是模型生成的摘要。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0msummary_model_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_model_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 解碼生成的摘要文本\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1653\u001b[0m             )\n\u001b[1;32m   1654\u001b[0m             \u001b[0;31m# 13. run beam search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   1656\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, sequential, **model_kwargs)\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m             \u001b[0;31m# stateless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3225\u001b[0;31m             beam_outputs = beam_scorer.process(\n\u001b[0m\u001b[1;32m   3226\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m                 \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/beam_search.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index, decoder_prompt_len)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0;31m# once the beam for next step is full, don't add more tokens to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mbeam_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. 4.標準化損失和動態調整權重**"
      ],
      "metadata": {
        "id": "t5E-V6oNJblJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_sentiment_distribution(corpus):\n",
        "    sentiment_labels = []\n",
        "    for text in tqdm(corpus, desc=\"Processing corpus for sentiment distribution\"):\n",
        "        labels = get_sentiment_labels(sentiment_model, [text])\n",
        "        sentiment_labels.extend(labels.tolist())\n",
        "\n",
        "    sentiment_counts = Counter(sentiment_labels)\n",
        "    print(\"Sentiment distribution:\")\n",
        "    for label, count in sentiment_counts.items():\n",
        "        print(f\"{label}: {count}\")\n",
        "    return sentiment_counts\n",
        "\n",
        "# 在訓練開始之前進行一次測試步驟，確定模型的初始性能\n",
        "test_step()\n",
        "\n",
        "# 檢查訓練集中的情感標籤分布\n",
        "all_news = []\n",
        "for news, _ in train_dataloader:\n",
        "    all_news.extend(news)\n",
        "\n",
        "check_sentiment_distribution(all_news)\n",
        "\n",
        "# 循環遍歷每一個訓練周期（epoch）\n",
        "for epoch in range(start_epoch+1, start_epoch+num_train_epochs+1):\n",
        "    summary_loss_weight, sentiment_loss_weight = adjust_weights(avg_summary_loss, avg_sentiment_loss)\n",
        "    avg_summary_loss, avg_sentiment_loss = train_step(epoch, avg_summary_loss, avg_sentiment_loss)\n",
        "    eval_step(epoch)\n",
        "    test_step()\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': summary_model.state_dict()\n",
        "    }, os.path.join(MODEL_SAVE_PTH, f'state_dict_{epoch}.pt'))"
      ],
      "metadata": {
        "id": "hnF4WLr2JbBk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "b3da86cb-40c2-4766-dc01-73fcc67730e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 67/67 [01:37<00:00,  1.45s/it, Same Sentiment Rate: 0.328]\n",
            "Processing corpus for sentiment distribution: 100%|██████████| 1192/1192 [08:31<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment distribution:\n",
            "5: 403\n",
            "2: 587\n",
            "3: 65\n",
            "0: 92\n",
            "4: 23\n",
            "1: 20\n",
            "6: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 1] Training:   0%|          | 0/149 [00:05<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-b3a1fb57542d>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msummary_loss_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment_loss_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjust_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_summary_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_sentiment_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mavg_summary_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_sentiment_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_summary_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_sentiment_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0meval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-712d3c57fc32>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(epoch, avg_summary_loss, avg_sentiment_loss)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mnews_sentiment_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sentiment_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mgen_summaries_sentiment_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sentiment_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_summaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0msentiment_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_summaries_sentiment_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnews_sentiment_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-76d471230f8f>\u001b[0m in \u001b[0;36mget_sentiment_logits\u001b[0;34m(sentiment_model, corpus)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 新增檢查空文本的邏輯\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m               \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 獲取情感分析結果，返回所有分數。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m               \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 獲取每個情感標籤的分數作為 logits。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mcorpus_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 將 logits 轉換為張量並添加到列表\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unable to understand extra arguments {args}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"This example is {}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1232\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChunkPipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m             return next(\n\u001b[0m\u001b[1;32m   1235\u001b[0m                 iter(\n\u001b[1;32m   1236\u001b[0m                     self.get_iterator(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# Try to return next item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubiterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;31m# When a preprocess iterator ends, we can start lookig at the next item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, inputs, candidate_labels, hypothesis_template)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"This example is {}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0msequence_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcandidate_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/zero_shot_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sequences, labels, hypothesis_template)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You must include at least one label and at least one sequence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhypothesis_template\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(start_epoch+1, start_epoch+num_train_epochs+1):\n",
        "    summary_loss_weight, sentiment_loss_weight = adjust_weights(avg_summary_loss, avg_sentiment_loss)\n",
        "    avg_summary_loss, avg_sentiment_loss, same_sentiment_rate = train_step(epoch, avg_summary_loss, avg_sentiment_loss)\n",
        "    eval_step(epoch)\n",
        "    test_step()\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': summary_model.state_dict()\n",
        "    }, os.path.join(MODEL_SAVE_PTH, f'state_dict_{epoch}.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aicdi4xoa0PY",
        "outputId": "2e77910e-b31c-4c39-b072-2333691d2472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 1] Training: 100%|██████████| 250/250 [29:16<00:00,  7.02s/it, Batch Loss: 1.573619, Avg Loss: 1.262937]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Same Sentiment Rate: 0.453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 1] Validation: 100%|██████████| 13/13 [01:28<00:00,  6.84s/it, Batch Loss: 2.704040, Average Loss: 2.702139]\n",
            "100%|██████████| 112/112 [02:37<00:00,  1.40s/it, Same Sentiment Rate: 0.482]\n",
            "[Epoch 2] Training:  62%|██████▏   | 154/250 [17:49<10:49,  6.76s/it, Batch Loss: 9.476467, Avg Loss: 8.897231]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. 全部印出來**"
      ],
      "metadata": {
        "id": "UBC7-TLhk6lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 最後一區有用到 __測試集\n",
        "\n",
        "# 定義一個函數來在測試集上評估模型\n",
        "def test_step():\n",
        "    # 將模型設置為評估模式\n",
        "    summary_model.eval()\n",
        "\n",
        "    # 初始化一個列表來存儲測試結果\n",
        "    result = []\n",
        "\n",
        "    # 初始化一個列表來存儲測試結果\n",
        "    result_new = []\n",
        "\n",
        "    # 初始化進度條\n",
        "    pbar = tqdm(test_dataloader)\n",
        "\n",
        "    # 遍歷測試數據集中的每個批次\n",
        "    for index, (news, _) in enumerate(pbar):\n",
        "        # 使用 data_collator 函數和分詞器處理新聞文本，生成模型輸入\n",
        "        summary_model_inputs = data_collator(get_model_inputs(summary_tokenizer, news))['input_ids'].to(DEVICE)\n",
        "        # 使用模型生成摘要\n",
        "        summary_model_outputs = summary_model.generate(summary_model_inputs)\n",
        "        # 將生成的摘要轉換為文本\n",
        "        summarized_text = summary_tokenizer.batch_decode(summary_model_outputs, skip_special_tokens=True)\n",
        "\n",
        "        # 打印每個生成的摘要\n",
        "        print(f'news Text {index + 1}: {news}')\n",
        "\n",
        "        # 打印每個生成的摘要\n",
        "        print(f'Summarized Text {index + 1}: {summarized_text}')\n",
        "\n",
        "                # 將結果添加到結果列表中\n",
        "        result_new.append({\n",
        "            'News': news[0],\n",
        "            'Summarized Text': summarized_text,\n",
        "\n",
        "        })\n",
        "\n",
        "        # 使用情緒分析模型獲取新聞文本的情緒標籤\n",
        "        news_sentiment_label = get_sentiment_labels(sentiment_model, news)[0]\n",
        "        # 使用情緒分析模型獲取生成摘要的情緒標籤\n",
        "        summarized_sentiment_label = get_sentiment_labels(sentiment_model, summarized_text)[0]\n",
        "\n",
        "        # 比較新聞文本和生成摘要的情緒標籤是否相同，並將結果添加到結果列表中\n",
        "        # result是一個列表來存儲測試結果 如果摘要和原文標籤相同就append1，最後計算1總共的數量\n",
        "        result.append(1 if news_sentiment_label == summarized_sentiment_label else 0)\n",
        "\n",
        "        # 如果當前批次是最後一個，更新進度條的後綴信息，顯示相同情緒的比例\n",
        "        # 所以是1越多越好\n",
        "        # Same Sentiment Rate: 摘要和原文標籤相同/總共原文數量\n",
        "        if index == len(test_dataloader) - 1:\n",
        "            pbar.set_postfix_str('Same Sentiment Rate: {:.3f}'.format(result.count(1) / len(result)))\n",
        "        # 創建 pandas DataFrame 並顯示表格\n",
        "    results_df = pd.DataFrame(result_new)\n",
        "    print(results_df)\n",
        "\n",
        "    # 將結果匯出成 CSV 文件\n",
        "    results_df.to_csv('results.csv', index=False)"
      ],
      "metadata": {
        "id": "JJg00RpNk2Kn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOhx0JLnof8t",
        "outputId": "6ace3c59-3023-47a8-9f0a-fd84fb574608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/112 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 1: ['UK house prices dip in November  UK house prices dipped slightly in November, the Office of the Deputy Prime Minister (ODPM) has said.  The average house price fell marginally to Â£180,226, from Â£180,444 in October. Recent evidence has suggested that the UK housing market is slowing after interest rate increases, and economists forecast a drop in prices during 2005. But while the monthly figures may hint at a cooling of the market, annual house price inflation is still strong, up 13.8% in the year to November. Economists, however, forecast that ODPM figures are likely to show a weakening in annual house price growth in coming months. \"Overall, the housing market activity is slowing down and that is backed up by the mortgage lending and the mortgage approvals data,\" said Mark Miller, at HBOS Treasury Services. \"The ODPM data is a fairly lagging indicator.\"  The figures come after the Bank of England said the number of mortgages approved in the UK has fallen to the lowest level for nearly a decade. The Halifax, meanwhile, said last week that house prices increased by 1.1% in December - the first monthly rise since September.  The UK\\'s biggest mortgage lender said prices rose 15.1% over the whole of 2004, but by only 2.8% in the second half of the year. It is predicting a 2% fall in overall prices in 2005 as the market stabilises after large gains in recent years. The ODPM attributed the monthly fall of prices in November to a drop in the value of detached houses and flats. It said annual inflation rose between October and November because prices had fallen by 1.1% in the same period in 2003.  The ODPM data showed the average house price was Â£192,713 in England; Â£139,544 in Wales; Â£116,542 in Scotland, and Â£111,314 in Northern Ireland.  All areas saw a rise in annual house price inflation in November except for Northern Ireland and the West Midlands, where the rate was unchanged, the ODPM said. The North East showed the highest rate of inflation at 26.2%, followed by Yorkshire and the Humber on 21.7%, and the North West on 21.1%. The East Midlands, the West Midlands and the South West all had an annual inflation rate of more than 15%. In London, the area with the highest average house price at Â£262,825, annual inflation rose only slightly in November to 7.1% from 7% the previous month.']\n",
            "Summarized Text 1: ['UK house prices dipped slightly in November, Office of the Deputy Prime Minister says. Average house price fell marginally to Â£180,226, from Â £180,444 in October. But annual house price inflation is still strong, up 13.8% in the year to November.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/112 [00:01<02:42,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 2: ['LSE \\'sets date for takeover deal\\'  The London Stock Exchange (LSE) is planning to announce a preferred takeover by the end of the month, newspaper reports claim.  The Sunday Telegraph said the LSE\\'s plan was further evidence it wants to retain tight control over its destiny. Both Deutsche Boerse and rival Euronext held talks with the London market last week over a possible offer. A Â£1.3bn offer from Deutsche Boerse has already been rejected, while Euronext has said it will make an all cash bid. Speculation suggests that Paris-based Euronext has the facilities in place to make a bid of Â£1.4bn, while its German rival may up its bid to the Â£1.5bn mark. Neither has yet tabled a formal bid, but the LSE is expected to hold further talks with the two parties later this week. However, the Sunday Telegraph report added that there are signs that Deutsche Boerse chief executive Werner Seifert is becoming increasingly impatient with the LSE\\'s managed bid process.  Despite insisting he wants to agree a recommended deal with the LSE\\'s board, the newspaper suggested he may pull out of the process and put an offer directly to shareholders instead. The newspaper also claimed Mr Seifert was becoming \"increasingly frustrated\" with the pace of negotiations since Deutsche Boerse\\'s Â£1.3bn offer was rejected in mid-December, in particular the LSE\\'s decision to suspend talks over the Christmas period. Meanwhile, the German exchange\\'s offer has come under fire recently. Unions for Deutsche Boerse staff in Frankfurt have reportedly expressed fears that up to 300 jobs would be moved to London if the takeover is successful. Others claim it will weaken the city\\'s status as Europe\\'s financial centre, while German politicians are also said to be angry over the market operator\\'s promise to move its headquarters to London if a bid is successful. A further stumbling block is Deutsche Boerse\\'s control over its Clearstream unit, the clearing house that processes securities transactions. LSE shareholders fear it would create a monopoly situation, weakening the position of shareholders when negotiating lower transaction fees for share dealings. LSE and Euronext do not have control over their clearing and settlement operations, a situation which critics say is more transparent and competitive.']\n",
            "Summarized Text 2: [\"LSE'sets date for takeover deal' by the end of the month, reports claim. Both Deutsche Boerse and Euronext held talks with the London market last week. A Â£1.3bn offer from the German exchange has already been rejected. LSE shareholders fear it would create a monopoly situation.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/112 [00:02<02:40,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 3: ['Harinordoquy suffers France axe  Number eight Imanol Harinordoquy has been dropped from France\\'s squad for the Six Nations match with Ireland in Dublin on 12 March.  Harinordoquy was a second-half replacement in last Saturday\\'s 24-18 defeat to Wales. Bourgoin lock Pascal Pape, who has recovered from a sprained ankle, returns to the 22-man squad. Wing Cedric Heymans and Ludovic Valbon come in for Aurelien Rougerie and Jean-Philippe Grandclaude.  Rougerie hurt his chest against Wales while Grandclaude was a second-half replacement against both England and Wales. Valbon, capped in last June\\'s Tests against the United States and Canada, was a second half replacement in the win over Scotland.  France coach Bernard Laporte said Harinordoquy had been axed after a poor display last weekend. \"Imanol has been dropped from the squad because the least I can say is that he didn\\'t make a thundering comeback against Wales,\" said Laporte. \"We know the Ireland game will be fast and rough and we also want to be able to replace both locks during the game if needed, and Gregory Lamboley can also come on at number seven or eight. \"The Grand Slam is gone but we\\'ll go to Ireland to win. \"It will be a very exciting game because Ireland have three wins under their belt, have just defeated England and have their eyes set on a Grand Slam.\" France, who lost to Wales last week, must defeat the Irish to keep alive their hopes of retaining the Six Nations trophy. Ireland are unbeaten in this year\\'s tournament and have their sights set on a first Grand Slam since 1948.  Dimitri Yachvili (Biarritz), Pierre Mignoni (Clermont), Yann Delaigue (Castres), Frederic Michalak (Stade Toulousain), Damien Traille (Biarritz), Yannick Jauzion (Stade Toulousain), Ludovic Valbon (Biarritz), Christophe Dominici (Stade Francais), Cedric Heymans (Stade Toulousain), Julien Laharrague (Brive)  Sylvain Marconnet (Stade Francais), Nicolas Mas (Perpignan), Olivier Milloud (Bourgoin), Sebastien Bruno (Sale/ENG), William Servat (Stade Toulousain), Fabien Pelous (Stade Toulousain, capt), Jerome Thion (Biarritz), Pascal Pap&#233; (Bourgoin), Gregory Lamboley (Stade Toulousain), Serge Betsen (Biarritz), Julien Bonnaire (Bourgoin), Yannick Nyanga (B&#233;ziers)']\n",
            "Summarized Text 3: [\"Imanol Harinordoquy was a second-half replacement in last Saturday's 24-18 defeat to Wales. Bourgoin lock Pascal Pape, who has recovered from a sprained ankle, returns to the 22-man squad. Wing Cedric Heymans and Ludovic Valbon come in for Aurelien Rougerie and Jean-Philippe Grandclaude.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/112 [00:04<02:52,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 4: ['Barclays shares up on merger talk  Shares in UK banking group Barclays have risen on Monday following a weekend press report that it had held merger talks with US bank Wells Fargo.  A tie-up between Barclays and California-based Wells Fargo would create the world\\'s fourth biggest bank, valued at $180bn (Â£96bn). Barclays has declined to comment on the report in the Sunday Express, saying it does not respond to market speculation. The two banks reportedly held talks in October and November 2004.  Barclays shares were up 8 pence, or 1.3%, at 605 pence by late morning in London on Monday, making it the second biggest gainer in the FTSE 100 index. UK banking icon Barclays was founded more than 300 years ago; it has operations in over 60 countries and employs 76,200 staff worldwide. Its North American divisions focus on business banking, whereas Wells Fargo operates retail and business banking services from 6,000 branches. In 2003, Barclays reported a 20% rise in pre-tax profits to Â£3.8bn, and it has recently forecast similar gains in 2004, predicting that full year pre-tax profits would rise 18% to Â£4.5bn. Wells Fargo had net income of $6.2bn in its last financial year, a 9% increase on the previous year, and revenues of $28.4bn. Barclays was the focus of takeover speculation in August, when it was linked to Citigroup, though no bid has ever materialised. Stock market traders were sceptical that the latest reports heralded a deal. \"The chief executive would be abandoning his duty if he didn\\'t talk to rivals, but a deal doesn\\'t seem likely,\" Reuters quoted one trader as saying.']\n",
            "Summarized Text 4: [\"Barclays shares up on merger talk. Shares up 8 pence, or 1.3%, at 605 pence by late morning in London on Monday. A tie-up between Barclays and California-based Wells Fargo would create the world's fourth biggest bank, valued at $180bn.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 4/112 [00:05<02:37,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 5: ['Campaign \\'cold calls\\' questioned  Labour and the Conservatives are still telephoning the millions of people who have signed up to make sure they do not get marketing \"cold calls\".  The parties say they can stick to the rules by ensuring that their calls are not marketing - for instance by asking about people\\'s voting intentions. The Lib Dems are asking the watchdog overseeing the rules to stop the calls. The information commissioner\\'s office says surveys are allowed but people had to be told if personal data was kept. Telephone call centres are expected to be used as never before by all the three major parties in the run-up to the general election.  But seven million telephone numbers are on the Telephone Preference Service (TPS) lists, which ban unsolicited sales and marketing calls. Both schemes are run by the Direct Marketing Association and backed by EU directives on privacy and electronic communications.  The rules on marketing calls apply as much to politicians as to private sector companies. But that does not mean Labour and the Tories are not calling people signed up to the TPS. A Labour Party spokesman told the BBC News website the party avoided those on TPS lists when telephoning people about membership or fundraising. But that did not happen for \"voter identification\" calls. \"When we ask which party they will vote for, that is not marketing and we have very clear legal advice that it is not,\" he said. \"So it is not covered by the Telephone Preference Service.\"  He said the party always asked people if they would be happy to be contacted again and if they said no, they were not rung again. A Conservative spokeswoman said the party stuck to the rules when it rang TPS subscribers. She said: \"We do apply TPS but in line with the law. We would not do things that are not allowed in the law.\" Assistant information commissioner Phil Jones said it was classed as marketing if political parties telephoned people to encourage them to vote for them. But \"classic market research\", such as a poll of voter intentions, did not constitute direct marketing, he said. \"If a party is calling someone who is registered on TPS and records their voting intention with a view to using this information in the future, this should be clear to the voter concerned,\" said Mr Jones. \"If a party rings a person who is registered on TPS to ask about their voting intention and goes on to encourage that voter to support them, the party may well be in breach of the regulations. \"In summary, whether a party calling TPS registered voters to check their voting intentions will breach regulations will depend on the script used and whether the script is followed.\" Mr Jones said the watchdog received \"very few complaints\" on the issue.  Earlier, Lib Dem chairman Matthew Taylor wrote to the watchdog saying: \"The advice we have received on several previous occasions is that such phone calls are illegal.\" He says evidence from local Lib Dem parties around the country suggests there are \"significant\" numbers of such calls. \"I hope you can therefore take swift and efficient action to ensure that this ceases,\" he tells the commissioner. Mr Taylor argues there should be new guidelines so all parties can act in the same way if the watchdog believes the rules allow parties to ring TPS numbers about voting intentions and later urge those people to vote for them.']\n",
            "Summarized Text 5: [\"Seven million telephone numbers are on the Telephone Preference Service (TPS) List bans unsolicited sales and marketing calls. Lib Dems are asking watchdog overseeing the rules to stop the calls. Information commissioner's office says surveys are allowed but people had to be told if personal data was kept.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 5/112 [00:07<02:37,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 6: ['Wolves appoint Hoddle as manager  Glenn Hoddle has been unveiled as the new Wolves manager.  The ex-England coach has been given a six-month contract to succeed Dave Jones, who was sacked after the club\\'s poor start to the season. Wolves chairman Rick Hayward said: \"We\\'re delighted Glenn is here. He has a six-month contract so we can test each other out and see if it works.\" Hoddle, who will work alongside Stuart Gray, has been out of the game since he was sacked by Spurs in 2003. Gray, who has been caretaker manager, was assistant boss when Hoddle was manager at Southampton. \"I\\'m delighted to be here,\" said Hoddle.  \"I saw the massive potential that Wolves have got and their desire and amibition to get back into the Premiership parallels my ambitions. \"Stuart Gray has done a fantastic job as caretaker manager. We\\'ve worked together at Southampton and I\\'m delighted to be back with him.\" Wolves chief executive Jez Moxey defended the decision to give Hoddle a short-term contract. \"We hope it will work out for both parties and we extend it for the long term,\" he said. \"Most managers want a four-year contract and then expect it to be paid off if it doesn\\'t work out. \"For somebody of Glenn\\'s calibre to come in on a short-term contract and put his reputation on the line, it demonstrates his commitment and self-belief and the potential he thinks is here.\" Hayward revealed that Hoddle was one of the first to be approached after Jones\\' departure. \"He was not available at the time because he was looking at various other things,\" he explained. \"Five weeks later we\\'re back on track and this a tremendous opportunity for Wolves.\"  Hoddle began his managerial career as player-boss with Swindon before moving on to Chelsea and then taking up the England job. His spell in charge of the national side came to an end after the 1998 World Cup when he made controversial remarks about the disabled in a newspaper interview. The 47-year-old later returned to management with Southampton, where he again succeeded Jones - as he has now done at Wolves. He engineered an upturn in Saints\\' fortunes before being lured to White Hart Lane by Tottenham - the club where he made his name as a player. That relationship turned sour at the start of the last campaign and he left the London club early last season. Since then he has applied unsuccessfully for the post of France manager and had also been linked with a return to Southampton. Wolves are currently 17th in the Championship and have a home game against Millwall on Tuesday.']\n",
            "Summarized Text 6: ['Glenn Hoddle given a six-month contract to succeed Dave Jones. Wolves chairman Rick Hayward said: \"We\\'re delighted Glenn is here\" Wolves chief executive Jez Moxey defended the decision to give Hoddlle a short-term contract. Hiddle has been out of the game since he was sacked by Spurs in 2003.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 6/112 [00:08<02:38,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 7: ['Hantuchova in Dubai last eight  Daniela Hantuchova moved into the quarter-finals of the Dubai Open, after beating Elene Likhotseva of Russia 7-5 6-4, and now faces Serena Williams.  Australian Open champion Williams survived an early scare to beat Russia\\'s Elena Bovina 1-6 6-1 6-4. World number one Lindsay Davenport and Anastasia Myskina also progressed. Davenport defeated China\\'s Jie Zheng 6-2 7-5, while French Open champion Myskina sailed through after her opponent Marion Bartoli retired hurt. American Davenport will now face fellow former Wimbledon champion, Conchita Martinez of Spain, who ousted seventh-seeded Nathalie Dechy of France 6-1 6-2. Myskina will face eighth-seed Patty Schnyder from Switzerland, who defeated China\\'s Li Na 6-3 7-6 (10-8). The other quarter final pits wild card Sania Mirza of India against Jelena Jankovic of Serbia and Montenegro, who both won on Tuesday.  Before her meeting with Martinez, Davenport believes there is some room for improvement in her game. \"I started well and finished well, but played some so-so games in the middle,\" she said. Williams was also far from content. \"I don\\'t know what I was doing there,\" she said. \"It was really windy and I hadn\\'t played in the wind. All my shots were going out of here.\" But Hantuchova is in upbeat mood ahead of her clash with the younger Williams sister, who was handed a first-round bye. \"I feel I have an advantage (over Serena) because I have already played two matches on these courts,\" she said. \"It is a difficult court to play on. Very fast and sometimes you feel you have no control over the ball.\"']\n",
            "Summarized Text 7: ['Daniela Hantuchova will play Serena Williams in the quarter-finals of the Dubai Open. Australian Open champion Williams beat Elena Bovina 1-6 6-1 6-4. World number one Lindsay Davenport and Anastasia Myskina also progressed. The other quarter final pits wild card Sania Mirza of India against Jelena Jankovic.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 7/112 [00:10<02:38,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 8: ['BAA support ahead of court battle  UK airport operator BAA has reiterated its support for the government\\'s aviation expansion plans to airports throughout the country.  The comments come a day ahead of a High Court challenge by residents\\' groups and local councils to the government\\'s White Paper. The judicial review will centre on government plans for expansion at Heathrow, Stansted and Luton airports. BAA, which operates all three, said it was consulting with local communities. \"We are...consulting on voluntary compensation schemes which go beyond our statutory obligations,\" a BAA spokesman said.  Groups challenging the plans include Stop Stansted Expansion, Heathrow anti-noise campaigners HACAN Clearskies and the London boroughs of Hillingdon and Wandsworth. At Heathrow, Gatwick, Edinburgh and Glasgow airports, BAA launched a series of consultations on blight to properties from the proposed expansion in September 2004, which will close next week. The company is also offering to buy noise-hit properties for an index-linked, unblighted price. Among other measures, BAA has set up a homeowner support scheme for people living near Stansted, and has launched a special scheme for those close to the airport but far enough away not to be covered by the homeowner scheme. At Heathrow, BAA said it was working closely with all interested parties to see how the strict environmental, air quality and noise targets for a third runway can be met.  At Gatwick, the company has written to homes and business likely to be affected by any extra runway. Stop Stansted Expansion said the White Paper, published in December 2003, was \"fundamentally flawed\" and did not follow the proper consultation process. \"We do not underestimate the scale of the challenge before us because the courts have never before overturned a government White Paper,\" said Stop Stansted Expansion chairman Peter Sanders said. HACAN chairman John Stewart said: \"Almost exactly a year ago the government published its 30-year aviation White Paper with much fanfare. \"It hoped that would be the end of the debate and it could proceed with its plans for a massive expansion of aviation. \"Yet, a year later the protesters are still here, and stronger than ever. \" A judgement from Mr Justice Sullivan is expected early in February.']\n",
            "Summarized Text 8: [\"UK airport operator reiterates support for government's aviation expansion plans. Comments come a day ahead of a High Court challenge by residents' groups and local councils to the government's White Paper. The judicial review will centre on government plans for expansion at Heathrow, Stansted and Luton airports.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 8/112 [00:11<02:31,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 9: ['\\'My memories of Marley...\\'  To mark the 60th anniversary of the birth of reggae star Bob Marley, Rob Partridge - Marley\\'s former head of press at Island Records - remembers the man behind the legend.  Partridge worked with Marley from 1977 until the Jamaican musician\\'s death in 1981.  : \"I joined Island Records in 1977 and the first week I was there I worked on his show at the Rainbow Theatre. It was one of the last dates he did in London.\"  : The album Exodus came out in 1977 and that provided five hits and confirmed his global superstar status. \"By 1979 he was the biggest touring attraction in the world. I remember going to see dates in Milan and Turin and they were enormous concerts.\"  : Bob was one of the most mesmeric people I\\'ve ever had the privilege to work with. \"He must have had an iron will to succeed. Bob was a very driven individual. You realised from the start there was a manifest destiny within him that he believed in. He didn\\'t suffer fools gladly. At the risk of stating the obvious, he was an extraordinary song writer and his stage act was perhaps the greatest I\\'ve ever seen. I saw him many times.\"  : \"I recall in 1978 he came to the UK for Top of the Pops and a Daily Mirror journalist did a half-hour interview. It was interrupted to do a rehearsal. He came back into the dressing room to resume the interview but saw a World Cup match on TV.  \"He sat down in front of the TV and after 10 minutes it was obvious he wasn\\'t going to move. That was the end of it. The Mirror had a very truncated interview. \"The last time I saw him was in London in 1980. I arranged for him to play four days of football indoors in Fulham. \"Bob was a good player. We are talking about Jamaican-style football. He was an attacking midfield player. His team assembled wherever his gigs were. We played in Brazil against some World Cup-winning players.\"  : It was always a struggle for him to connect with Black America. Reggae did not correspond with disco in the 70s. But Bob in the 1990s became one of the great icons in America and the Third World. \"In 1991, ten years after his death, he sold more records than at any time during his life. \"We saw Black America taking Bob into their hearts for the first time.\"  : \"Bob, in worldwide terms, is the greatest music star there has ever been. If you went to Africa he would be recognised everywhere, in places John Lennon or Elvis wouldn\\'t be. \"No disrespect to the other artists but a case can be made for him as the greatest, the best and the most influential artist in popular music.\"  : Well 1981 was to be the year he toured Africa with Stevie Wonder. He had only performed in Zimbabwe and Guinea before. \"Of course the 1981 tour never happened, but the whole of Africa would have embraced him. We can\\'t speculate but he was at the height of his powers and just 36 years old. I had no sense his career was going to go downhill.\"  : \"Bob was endlessly optimistic about the way Africa would turn out. He realised that nothing was perfect but he had total belief in the power of mankind. \"I\\'m sure if he were alive today he would believe Africa would firstly become politically free and secondly be able to defeat the Aids epidemic.\"  : \"The final tune of his final album was Redemption Song - one of the most incredible classics of all time.\"']\n",
            "Summarized Text 9: [\"Rob Partridge worked with Marley from 1977 until the Jamaican musician's death in 1981. Partridge: 'He must have had an iron will to succeed. Bob was a very driven individual' 'His stage act was perhaps the greatest I've ever seen' 'In 1991, ten years after his death, he sold more records than at any time'\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 9/112 [00:13<02:40,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 10: ['Labour trio \\'had vote-rig factory\\'  Three Labour councillors in Birmingham were caught operating a \"vote-rigging factory\", an Election Court has heard.  Police found the trio handling unsealed postal ballots in a deserted warehouse in the city during a late-night raid in June 2004, the hearing was told. The votes were later counted towards that month\\'s English local elections. The men, elected to the Aston ward, deny collecting votes fraudulently. The judge presiding has indicated the whole postal voting system is under scrutiny. Deputy High Court Judge Richard Mawrey, QC told the hearing at the Birmingham and Midlands Institute the case could have potentially serious consequences for any forthcoming General Election.  The special Election Court, the first in living memory to hear allegations of vote-rigging, opened in Birmingham last month. The case against Muhammad Afzal, Mohammed Islam and Mohammed Kazi is being brought by local Liberal Democrat supporters. They claim the trio benefited from the widespread misuse of postal votes during the 10 June election. Ravi Sukul, counsel for the petitioners, accused the three men of being \"deeply involved\" in illegal practices. Witnesses saw them carrying several bags from their campaign office, which the men drove to a warehouse on an industrial estate off Birch Road East, the court was told.  The police were alerted and called to the premises. Mr Sukul said: \"When (the officers) arrived there, in the middle of the night, they saw a large room with a 10ft long table and six Asian men present. \"Hundreds of documents and unsealed envelopes were scattered all over the table.\" The police officers left the warehouse, but were later ordered back to seize the documents. \"When the officers left, all the envelopes and papers were scattered,\" Mr Sukul said.  \"(When they went) back to make the seizure, every one of these 275 yellow ballot papers were placed neatly in envelope A and sealed. The house was in order.\" Interrupting Mr Sukul in his opening, Mr Mawrey said: \"What you are saying is, these men were operating a vote-forging factory on an industrial estate.\" The court heard how documents were taken by police to the elections office next morning, where they were mixed in with other ballots. The case against the men follows a hearing into postal fraud allegations made against three other Birmingham councillors in the Bordesley Green ward, claims which are denied. Mr Mawrey is due to deliver a judgment in their case once the Aston petition has been heard. Mr Afzal, Mr Islam and Mr Kazi deny conspiring to commit election fraud to deceive the returning officer. The case continues.']\n",
            "Summarized Text 10: [\"Police found the trio handling unsealed postal ballots in a deserted warehouse. The votes were later counted towards that month's English local elections. The men, elected to the Aston ward, deny collecting votes fraudulently. The case could have potentially serious consequences for any forthcoming General Election.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 10/112 [00:15<02:33,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 11: ['US to rule on Yukos refuge call  Yukos has said a US bankruptcy court will decide whether to block Russia\\'s impending auction of its main production arm on Thursday.  The Russian oil firm has filed for bankruptcy protection in the US in an attempt to halt the forced sale. However, Judge Letitia Clark said the hearing would continue on Thursday when arguments in the case would be heard. Russian authorities are due to auction off Yuganskneftegas on 19 December to pay a huge tax bill sent to Yukos.  Russian prosecutors are forcing the sale of the firm\\'s most lucrative asset Yuganskneftegas to help pay a $27bn (Â£14bn) back tax bill, which they claim is owed by Yukos.  Filing for bankruptcy protection in the US was \"a last resort to preserve the rights of our shareholders, employees and customers,\" said Yukos chief executive Steven Theede. The company added it had opted to take action through American courts as US bankruptcy law gives worldwide jurisdiction over a debtor company\\'s property and because it was seeking a judiciary willing to protect the value of shareholders\\' investments. However, as the firm is based in Russia and has no significant US assets, lawyers are unsure of the outcome of the case. \"We are here to stop 60% of our body from being cut off on Sunday,\" Zack Clement, a lawyer for Yukos, told Judge Clark in an emergency hearing in Houston, Texas, on Wednesday. As well as the bid to get Chapter 11 bankruptcy - which protects firms from creditors, allowing them to continue trading as they restructure their finances - the group also made a claim for damages against the Russian government. Yukos asked the Houston court to order Russia to arbitration so that it can press claims for billions of dollars in damages over a \"campaign of illegal, discriminatory and disproportionate\" tax claims. Mr Clement said that under Russian law, the Russian government was obliged to enter into arbitration as set out in international law.  He added that the opening bid for the firm\\'s Yuganskneftgas unit was $8bn - less than half of the $20bn that Yukos advisers say it is worth. \"We believe the only significant bidder at the auction on Sunday is Gazprom,\" he said, referring to Russia\\'s natural gas giant. Yukos maintains that the forced auction is illegal and \"will cause the company to suffer immediate and irreparable harm.\" Many commentators believe the Russian government\\'s aggressive pursuit of Yukos is a politically-motivated response to the political ambitions of its former chief executive, Mikhail Khodorkovsky. Mr Khodorkovsky, who had funded liberal opposition groups, was arrested in October last year on fraud and tax evasion charges and is still in jail Analysts believe that if its production unit is auctioned off, it is likely to be bought up by a government-backed firm, like Gazprom, effectively bringing a large chunk of Russia\\'s lucrative oil and gas industry back under state control.']\n",
            "Summarized Text 11: [\"Yukos has filed for bankruptcy protection in the US in an attempt to halt the forced sale of its main production arm. Russian authorities are due to auction off Yuganskneftegas on 19 December to pay a huge tax bill sent to Yukos. Russian prosecutors are forcing the sale of the firm's most lucrative asset to help pay a $27bn (Â£14bn) back tax bill.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 11/112 [00:16<02:39,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 12: [\"Ray DVD beats box office takings  Oscar-nominated film biopic Ray has surpassed its US box office takings with a combined tally of $80m (Â£43m) from DVD and video sales and rentals.  Ray's success on DVD outstripped its $74m (Â£40m) US box office total, earning more than $40m (Â£22m) on the first day of the DVD's release alone. Ray has been nominated in six Oscar categories including best film and best actor for Jamie Foxx. The film recounts the life of blues singer Ray Charles, who died in 2004. In its first week on home entertainment release the film was the number one selling DVD, with the limited edition version coming in at number 11. Sony horror film The Grudge, starring Michelle Gellar, was the US' second best-selling DVD, with Jennifer Lopez and Richard Gere's romantic comedy Shall We Dance? at number three. Foxx's critically acclaimed performance as Ray has already earned him a Screen Actors Guild Award for best actor, as well as a prestigious Golden Globe. Ray director Taylor Hackford, responsible for the classic 1982 film An Officer and a Gentleman, has also received an Oscar nomination in the best director category. The film's three other Oscar nominations are for costume, film editing and sound mixing.\"]\n",
            "Summarized Text 12: ['Ray DVD beats box office takings with a combined tally of $80m (Â£43m) The film has been nominated in six Oscar categories including best film and best actor for Jamie Foxx. In its first week on home entertainment release the film was the number one selling DVD.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 12/112 [00:17<02:25,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 13: ['Adriano\\'s Chelsea link rejected  Adriano\\'s agent Gilmar Rinaldi has insisted that he has had no contact with Chelsea over the striker.  Chelsea were reported to have made inquiries about Inter Milan\\'s 22-year-old Brazilian star. Rinaldi told BBC Sport from Rio de Janeiro: \"I can assure you that Chelsea have had no dealings whatsoever with either me or Adriano. \"Parma and Real Madrid are interested but there\\'s nothing new there. Their interest has been known for some time.\" Adriano has scored 14 goals in 20 Serie A appearances this season. And Chelsea boss Jose Mourinho had claimed that he was in Milan talking to Adriano on the day he is alleged to have held a clandestine meeting with Arsenal defender Ashley Cole. Mourinho said he was \"just practising my Portuguese with him because I don\\'t need strikers\". Rinaldi told BBC Sport: \"I have to say that nobody from Chelsea or any other London club has contacted me. \"If they want to, that\\'s fine. I can tell them what the situation is. \"If Chelsea are interested then they must make an offer.\" Inter are reported to have slapped a price tag in the region of Â£40m on the head of Adriano, who joined them just over a year ago from Parma. Real Madrid view him as a natural replacement for compatriot Ronaldo. But Rinaldi said: \"I cannot give you a price that Inter would accept for Adriano. That\\'s something that would have to be negotiated between the interested clubs.\"']\n",
            "Summarized Text 13: [\"Chelsea were reported to have made inquiries about Inter Milan's Adriano. Adriano's agent Gilmar Rinaldi has insisted that he has had no contact with Chelsea over the striker. Parma and Real Madrid are also said to be interested in the 22-year-old.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 13/112 [00:19<02:16,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 14: ['Weak end-of-year sales hit Next  Next has said its annual profit will be Â£5m lower than previously expected because its end-of-year clearance sale has proved disappointing.  \"Clearance rates in our end-of-season sale have been below our expectations,\" the company said. The High Street retailer said it now expected to report annual profits of between Â£415m and Â£425m ($779m-798m). Next\\'s shares fell more than 3% following the release of the trading statement.  Next chief executive Simon Wolfson admitted that festive sales were \"below where we would expect a normal Christmas to be\", but said sales should still top analyst expectations.  Among areas where Next could have done better, Mr Wolfson said menswear ranges were \"a little bit too similar to the previous year\". Mr Wolfson also said that disappointing pre-Christmas sales were \"more to do with the fact that we went in with too much stock rather than (the fact that) demand wasn\\'t there for the stock\". Next\\'s like-for-like store sales in the five months from 3 August to 24 December were up 2.9% on a year earlier. This figure is for existing Next stores, which were unaffected by new Next store openings. Like-for-like sales growth at the 49 Next stores directly affected by new store openings in their locality was 0.5%.  Overall sales across both its retail and mail order divisions were up 12.4%, Next said. Its Next Directory mail order division saw sales rise 13.4% during the five-month period. \"In terms of all the worries about their trading pre-Christmas, it\\'s a result,\" said Nick Bubb, an analyst at Evolution Securities. \"Profits of around Â£420m would be well within the comfort zone.\" However, one dealer, who asked not to be named, told Reuters the seasonal sales performance was \"not what people had hoped for\". \"Christmas has been tough for the whole sector, and this is one of the best retailers,\" he said. Next\\'s trading statement comes a day after House of Fraser and Woolworths disappointed investors with their figures.']\n",
            "Summarized Text 14: ['Next\\'s shares fell more than 3% following the release of the trading statement. Chief executive Simon Wolfson admitted festive sales were \"below where we would expect a normal Christmas to be\" Like-for-like store sales in the five months from 3 August to 24 December were up 2.9% on a year earlier.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 14/112 [00:20<02:16,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 15: [\"Howl helps boost Japan's cinemas  Japan's box office received a 3.8% boost last year, with ticket sales worth 211bn yen (Â£1.08bn).  The surge was led by animated movie Howl's Moving Castle, which took 20bn yen (Â£102m) to become the biggest film in Japan in 2004. It is expected to match the 30.7bn yen (Â£157m) record of Hayao Miyazaki's previous film Spirited Away. Japan Motion Picture Producers figures showed that 170 million cinema admissions were made in Japan in 2004. The Last Samurai, starring Tom Cruise, was the biggest foreign movie hit in Japan last year, taking 13.8bn yen (Â£70.7m).  It was followed by Harry Potter and the Prisoner of Azkaban, Finding Nemo and The Lord of the Rings: The Return of the King. The second highest-grossing Japanese film was romantic drama Crying Out Love in the Centre of the World, followed by Be With You and Pocket Monsters Advanced Generation. Japanese films accounted for 37.5% of Japan's box office total last year, with foreign films taking the remaining 62.5%. This represented a 4.5% gain for the proportion of Japanese films in 2004 compared to 2003. The number of Japanese films released rose to 310 in 2004 from 287 the previous year. Sales of movies on DVD and video amounted to 497bn yen (Â£2.54bn) for the year.\"]\n",
            "Summarized Text 15: [\"Japan's box office received a 3.8% boost last year, with ticket sales worth 211bn yen (Â£1.08bn) The surge was led by animated movie Howl's Moving Castle. The Last Samurai, starring Tom Cruise, was the biggest foreign movie hit in Japan last year.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 15/112 [00:21<02:09,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 16: [\"Ailing EuroDisney vows turnaround  EuroDisney, the European home of Mickey Mouse and friends, has said it will sell 253m euros (Â£175m; $328m) of new shares as it looks to avoid insolvency.  The sale is the last part of a plan to restructure 2.4bn euros-worth of debts. Despite struggling since it was opened in 1992, EuroDisney has recently made progress in turning its business around and ticket sales have picked up. However, analysts still question whether it attracts enough visitors to stay open, even with the restructuring.  EuroDisney remains Europe's largest single tourist attraction, attracting some 12.4 million visitors annually. A new attraction - Walt Disney Studios - has recently opened its site near Paris. The company's currently traded stock tumbled in Paris on the latest news, shedding 15% to 22 euro cents. EuroDisney will sell the new shares priced at 9 euros cents each. The US Disney Corporation and Saudi Arabian prince Al-Walid bin Talal, the firm's two main shareholders, will buy the new stock. The restructuring deal is the second in the firm's troubled financial history; its finances were first reorganised in 1994.\"]\n",
            "Summarized Text 16: [\"EuroDisney will sell 253m euros (Â£175m; $328m) of new shares. The sale is the last part of a plan to restructure 2.4bn euros-worth of debts. The US Disney Corporation and Saudi Arabian prince Al-Walid bin Talal, the firm's two main shareholders, will buy the new stock.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 16/112 [00:23<02:07,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 17: ['Microsoft launches its own search  Microsoft has unveiled the finished version of its home-grown search engine.  The now formally launched MSN search site takes the training wheels off the test version unveiled in November 2003. The revamped engine indexes more pages than before, can give direct answers to factual questions, and features tools to help people create detailed queries. Microsoft faces challenges establishing itself as a serious search site because of the intense competition for queries.  Google still reigns supreme as the site people turn to most often when they go online to answer a query, keep up with news or search for images. But in the last year Google has faced greater competition than ever for users as old rivals, such as Yahoo and Microsoft, and new entrants such as Amazon and Blinkx, try to grab some of the searching audience for themselves. This renewed interest has come about because of the realisation that many of the things people do online begin with a search for information - be it for a particular web page, recipe, book, gadget, news story, image or anything else. Microsoft is keen to make its home-grown search engine a significant rival to Google. To generate its corpus of data, Microsoft has indexed 5 billion webpages and claims to update its document index every two days - more often than rivals. The Microsoft search engine can also answer specific queries directly rather than send people to a page that might contain the answer.  For its direct answer feature, Microsoft is calling on its Encarta encyclopaedia to provide answers to questions about definitions, facts, calculations, conversions and solutions to equations. Tony Macklin, director of product at Ask Jeeves, pointed out that its search engine has been answering specific queries this way since April 2003. \"The major search providers have moved beyond delivering only algorithmic search, so in many ways Microsoft is following the market,\" he said. Tools sitting alongside the MSN search engine allow users to refine results to specific websites, countries, regions or languages. Microsoft is also using so-called \"graphic equalisers\" that let people adjust the relevance of terms to get results that are more up-to-date or more popular. The company said that user feedback from earlier test versions had been used to refine the workings of the finished system. The test, or beta, version of the MSN search engine unveiled in November had a few teething troubles. On its first day many new users keen to try it were greeted with a page that said the site had been overwhelmed.']\n",
            "Summarized Text 17: ['Microsoft unveils finished version of its home-grown search engine. The revamped engine indexes more pages than before. Can give direct answers to factual questions, and features tools to help people create detailed queries. Google still reigns supreme as the site people turn to most often when they go online to answer a query.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 17/112 [00:24<02:09,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 18: ['Rock group Korn\\'s guitarist quits  The guitarist with US rock band Korn has quit the music business, saying he made the decision after experiencing a religious awakening.  Brian \\'Head\\' Welch told a radio station in California that his bandmates respected his decision to leave. A replacement guitarist has yet to be named by Korn, who are currently at work on their eighth studio album. Welch added that he would appear at a church in Bakersfield to explain how he \"got to this place in life\". The remaining members of Korn, who are known for their hardcore brand of rock, said they hoped Welch \"finds the happiness he is looking for\".  The 34-year-old made reference to the band\\'s aggressive brand of music and its young fans in his parting statement. \"Anger is a good thing, and if kids want to listen to Korn, good, but there\\'s happiness after the anger,\" he told his local radio station in Bakersfield. \"I\\'m going to show it through my actions, how much I love my fans,\" added Welch. Korn have enjoyed a moderate degree of chart success in the UK, with 10 singles breaking into the Top 40. Their best performance to date in the UK has been 2002\\'s Here To Stay, which reached number 12, while their album Untouchables, released in the same year, made it to number four.']\n",
            "Summarized Text 18: [\"Brian 'Head' Welch says he made the decision after experiencing a religious awakening. The 34-year-old made reference to the band's aggressive brand of music and its young fans in his parting statement. A replacement guitarist has yet to be named by Korn, who are currently at work on their eighth studio album.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 18/112 [00:25<02:05,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 19: [\"Troubled Marsh under SEC scrutiny  The US stock market regulator is investigating troubled insurance broker Marsh & McLennan's shareholder transactions, the firm has said.  The Securities and Exchange Commission has asked for information about transactions involving holders of 5% or more of the firm's shares. Marsh has said it is co-operating fully with the SEC investigation. Marsh is also the focus of an inquiry the New York attorney-general into whether insurers rigged the market. Since that inquiry was launched in October, Marsh has replaced its chief executive and held a boardroom shake-out to meet criticism by lessening the number of company executives on the board. Prosecutors allege that Marsh - the world's biggest insurance broker - and other US insurance firms may have fixed bids for corporate cover. This is the issue at the heart of the inquiry by New York's top law officer, Eliot Spitzer, and a separate prosecution of five insurers by the State of California. The SEC's investigation into so-called related party transactions includes dealings in the Trident Funds, managed by MMC Capital, the company's private equity firm. Marsh's new chief executive, Michael Cherkasky, is trying to negotiate a settlement with Mr Spitzer. Mr Spitzer has built up a reputation as a fierce critic and campaigner against corporate America's misdeeds.  The uncertainty unleashed by the scandal has prompted three credit rating agencies - Standard & Poor's, Moody's and Fitch - to downgrade Marsh in recent weeks. According to the Financial Times, insurance analysts are now questioning whether Marsh will be able to maintain its strong record of earning growth as they draw up forecasts for the first quarter of next year. Doubts also exist over how much the company may have to pay regulators and lawyers to put the scandal behind.\"]\n",
            "Summarized Text 19: [\"SEC has asked for information about transactions involving 5% or more of firm's shares. Marsh is also the focus of an inquiry the New York attorney-general into whether insurers rigged the market. Since that inquiry was launched in October, Marsh has replaced its chief executive and held a boardroom shake-out.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 19/112 [00:27<02:03,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 20: ['Campaigners attack MTV \\'sleaze\\'  MTV has been criticised for \"incessant sleaze\" by television indecency campaigners in the US.  The Parents Television Council (PTC), which monitors violence and sex on TV, said the cable music channel offered the \"cheapest form\" of programming. The group is at the forefront of a vociferous campaign to clean up American television. But a spokeswoman for MTV said it was \"unfair and inaccurate\" to single out MTV for criticism.  The PTC monitored MTV\\'s output for 171 hours from 20 March to 27 March 2004, during the channel\\'s Spring Break coverage. In its report - MTV Smut Peddlers: Targeting Kids with Sex, Drugs and Alcohol - the PTC said it witnessed 3,056 flashes of nudity or sexual situations and 2,881 verbal references to sex. Brent Bozell, PTC president and conservative activist said: \"MTV is blatantly selling raunchy sex to kids. \"Compared to broadcast television programmes aimed at adults, MTV\\'s programming contains substantially more sex, foul language and violence - and MTV\\'s shows are aimed at children as young as 12. \"There\\'s no question that TV influences the attitudes and perceptions of young viewers, and MTV is deliberately marketing its raunch to millions of innocent children.\"  The watchdog decided to look at MTV\\'s programmes after Janet Jackson\\'s infamous \"wardrobe malfunction\" at last year\\'s Super Bowl. The breast-baring incident generated 500,000 complaints and CBS - which is owned by the same parent company as MTV - was quick to apologise. MTV spokeswoman Jeannie Kedas said the network follows the same standards as broadcasters and reflects the culture and what its viewers are interested in. \"It\\'s unfair and inaccurate to paint MTV with that brush of irresponsibility,\" she said. \"We think it\\'s underestimating young people\\'s intellect and level of sophistication.\" Ms Kedas also highlighted the fact MTV won an award in 2004 for the Fight for Your Rights series that focused on issues such as sexual health and tolerance.']\n",
            "Summarized Text 20: ['Parents Television Council monitors violence and sex on TV. Group is at forefront of campaign to clean up American television. Spokeswoman for MTV says it is \"unfair and inaccurate\" to single out MTV for criticism. PTC monitored MTV\\'s output for 171 hours from 20 March to 27 March 2004.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 20/112 [00:28<02:02,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 21: ['Australia rates at four year high  Australia is raising its benchmark interest rate to its highest level in four years despite signs of a slowdown in the country\\'s economy.  The Reserve Bank of Australia lifted interest rates 0.25% to 5.5%, their first upwards move in more than a year. However, shortly after the Bank made its decision, new figures showed a fall in economic growth in the last quarter. The Bank said it had acted to curb inflation but the move was criticised by some analysts.  The rate hike was the first since December 2003 and had been well-flagged in advance. However, opposition parties and some analysts said the move was ill-timed given data showing the Australian economy grew just 0.1% between October and December and 1.5% on an annual basis.  The figures, representing a decline from the 0.2% growth in GDP seen between July and September, were below market expectations. Consumer spending remains strong, however, and the Bank is concerned about growing inflationary pressures. \"Over recent months it has become increasingly clear that remaining spare capacity in the labour and goods markets is becoming rather limited,\" said Ian Macfarlane, Governor of the Reserve Bank.  At 2.6%, inflation remains within the Bank\\'s 2-3% target range. However, exports declined in the second half of 2004, fuelling a rise in the country\\'s current account deficit - the difference in the value of imports compared to exports - to a record Australian dollar 29.4bn. The Australian government said the economy remained strong with unemployment at a near 30 year low. \"The economy has been strong and it is properly moderating but it doesn\\'t look to me like it\\'s slowing in any unreasonable way,\" said Treasurer Peter Costello. Stock markets had factored in the likelihood of a rate rise but analysts still expressed concern about the strength of the economy. \"That 1.5% annual growth rate is the lowest we have seen since the post-election slump we saw back in 2000-1,\" said Michael Blythe, chief economist at the Commonwealth Bank of Australia. \"This suggests the economy really did slow very sharply in the second half of 2004.\"']\n",
            "Summarized Text 21: ['The Reserve Bank of Australia lifted interest rates 0.25% to 5.5%. The Bank said it had acted to curb inflation but the move was criticised by some analysts. The Australian economy grew just 0.1% between October and December and 1.5% on an annual basis. Consumer spending remains strong, but the Bank is concerned about growing inflation.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 21/112 [00:29<02:06,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 22: ['Almagro continues Spanish surge  Unseeded Nicolas Almagro became the fifth Spaniard to reach the last eight at the Buenos Aires Open, ousting eighth seed Mariano Zabaleta.  He showed admirable resolve to win a rain-affected match 6-7 6-4 6-4. Compatriot and seventh seed Rafael Nadal also reached the last eight, beating Italian Potito Starace 6-1 6-3. Nadal, playing in the outdoor clay event for the first time, hit some powerful forehands to oust Starace in a match delayed over an hour by rain. \"It\\'s always a problem to have to stop for rain but one gets used to it,\" said Spanish teenager Nadal. \"Luckily, I was able to keep my pace going throughout the match.\" He will now play Gaston Gaudio, who beat unseeded Brazilian Flavio Saretta 6-3 6-2 in the day\\'s late match.']\n",
            "Summarized Text 22: ['Unseeded Nicolas Almagro becomes the fifth Spaniard to reach the last eight at the Buenos Aires Open. Compatriot and seventh seed Rafael Nadal also reached the lastEight, beating Italian Potito Starace 6-1 6-3. He will now play Gaston Gaudio, who beat unseeded Brazilian Flavio Saretta.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 22/112 [00:31<02:04,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 23: ['India power shares jump on debut  Shares in India\\'s largest power producer, National Thermal Power Corp (NTPC) have risen 13% on their stock market debut.  The government\\'s partial sell-off of NTPC is part of a controversial programme to privatise state-run firms. The 865 million share offer, a mix of new shares and sales by the government, raised 54bn rupees($1.2bn). It was India\\'s second $1bn stock debut in three months, coming after the flotation by software firm Tata. The share offer was eleven times oversubscribed. \"It is a good investment bet,\" said Suhas Naik, an investment analyst from ING Mutual Fund. \"Power needs in India are set to rise and NTPC will benefit from that.\" Analysts say the success of the NTPC flotation would encourage the government to reduce stakes in more power companies. NTPC has said it will use the money from the share sale to feed the growing needs of the country\\'s energy-starved economy. The firm is the largest utility company in India, and the sixth largest power producer in the world.']\n",
            "Summarized Text 23: [\"Shares in India's largest power producer, National Thermal Power Corp (NTPC) rise 13%. Government's partial sell-off of NTPC is part of a controversial programme to privatise state-run firms. The 865 million share offer raised 54bn rupees ($1.2bn)\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 23/112 [00:32<01:56,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 24: ['Stars pay tribute to actor Davis  Hollywood stars including Spike Lee, Burt Reynolds and Oscar nominee Alan Alda have paid tribute to actor Ossie Davis at a funeral in New York.  Veteran star Ossie Davis, a well-known civil rights activist, died in Miami at the age of 87 on 4 February 2005. Friends and family, including actress Ruby Dee his wife of 56 years, gathered at the Riverside Church on Saturday. Also present at the service was former US president Bill Clinton and singer Harry Belafonte, who gave the eulogy. \"He would have been a very good president of the United States,\" said Mr Clinton. \"Like most of you here, he gave more to me than I gave to him.\"  The 87-year-old was found dead last weekend in his hotel room in Florida, where he was making a film. Police said that he appeared to have died of natural causes. Davis made his acting debut in 1950 in No Way Out starring Sidney Poiter. He frequently collaborated with director Spike Lee, starring in seven Lee films including Jungle Fever, Do The Right Thing and Malcolm X. Attallah Shabazz, the daughter of activist Malcolm X, recalled the famous eulogy delivered by Davis at her father\\'s funeral. \"Harlem has come to bid farewell to one of its finest hopes,\" she said, quoting the man she knew as Uncle Ossie. \"Ditto.\" \"Ossie was my hero, and he still is,\" said Aviator star Alan Alda, a family friend for over forty years. \"Ossie was a thing of beauty.\"  \"I want so badly someday to have his dignity - a little of it anyway,\" added Burt Reynolds, Davis\\'s co-star in the 90s TV comedy Evening Shade. Before the midday funeral, scores of Harlem residents formed a queue outside the church to pay their respects to Davis. \"It is hard to fathom that we will no longer be able to call on his wisdom, his humour, his loyalty and his moral strength to guide us in the choices that are yet to be made and the battles that are yet to be fought,\" said Belafonte, himself an ardent civil rights activist who had been friends with Davis for over 60 years. \"But how fortunate we were to have him as long as we did.\"']\n",
            "Summarized Text 24: ['Veteran star Ossie Davis, a well-known civil rights activist, died in Miami at the age of 87 on 4 February 2005. Friends and family, including actress Ruby Dee his wife of 56 years, gathered at the Riverside Church on Saturday. Also present at the service was former US president Bill Clinton and singer Harry Belafonte.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 24/112 [00:33<02:00,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 25: [\"Buyers snap up Jet Airways' shares  Investors have snapped up shares in Jet Airways, India's biggest airline, following the launch of its much anticipated initial public offer (IPO).  The IPO for 17.3 million shares was fully sold within 10 minutes of opening, on Friday. Analysts expect Jet to raise at least 16.4bn rupees ($375m; Â£198m) from the offering. Interest in Jet's IPO has been fuelled by hopes for robust growth in India's air travel market.  The share offer, representing about 20% of Jet's equity, was oversubscribed, news agency Reuters reported. Jet, which was founded by London-based travel agent Naresh Goyal, plans to use the cash to buy new planes and cut its debt. The company has grown rapidly since it launched operations in 1993, overtaking state-owned flag carrier Indian Airlines. However, it faces stiff competition from rivals and low-cost carriers. Jet's IPO is the first in a series of expected share offers from Indian companies this year, as they move to raise funds to help them do business in a rapidly-growing economy.\"]\n",
            "Summarized Text 25: ['The IPO for 17.3 million shares was fully sold within 10 minutes of opening. Analysts expect Jet to raise at least 16.4bn rupees ($375m; Â£198m) from the offering. Jet, founded by London-based travel agent Naresh Goyal, plans to use cash to buy new planes and cut its debt.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 25/112 [00:35<01:57,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 26: ['Dibaba breaks 5,000m world record  Ethiopia\\'s Tirunesh Dibaba set a new world record in winning the women\\'s 5,000m at the Boston Indoor Games.  Dibaba won in 14 minutes 32.93 seconds to erase the previous world indoor mark of 14:39.29 set by another Ethiopian, Berhane Adera, in Stuttgart last year. But compatriot Kenenisa Bekele\\'s record hopes were dashed when he miscounted his laps in the men\\'s 3,000m and staged his sprint finish a lap too soon. Ireland\\'s Alistair Cragg won in 7:39.89 as Bekele battled to second in 7:41.42. \"I didn\\'t want to sit back and get out-kicked,\" said Cragg. \"So I kept on the pace. The plan was to go with 500m to go no matter what, but when Bekele made the mistake that was it. The race was mine.\" Sweden\\'s Carolina Kluft, the Olympic heptathlon champion, and Slovenia\\'s Jolanda Ceplak had winning performances, too. Kluft took the long jump at 6.63m, while Ceplak easily won the women\\'s 800m in 2:01.52.']\n",
            "Summarized Text 26: [\"Tirunesh Dibaba wins women's 5,000m at Boston Indoor Games. Ethiopian breaks previous world indoor mark of 14:39.29 set by Berhane Adera. Kenenisa Bekele's record hopes dashed when he miscounted his laps.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 26/112 [00:36<01:54,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 27: ['Glasgow hosts tsunami benefit gig  The top names in Scottish music are taking part in a benefit concert in aid of the victims of the Asian tsunami.  All 10,000 tickets for Saturday\\'s concert, featuring Franz Ferdinand, Belle and Sebastian and Travis, at Glasgow\\'s SECC sold out in 36 hours. Mull Historical Society, Deacon Blue, Idlewild, Texas, Mogwai and Teenage Fanclub are among the other acts performing at the concert. Organisers hope to raise at least Â£250,000 from the show.  It follows a Cardiff gig starring Eric Clapton, Keane and Jools Holland, which raised more than Â£1.25m. And it is taking place on the same night as a tsunami benefit show in Bristol, which will see Massive Attack and Portishead share a stage for the first time. Colin MacIntyre, of Mull Historical Society, was playing another gig on the same day but said he was determined to make the Glasgow benefit. He said: \"I think we were all affected by seeing the reports coming from the Far East. \"We all know somebody who was there, but more than that it was that we had never seen a wave of destruction, a natural disaster, like this in my generation. \"I\\'m lucky as an artist to be able to perform at something like this.\"']\n",
            "Summarized Text 27: [\"All 10,000 tickets for Saturday's concert sold out in 36 hours. It follows a Cardiff gig starring Eric Clapton, Keane and Jools Holland. Mull Historical Society, Deacon Blue, Idlewild, Texas, Mogwai and Teenage Fanclub are among the other acts performing.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 27/112 [00:37<01:49,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 28: ['Hewitt fights back to reach final  Lleyton Hewitt kept his dream of an Australian Open title alive with a four-set win over Andy Roddick in Friday\\'s second semi-final.  The home favourite will face Marat Safin in Sunday\\'s final after coming through 3-6 7-6 (7-3) 7-6 (7-4) 6-1. Hewitt fought back from a set down and trailed in both tie-breaks but would not be denied, thrilling the Melbourne crowd with a typically battling effort. He is aiming to be the first Australian winner since Mark Edmondson in 1976. Hewitt is the first Australian to make the final since Pat Cash lost to Mats Wilander in 1988, but faces a huge challenge against Safin - the conqueror of Roger Federer. After needing five sets in his last two matches there was reason to think Hewitt might struggle for fitness. He certainly made a sluggish start, dropping his opening service game, and Roddick dominated with his huge serve as he took the first set.  After 12 tense games in the second, the key moment came when Hewitt raised his game in the tie-break to overturn an early mini-break. That energised the crowd but Roddick was not finished and raced 4-1 clear in the crucial third before Hewitt pegged him back and forced another tie-break. Again Roddick broke first and again Hewitt fought back, taking the lead with a superb backhand pass.  The Australian was not to be denied and a disheartened Roddick made little impact in the fourth set as Hewitt raced to victory, sending the Melbourne crowd wild and ensuring the final will be a huge occasion. \"It\\'s awesome,\" said Hewitt. \"I started preparing for this tournament nine months ago. \"I\\'ve done a lot of hard yards to get here. \"I\\'ve always said I\\'d do anything to get in the first night final at the Australian Open. Now I\\'ve got my chance.\" Roddick was furious with himself for failing to take advantage of leads in both tie-breaks. \"I\\'m usually pretty money in those,\" said Roddick. \"Either one of those would have given me a distinct advantage. \"I\\'m mad, I felt I was in there with a shot. He put himself in position to win big points. I donated a little more than I would have wanted.\" And the American played down the influence of one spectator who appeared to contribute to a double fault by shouting during Rodick\\'s service action. \"It just took one jackass to shout out,\" said Roddick, adding that the crowd overall was \"very respectful\".']\n",
            "Summarized Text 28: [\"Lleyton Hewitt will face Marat Safin in Sunday's Australian Open final. Hewitt fought back from a set down to beat Andy Roddick 3-6 7-6 (7-3) 6-1. The Australian is the first Australian to make the final since Pat Cash in 1988.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 28/112 [00:39<01:52,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 29: ['Crucial decision on super-casinos  A decision on whether to allow Westminster to legislate on super-casinos is set to be made by the Scottish Parliament.  The government has plans for up to eight Las Vegas style resorts in the UK, one of which is likely to be in Glasgow. Scottish ministers insist they will still have the final say on whether a super-casino will be built in Scotland. But opposition parties say that will not happen in practice. The vote is due to be taken on Wednesday and is expected to be close.  The Scottish Executive believes that the legislation should be handled by Westminster. The new law will control internet gambling for the first time and is aimed at preventing children from becoming involved. A super-casino in Glasgow could be located at Ibrox or the Scottish Exhibition and Conference Centre. The new gambling bill going through Westminster will allow casino complexes to open to the public, have live entertainment and large numbers of fruit machines with unlimited prizes. But the Scottish National Party and the Tories say the issue of super-casinos should be decided in Scotland and believe the executive is shirking its responsibility.']\n",
            "Summarized Text 29: ['The government has plans for up to eight Las Vegas style resorts in the UK. Scottish ministers insist they will still have the final say on whether a super-casino will be built in Scotland. But opposition parties say that will not happen in practice. Vote is due to be taken on Wednesday and is expected to be close.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 29/112 [00:40<01:48,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 30: ['Tigers wary of Farrell \\'gamble\\'  Leicester say they will not be rushed into making a bid for Andy Farrell should the Great Britain rugby league captain decide to switch codes.  \"We and anybody else involved in the process are still some way away from going to the next stage,\" Tigers boss John Wells told BBC Radio Leicester. \"At the moment, there are still a lot of unknowns about Andy Farrell, not least his medical situation. \"Whoever does take him on is going to take a big, big gamble.\" Farrell, who has had persistent knee problems, had an operation on his knee five weeks ago and is expected to be out for another three months. Leicester and Saracens are believed to head the list of rugby union clubs interested in signing Farrell if he decides to move to the 15-man game.  If he does move across to union, Wells believes he would better off playing in the backs, at least initially. \"I\\'m sure he could make the step between league and union by being involved in the centre,\" said Wells. \"I think England would prefer him to progress to a position in the back row where they can make use of some of his rugby league skills within the forwards. \"The jury is out on whether he can cross that divide. \"At this club, the balance will have to be struck between the cost of that gamble and the option of bringing in a ready-made replacement.\"']\n",
            "Summarized Text 30: [\"Tigers wary of Farrell 'gamble' Leicester say they will not be rushed into making a bid for Andy Farrell. Great Britain rugby league captain may decide to switch codes. Leicester and Saracens are believed to head the list of rugby union clubs interested in signing Farrell if he decides to move.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 30/112 [00:41<01:44,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 31: ['Redknapp poised for Saints  Southampton are set to unveil Harry Redknapp as their new manager at a news conference at 1500 GMT on Wednesday.  The former Portsmouth boss replaces Steve Wigley, who has been relieved of first-team duties after just one win in 14 league games in charge. Redknapp, 57, quit his Fratton Park position on 24 November and vowed: \"I will not go down the road - no chance.\" Pompey coach Kevin Bond is poised to join Redknapp, who will be Saints\\' third boss of the season. Redknapp\\'s first game in charge will be at home to Middlesbrough on Saturday. Portsmouth chairman Milan Mandaric said he was \"disappointed\" by the news and claimed Redknapp had been in talks with Southampton for \"some time\".  \"It would appear that negotiations over this have been going on for some time,\" Mandaric said on Portsmouth\\'s official website. \"I am surprised and a little shocked that the chairman of Southampton has not picked up the phone and kept me informed.\" According to Mandaric, Redknapp vowed he would not join their South coast rivals when he left Portsmouth. \"I said to Harry \\'I hope you don\\'t go to Southampton\\', and he told me \\'absolutely not\\',\" he said. \"I\\'m wouldn\\'t say I\\'m bitter, disgusted or angry, just disappointed, but it\\'s Harry\\'s life and it\\'s his decision.\" Redknapp became a cult hero after leading Portsmouth into the Premiership for the first time, and then masterminding their survival in their debut season. But he left the club claiming he needed a break from football, though many believed he was upset with Mandaric\\'s decision to bring in Velimir Zajec as executive director.  Southampton chairman Rupert Lowe was desperate to give former academy director Wigley, who replaced Paul Sturrock just two games into the season, every chance to succeed at St Mary\\'s. But results under Wigley have been poor and Southampton are deep in trouble near the foot of the table. When Redknapp\\'s appointment is confirmed, he will be Saints\\' ninth manager in eight years.']\n",
            "Summarized Text 31: ['Harry Redknapp set to be unveiled as Southampton manager on Wednesday. Portsmouth chairman Milan Mandaric said he was \"disappointed\" by the news. Portsmouth coach Kevin Bond is also poised to join the Saints. Steve Wigley relieved of first-team duties after just one win in 14 league games.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 31/112 [00:43<01:46,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 32: ['Blair and Blunkett Sheffield trip  Tony Blair is to join Home Secretary David Blunkett in a visit to Sheffield on Thursday.  Mr Blunkett\\'s conduct is being looked at to establish whether he abused his position in relation to his ex-lover. The Parliamentary standards watchdog is looking at his decision to give Kimberly Quinn free rail tickets. He is also being investigated over the visa application of Mrs Quinn\\'s ex-nanny. The visit to Sheffield will be seen as a show of unity by Mr Blair.  On Wednesday during Prime Minister\\'s Questions, Tory leader Michael Howard went on the offensive over comments Mr Blunkett is alleged to have made in a new biography. He is understood to have made a series of criticisms about his Cabinet colleagues from the prime minister down. Mr Howard said Mr Blunkett had complained he had inherited a \"giant mess\" when he took over at the Home Office from Jack Straw, now foreign secretary. The Tory leader went on: \"He doesn\\'t stop there: he thinks the culture secretary\\'s weak; he thinks the trade secretary doesn\\'t think strategically and he thinks the education secretary hasn\\'t developed as expected. \"He says the prime minister doesn\\'t like being told the truth and the chancellor - no doubt the prime minister will agree with this - is a bully.\" Mr Blair retorted voters remembered the record of a government and no comments by politicians.  The home secretary has already admitted he was wrong to give the two first class tickets, given to him as an MP, to Mrs Quinn and has since paid the Â£180 back. He has apologised for \"a genuine mistake\" and says he will write to the watchdog to answer further questions. The rail tickets are meant to help MPs\\' spouses get between Westminster and their constituencies. After his inquiry, Parliamentary watchdog Sir Philip Mawer will report to the Commons Standards and Privileges Committee, the group of MPs who will recommend to the full House of Commons what action - if any - should be taken against Mr Blunkett.  The separate inquiry by ex-senior civil servant Sir Alan Budd is investigating whether the home secretary helped fast-track a bid by Mrs Quinn\\'s nanny, Leoncia Casalme, to stay in the UK. Last week, Mr Blunkett won the first round of a High Court battle with Mrs Quinn for access to her son. Mr Blunkett declined to comment about his own position, saying the inquiry was under way and the High Court had stressed his right to privacy did not affect his job in improving security and stability. Downing Street has stressed Mr Blair\\'s support for the home secretary.']\n",
            "Summarized Text 32: [\"Blair to join David Blunkett in a visit to Sheffield on Thursday. Watchdog is looking at his decision to give Kimberly Quinn free rail tickets. He is also being investigated over the visa application of Mrs Quinn's ex-nanny. Visit to Sheffield will be seen as a show of unity by Mr Blair. Tory leader Michael Howard went on the offensive over comments Mr Blunket made in a new biography.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 32/112 [00:44<01:55,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 33: ['More power to the people says HP  The digital revolution is focused on letting people tell and share their own stories, according to Carly Fiorina, chief of technology giant Hewlett Packard.  The job of firms such as HP now, she said in a speech at the Consumer Electronics Show (CES), was to ensure digital and physical worlds fully converged. She said the goal for 2005 was to make people the centre of technology. CES showcases 50,000 new gadgets that will be hitting the shelves in 2005. The tech-fest, the largest of its kind in the world, runs from 6 to 9 January. \"The digital revolution is about the democratisation of technology and the experiences it makes possible,\" she told delegates. \"Revolution has always been about giving power to the people.\" She added: \"The real story of the digital revolution is not just new products, but the millions of experiences made possible and stories that millions can tell.\" Part of giving people more control has been about the freeing up of content, such as images, video and music. Crucial to this has been the effort to make devices that speak to each other better so that content can be more easily transferred from one device, such as a digital camera, to others, such as portable media players. A lot of work still needs to be done, however, to sort out compatibility issues and standards within the technology industry so that gadgets just work seamlessly, she said.  Ms Fiorina\\'s talk also touted the way technology is being designed to focus on lifestyle, fashion and personalisation, something she sees as key to what people want.  Special guest, singer Gwen Stefani, joined her on-stage to promote her own range of HP digital cameras which Ms Stefani has helped design and which are heavily influenced by Japanese youth culture. The digital cameras, which are due to go on sale in the US by the summer, are based on the HP 607 model. The emphasis on personalisation and lifestyle is a big theme at this year\\'s CES, with tiny, wearable MP3 players at every turn and rainbow hues giving colour to everything. Ms Fiorina also announced that HP was working with Nokia to launch a visual radio service for mobiles, which would launch in Europe early this year. The service will let people listen to radio on their mobiles and download relevant content, like a track\\'s ringtone, simultaneously. The service is designed to make mobile radio more interactive.  Among the other new products she showcased was the Digital Media Hub, a big upgrade to HP\\'s Digital Entertainment Centre. Coming out in the autumn in the US, the box is a networked, high-definition TV, cable set-top box, digital video recorder and DVD recorder. It has a removable hard drive cartridge, memory card slots, and Light Scribe labelling software which lets people design and print customised DVD labels and covers. It is designed to contain all a household\\'s digital media, such as pre-recorded TV shows, pictures, videos and music so it can all be managed in one place. The hub reflects the increasing move to re-box the PC so that it can work as part of other key centres of entertainment. Research suggests that about 258 million images are saved and shared every day, equating to 94 billion a year. Eighty per cent of those remain on cameras. Media hubs are designed to encourage people to organise them on one box. Ms Fiorina was one of several keynote speakers, who also included Microsoft chief Bill Gates, to set out what major technology companies think people will be doing with technologies and gadgets in the next 12 months. In a separate announcement during the keynote speech, Ms Fiorina said that HP would be partnering MTV to replace this year\\'s MTV Asia music award. MTV\\'s Asia Aid will be held in Bangkok on 3 February, and is aimed at helping to raise money for the Asian tsunami disaster.']\n",
            "Summarized Text 33: ['Carly Fiorina says goal for 2005 is to make people the centre of technology. CES showcases 50,000 new gadgets that will be hitting the shelves in 2005. Singer Gwen Stefani joins Fiorina on stage to promote her own range of HP digital cameras. HP working with Nokia to launch visual radio service for mobiles.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 33/112 [00:46<01:59,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 34: ['Hundreds vie for best film Oscar  A total of 267 films are eligible for the best film Oscar but only five will be chosen to go forward as nominees.  The Academy of Motion Picture, Arts and Sciences has sent out the first ballot papers with the full list of films vying for recognition. Among those expected to receive nominations are The Aviator, Million Dollar Baby and Sideways. Academy members will now vote for their favourites before the final nominees are announced on 25 January.  To be eligible for nomination a film must have been shown in a commercial theatre for seven consecutive days before the deadline of 31 December. Director Martin Scorsese\\'s The Aviator, starring Leonardo DiCaprio went on general release on Christmas Day in the US, ensuring it just made the deadline. Studios have already begun lobbying voters, taking out full page adverts in trade publications such as Variety urging them to remember particular films when it comes to choosing what to back. Other movies tipped for possible success include Closer, starring Jude Law and Julia Roberts, Finding Neverland, with Johnny Depp as author JM Barry and Kinsey starring Liam Neeson as the famed sex scientist Alfred Kinsey. Meanwhile, design engineer Takuo Miyagishima will be awarded an Oscar at the Scientific and Technical Awards Dinner on 12 February 2005. Miyagishima is the 18th recipient of the Sawyer Award, which is \"presented to an individual in the motion picture industry whose technological contributions have brought credit to the industry.\" The main Oscar ceremony will be held in Los Angeles on 27 February.']\n",
            "Summarized Text 34: ['The Aviator, Million Dollar Baby and Sideways among those expected to receive nominations. Academy members will now vote for their favourites before the final nominees are announced on 25 January. To be eligible for nomination a film must have been shown in a commercial theatre for seven consecutive days before the deadline of 31 December.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 34/112 [00:47<01:51,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 35: ['\\'Strong dollar\\' call halts slide  The US dollar\\'s slide against the euro and yen has halted after US Treasury Secretary John Snow said a strong dollar was \"in America\\'s interest\".  But analysts said any gains are likely to be short-lived as problems with the US economy were still significant. They also pointed out that positive comments apart, President George W Bush\\'s administration had done little to stop the dollar\\'s slide. A weak dollar helps boost exports and narrow the current account deficit. The dollar was trading at $1.2944 against the euro at 2100GMT, still close to the $1.3006 record level set on 10 November. Against the Japanese yen, it was trading at 105.28 yen, after hitting a seven-month low of 105.17 earlier in the day.  Policy makers in Europe have called the dollar\\'s slide \"brutal\" and have blamed the strength of the euro for dampening economic growth. However, it is unclear whether ministers would issue a declaration aimed at curbing the euro\\'s rise at a monthly meeting of Eurozone ministers late on Monday. Higher growth in Europe is regarded by US officials as a way the huge US current account deficit - that has been weighing on the dollar - could be reduced. Mr Snow who is currently in Dublin at the start of a four-nation EU visit, has applauded Ireland\\'s introduction of lower taxes and deregulation which have helped boost growth. \"The eurozone is growing below its potential. When a major part of the global economy is below potential there are negative consequences... for the citizens of those economies... and for their trading partners,\" he said. Mr Snow\\'s comments may have helped shore up the dollar on Monday, but he was careful to qualify his statement.  \"Our basic policy, of course, is to let open, competitive markets set the values,\" he explained. \"Markets are driven by fundamentals and towards fundamentals.\" US officials have also said that other economies need to grow, so the US is not the main global growth engine. Economists say that the fundamentals, or key indicators, of the US economy are looking far from rosy. Domestic consumer demand is cooling, and heavy spending by President Bush has pushed the budget deficit to a record $427bn (Â£230bn). The current account deficit, meanwhile, hit a record $166bn in the second quarter of 2004. For many analysts, a weaker dollar is here to stay. \"No end is in sight,\" said Carsten Fritsch, a strategist at Commerzbank . \"It is only a matter of time until the euro reaches $1.30.\" Some analysts maintain the US is secretly happy with a lower dollar which helps makes its exports cheaper in Europe, thus boosting its economy.']\n",
            "Summarized Text 35: ['US Treasury Secretary John Snow said a strong dollar was \"in America\\'s interest\" But analysts said any gains are likely to be short-lived as problems with the US economy are still significant. A weak dollar helps boost exports and narrow the current account deficit. The dollar was trading at $1.2944 against the euro at 2100GMT, still close to the $ 1.3006 record set on 10 November.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 35/112 [00:49<01:56,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 36: ['EU-US seeking deal on air dispute  The EU and US have agreed to begin talks on ending subsidies given to aircraft makers, EU Trade Commissioner Peter Mandelson has announced.  Both sides hope to reach a negotiated deal over state aid received by European aircraft maker Airbus and its US rival Boeing, Mr Mandelson said. Airbus and Boeing accuse each other of benefiting from illegal subsidies. Mr Mandelson said the EU and US hoped to avoid having to resolve the dispute at the World Trade Organisation (WTO).  \"With this agreement the EU and US have confirmed their willingness to resolve the dispute which has arisen between them,\" Mr Mandelson said. \"I hope our negotiations in the next three months will lead to an agreement ending subsidies to development and production of large civil aircraft.\" Last year, the US terminated an agreement with the EU, reached in 1992, which limits the subsidies countries can hand over to civil aircraft makers. The US filed a complaint against Brussels with the WTO over state aid to Airbus, prompting a retaliatory EU complaint over US support for Boeing. However, both sides agreed to suspend their requests for WTO arbitration at the beginning of December, to allow bilateral talks to continue. EADS and BAE Systems, the European defence and aerospace firms which own Airbus, welcomed Mr Mandelson\\'s announcement. \"It has always been preferable that any differences between the US and Europe on this matter be overcome through constructive discussion rather than through legal recourse,\" the companies said in a joint statement.  Separately, the world\\'s largest package delivery company, UPS, said it had placed an order for 10 Airbus A380 superjumbo freight-carrying jets, with an option to buy 10 more of the triple-decker aircraft. The US company said it needed to expand its air freight capacity following strong international growth, and would begin receiving deliveries of the A380s from 2009. However, UPS said it was cutting a previous order for smaller Airbus A300s from 90 planes to 53. So far, Airbus has delivered 40 A300s to UPS. Airbus overtook Boeing as the world\\'s largest manufacturer of commercial airliners in 2003.']\n",
            "Summarized Text 36: ['EU-US seeking deal on air dispute. Airbus and Boeing accuse each other of benefiting from illegal subsidies. US terminated agreement with the EU, reached in 1992, which limits the subsidies countries can hand over to civil aircraft makers. UPS orders 10 Airbus A380 superjumbo freight-carrying jets.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 36/112 [00:50<01:49,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 37: ['WorldCom bosses\\' $54m payout  Ten former directors at WorldCom have agreed to pay $54m (Â£28.85m), including $18m from their own pockets, to settle a class action lawsuit, reports say.  James Wareham, a lawyer representing one of the directors, told Reuters the 10 had agreed to pay those who lost billions when the firm collapsed. The remaining $36m will be paid by the directors\\' insurers. But, a spokesman for the prosecutor, New York State Comptroller Alan Hevesi, said no formal agreement had been made.  Corporate governance experts said that if the directors do dip into their own pockets for the settlement, it will set a new standard for the accountability of bosses, when the firms they oversee face problems.  \"Directors very rarely pay,\" said Charles Elson, chairman of the Center for Corporate Governance at the University of Delaware. He added that the settlement \"sends a pretty strong shockwave through the director world\". A formal agreement on the payout is expected to be signed on Thursday in a US district court in Manhattan. Earlier, the New York Times had reported that the personal payments were required as part of any deal at the start of negotiations. The ten former outside directors are James Allen, Judith Areen, Carl Aycock, Max Bobbitt, Clifford Alexander, Stiles Kellett, Gordon Macklin, John Porter, Lawrence Tucker and the estate of John Sidgmore, who died last year. It has not yet been determined how much each director will have to pay. \"None of the 10 former directors was a direct participant in the accounting machinations of the WorldCom fraud,\" said the Wall Street Journal (WSJ).  Two other outside former directors, Bert Roberts and Francesco Galesi, remain defendants in the lawsuit, said the newspaper. According to the WSJ, which cites people familiar to the case, the settling directors are expected to deny wrongdoing and state they are settling the case to eliminate the uncertainties and expense of further litigations. The second-largest US long-distance telecoms operator filed for bankruptcy in 2002 when an $11bn accounting scandal was unearthed. The company emerged from Chapter 11 protection last year and changed its name to MCI Inc. Former WorldCom chief executive Bernard Ebbers is to face trial this month on criminal charges that he oversaw the fraud.']\n",
            "Summarized Text 37: [\"10 former WorldCom directors agree to pay $54m to settle class action lawsuit. $18m will be paid from their own pockets, $36m from directors' insurers. Deal is expected to be signed on Thursday in a US district court in Manhattan. Former WorldCom chief executive Bernard Ebbers is to face trial this month.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 37/112 [00:52<01:49,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 38: ['Hewitt falls to Dent  Lleyton Hewitt suffered a shock defeat to Taylor Dent in the quarter-finals of the Australian Hardcourt Championships in Adelaide on Friday.  The top seed was a strong favourite for the title but went down 7-6 (7-4) 6-3 to the American. Dent will face Juan Ignacio Chela next after the fourth seed was too strong for Jurgen Melzer. Olivier Rochus beat third seed Nicolas Kiefer 6-7 (4-7) 7-6 (8-6) 7-5 and will take on second seed Joachim Johansson. The Swede reached the last four by beating compatriot Thomas Enqvist 6-3 4-6 6-1. \"I felt like I was striking the ball much better,\" said Johansson. \"I felt like I had a lot of break chances, I didn\\'t take care of them all, but I broke him four times and he only broke me once. \"I felt that was the key to get up in the set early.\"']\n",
            "Summarized Text 38: ['Lleyton Hewitt beaten in quarter-finals of Australian Hardcourt Championships. Top seed beaten 7-6 (7-4) 6-3 by American Taylor Dent. Dent will face Juan Ignacio Chela next after he beat Jurgen Melzer. Olivier Rochus beats Nicolas Kiefer to reach last four. Second seed Joachim Johansson beats compatriot Thomas Enqvist.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 38/112 [00:53<01:47,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 39: ['Apple laptop is \\'greatest gadget\\'  The Apple Powerbook 100 has been chosen as the greatest gadget of all time, by US magazine Mobile PC.  The 1991 laptop was chosen because it was one of the first \"lightweight\" portable computers and helped define the layout of all future notebook PCs. The magazine has compiled an all-time top 100 list of gadgets, which includes the Sony Walkman at number three and the 1956 Zenith remote control at two. Gadgets needed moving parts and/or electronics to warrant inclusion. The magazine staff compiled the list and specified that gadgets also needed to be a \"self-contained apparatus that can be used on its own, not a subset of another device\".  \"In general we included only items that were potentially mobile,\" said the magazine.  \"In the end, we tried to get to the heart of what really makes a gadget a gadget,\" it concluded. The oldest \"gadget\" in the top 100 is the abacus, which the magazine dates at 190 A.D., and put in 60th place. Other pre-electronic gadgets in the top 100 include the sextant from 1731 (59th position), the marine chronometer from 1761 (42nd position) and the Kodak Brownie camera from 1900 (28th position). The Tivo personal video recorder is the newest device to make the top 10, which also includes the first flash mp3 player (Diamond Multimedia), as well as the first \"successful\" digital camera (Casio QV-10) and mobile phone (Motorola Startac). The most popular gadget of the moment, the Apple iPod, is at number 12 in the list while the first Sony transistor radio is at number 13.  Sony\\'s third entry in the top 20 is the CDP-101 CD player from 1983. \"Who can forget the crystalline, hiss-free blast of Madonna\\'s Like A Virgin emanating from their first CD player?\" asked the magazine. Karl Elsener\\'s knife, the Swiss Army Knife from 1891, is at number 20 in the list. Gadgets which could be said to feature surprisingly low down in the list include the original telephone (23rd), the Nintendo GameBoy (25th), and the Pulsar quartz digital watch (36th). The list also contains plenty of oddities: the Pez sweet dispenser (98th), 1990s toy Tamagotchi (86th) and the bizarre Ronco inside the shell egg scrambler (84th).  Almost everyone has a mobile phone, how many people own a Powerbook? or an iPod? The findings of this magazine are not very convincing.  What about the magnetic compass? We still use it 1,000 years after it was invented.  I am amazed by the obsession with individual gadgets rather than genre. For example the Sony walkman was the first truly portable way of listening to your own music on the move whereas Minidisc, Flash MP3, portable CD players etc. are really just improvements in technology.  My favourite \\'true\\' gadgets are probably my portable MiniDisc player and the little battery powered whizzy thing I use to froth up my coffee!  Calm down it\\'s only in their opinion, and any list that includes the Taser in the top 100 gadgets has to be suspect....  Swiss army knife and no question about it. How many of the other items are still relatively unchanged from the original idea and still as useful/popular? You don\\'t need a laptop or even a pocket calculator to work that one out!  This list merely illustrates interesting cultural divides between the American authors and the overwhelmingly British responses. Brits see no further than mobile phones and the over thirties Sinclair; whilst the Americans focus on Apple, TV remotes and TiVO (which probably is rather obscure in Europe).  What about the Soda Stream. This gadget changed my pre-teen life. Lap tops may enable you to \"think different, but you cant use them to \"get busy with the fizzy\"  How about Astro Wars, one of the pioneers for computer games, i remember spending many an hour playing this and it still works today! However tried it the other day and it was rubbish, still a great gadget of its time.  Why worry about mobile phones. Soon they will be subsumed into the PDA\\'s / laptops etc.  What about the Marine Chronometer? Completely revolutionised navigation for boats and was in use for centuries. For it\\'s time, a technological marvel!  Sony Net Minidisc! It paved the way for more mp3 player to explode onto the market. I always used my NetMD, and could not go anywhere without it.  A laptop computer is not a gadget! It\\'s a working tool!  The Sinclair Executive was the world\\'s first pocket calculator. I think this should be there as well.  How about the clockwork radio? Or GPS? Or a pocket calculator? All these things are useful to real people, not just PC magazine editors.  Are the people who created this list insane ? Surely the most important gadget of the modern age is the mobile phone? It has revolutionised communication, which is more than can be said for a niche market laptop. From outside the modern age, the marine chronometer is the single most important gadget, without which modern transportation systems would not have evolved so quickly.  Has everyone forgot about the Breville pie maker??  An interesting list. Of the electronic gadgets, thousands of journalists in the early 1980s blessed the original noteboook pc - the Tandy 100. The size of A4 paper and light, three weeks on a set of batteries, an excellent keyboard, a modem. A pity Tandy did not make it DOS compatible.  What\\'s an Apple Powerbook 100 ? It\\'s out of date - not much of a \"gadget\". Surely it has to be something simple / timeless - the tin opener, Swiss Army Knife, safety razor blade, wristwatch or the thing for taking stones out of horses hooves ?  It has to be the mobile phone. No other single device has had such an effect on our way of living in such a short space of time.  The ball point pen has got to be one of the most used and common gadgets ever. Also many might be grateful for the pocket calculator which was a great improvement over the slide rule.  The Casio pocket calculator that played a simple game and made tinny noises was also a hot gadget in 1980. A true gadget, it could be carried around and shown off.  All top 10 are electronic toys, so the list is probably a better reflection of the current high-tech obsession than anything else. I say this as the Swiss Army Knife only made No 20.  Sinclair QL a machine far ahead of its time. The first home machine with a true multi-takings OS. Shame the marketing was so bad!!!  Apple.. a triumph of fashion over... well everything else.  Utter rubbish. Yes, the Apple laptop and Sony Walkman are classic gadgets. But to call the sextant and the marine chronometer \\'gadgets\\' and rank them as less important than a TV remote control reveals a quite shocking lack of historical perspective. The former literally helped change the world by vastly improving navigation at see. The latter is the seed around which the couch potato culture has developed. No competition.  I\\'d also put Apple\\'s Newton and the first Palm Pilot there as the front runners for portable computing, and possibly the Toshiba Libretto for the same reason. I only wish that Vulcan Inc\\'s Flipstart wasn\\'t just vapourware otherwise it would be at the top.  How did a laptop ever manage to beat off the challenge of the wristwatch or the telephone (mobile or otherwise)? What about radios and TVs?  The swiss army knife. By far the most useful gadget. I got mine 12 years ago. Still wearing and using it a lot! It stood the test of time.  Psion Organiser series 3, should be up there. Had a usable qwerty keyboard, removable storage, good set of apps and programmable. Case design was good (batteries in the hinge - a first, I think). Great product innovation.  The first mobile PC was voted best gadget by readers of...err... mobile PC?! Why do you keep putting these obviously biased lists on your site? It\\'s obviously the mobile phone or remote control, and readers of a less partisan publication would tell you that.  The Motorola Startac should be Number One. Why? There will be mobile phones long after notebook computers and other gadgets are either gone or integrated in communications devices.  The Psion series 3c! The first most practical way to carry all your info around...  I too would back the Sinclair Spectrum - without this little beauty I would never have moved into the world of IT and earn the living that I do now.  I\\'d have put the mobile phone high up the list. Probably a Nokia model.  Sinclair Spectrum - 16k. It plugged into the tv. Games were rubbish but it gave me a taste for programming and that\\'s what I do for a living now.  I wish more modern notebooks -- even Apple\\'s newest offerings -- were more like the PB100. Particularly disheartening is the demise of the trackball, which has given way to the largely useless \"trackpad\" which every notebook on the market today uses. They\\'re invariably inaccurate, uncomfortable, and cumbersome to use.  Congratulations to Apple, a deserved win!']\n",
            "Summarized Text 39: ['Apple Powerbook 100 chosen as greatest gadget of all time by US magazine Mobile PC. The 1991 laptop was one of the first \"lightweight\" portable computers. Sony Walkman at number three and the 1956 Zenith remote control at two. The oldest \"gadget\" in the top 100 is the abacus, which dates at 190 A.D.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 39/112 [00:55<01:58,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 40: ['Strachan turns down Pompey  Former Southampton manager Gordon Strachan has rejected the chance to become Portsmouth\\'s new boss.  The Scot was Pompey chairman Milan Mandaric\\'s first choice to replace Harry Redknapp, who left Fratton Park for rivals Saints earlier in December. \"I think it\\'s a fantastic job for anybody apart from somebody who has just been the Southampton manager,\" Strachan told the BBC. Club director Terry Brady held initial talks with Strachan on Saturday. The former Scotland international added that joining Southampton\\'s local rivals would not be a wise move. \"It\\'s got everything going for it but I\\'ve got too many memories of the other side and I don\\'t want to sour those memories,\" he said. \"Everything\\'s right - it\\'s 10 minutes away, there are good players there, a good set-up, a good atmosphere at the ground. \"There\\'s lots to do but it\\'s not right for somebody who has just been the Southampton manager.\" Since Redknapp\\'s departure, executive director Velimir Zajec and coach Joe Jordan have overseen first-team affairs.  The duo had gone five matches unbeaten until Sunday\\'s 1-0 defeat at home to champions Arsenal, but the club are still in a respectable 12th place in the Premiership table. Strachan left St Mary\\'s in February, after earlier announcing his intention to take a break from the game at the end of the 2003-04 season. His previous managerial experience came at Coventry, whom he led for five years from 1996 to 2001.']\n",
            "Summarized Text 40: [\"Strachan was Pompey chairman Milan Mandaric's first choice to replace Harry Redknapp. Club director Terry Brady held initial talks with Strachan on Saturday. The Scot left St Mary's in February after earlier announcing his intention to take a break from the game at the end of the 2003-04 season.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 40/112 [00:56<01:49,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 41: ['Wi-fi web reaches farmers in Peru  A network of community computer centres, linked by wireless technology, is providing a helping hand for poor farmers in Peru.  The pilot scheme in the Huaral Valley, 80 kilometres north of the capital Lima, aims to offer the 6,000-strong community up-to-date information on agricultural market prices and trends. The Agricultural Information Project for Farmers of the Chancay-Huaral Valley also provides vital links between local organisations in charge of water irrigation, enabling them to coordinate their actions. More than 13,000 rural inhabitants, as well as 18,000 students in the region, will also benefit from the telecoms infrastructure.  The 14 telecentres uses only free open source software and affordable computer equipment. The network has been three years in the making and was officially inaugurated in September.  The non-government organisation, Cepes (Peruvian Centre for Social Studies) led the $200,000 project, also backed by local institutions, the Education and Agriculture ministries, and European development organisations. \"The plan includes training on computers and internet skills for both operators and users of the system,\" said Carlos Saldarriaga, technical coordinator at Cepes. Farmers are also taking extra lessons on how to apply the new information to make the most of their plots of land. The Board of Irrigation Users which runs the computer centres, aims to make the network self-sustainable within three years, through the cash generated by using the telecentres as internet cafes.  One of the key elements of the project is the Agricultural Information System, with its flagship huaral.org website. There, farmers can find the prices for local produce, as well as information on topics ranging from plague prevention to the latest farming techniques. The system also helps the inhabitants of the Chancay-Huaral Valley to organise their vital irrigation systems. \"Water is the main element that unites them all. It is a precious element in Peru\\'s coastal areas, because it is so scarce, and therefore it is necessary to have proper irrigation systems to make the most of it,\" Mr Saldarriaga told the BBC News website. The information network also allows farmers to look beyond their own region, and share experiences with other colleagues from the rest of Peru and even around the world.  Cepes says the involvement of the farmers has been key in the project\\'s success. \"Throughout the last three years, the people have provided a vital thrust to the project; they feel it belongs to them,\" said Mr Saldarriaga. The community training sessions, attended by an equal number of men and women, have been the perfect showcase for their enthusiasm. \"We have had an excellent response, mainly from young people. But we have also had a great feedback when we trained 40 or 50-year old women, who were seeing a computer for the first time in their lives.\" So far, the Huaral programme promoters say the experience has been very positive, and are already planning on spreading the model among other farmers\\' organisations in Peru. \"This is a pilot project, and we have been very keen on its cloning potential in other places,\" underlined Mr Saldarriaga.  The Cepes researcher recalls what happened in Cuyo, a 50-family community with no electricity, during the construction of the local telecentre site. There it was necessary to build a mini-hydraulic dam in order to generate 2kW worth of power for the computers, the communications equipment and the cabin lights. \"It was already dark when the technicians realised they didn\\'t have any light bulbs to test the generator, so they turned up to the local store to buy light bulbs,\" recalls Carlos Saldarriaga. \"The logical answer was \\'we don\\'t sell any\\', so they had to wait until the next morning to do the testing.\" Now, with the wireless network, Cuyo as well as the other communities is no longer isolated.']\n",
            "Summarized Text 41: ['Wi-fi web reaches farmers in Peru. Network of community computer centres, linked by wireless technology, is providing a helping hand for poor farmers. Pilot scheme in the Huaral Valley, 80 kilometres north of the capital Lima, aims to offer the 6,000-strong community up-to-date information.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 41/112 [00:58<01:51,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 42: ['UK needs tax cuts, Tories insist  A major change of direction is needed in Britain if it is to prosper, the shadow chancellor said as the Tory Party spring conference began.  Oliver Letwin said the UK could not compete with other countries without the Â£4bn tax cuts he was promising. Tory co-chairman Liam Fox had opened the forum in Brighton with an attack on Labour\\'s record and party leader Michael Howard is due to speak later. Tony Blair has said Conservative policies would cause economic failure. But Mr Letwin said Britain had fallen from fourth to 11th in the international economic competitiveness league.  \"Can this country compete, can this country prosper, unless we do something about the burden of regulation and tax on our economy?\" he said. \"If we are going to take on the great challenges, the challenges like those posed by the Chinese and the Indians, we have got to do something about getting down the burden of regulation and getting down the burden of tax,\" he said. \"The fact is the very carefully costed, fully funded plans we have laid out for saving Â£12bn by 2007-2008 are absolutely crucial to delivering an economy that will prosper and provide people with jobs and indeed provide the public services with the money they need on a sustainable long-term basis.\" Mr Letwin said voting for Labour meant choosing higher taxes, borrowing and waste.  Earlier, Dr Fox had said Labour\\'s rule had been characterised by \"lost trust and failure to deliver\". He also attacked the government\\'s \"failure\" to control immigration and asylum and criticised its record on the NHS, telling delegates Labour cannot be trusted on education or crime. A Tory government would sort out the \"shambles\" of immigration, put patients before statistics and bring discipline to schools, he said. Michael Howard, who had been due to welcome delegates to the conference on Friday, will address them in a lunchtime speech. His welcome address had to be postponed after he stayed in London to lead the party\\'s opposition to the Prevention of Terrorism Bill in its lengthy progress through Parliament. The bill was finally passed on Friday evening, after more than 30 hours of debate. Mr Howard is likely to defend his party\\'s handling of the bill, which was only passed after the Conservatives accepted Prime Minister Tony Blair\\'s promise that MPs would be able to review it within a year.']\n",
            "Summarized Text 42: [\"Oliver Letwin says UK cannot compete with other countries without tax cuts. Tory co-chairman Liam Fox opens forum with an attack on Labour's record. Party leader Michael Howard is due to speak later in Brighton. Tony Blair has said Conservative policies will cause economic failure.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 42/112 [00:59<01:44,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 43: ['Mild winter drives US oil down 6%  US oil prices have fallen by 6%, driven down by forecasts of a mild winter in the densely populated northeast.  Light crude oil futures fell $2.86 to $41.32 a barrel on the New York Mercantile Exchange (Nymex), and have now lost $4 in five days. Nonetheless, US crude is still 30% more expensive than at the beginning of 2004, boosted by growing demand and bottlenecks at refineries. Traders ignored the possible effects of Asia\\'s tidal waves on global supplies.  Instead, the focus is now on US consumption, which is heavily influenced in the short term by the weather. \"With the revised milder temperatures... I\\'m more inclined to think we\\'ll push lower and test the $40-40.25 range,\" said John Brady of ABN AMRO. \"The market definitely feels to be on the defensive.\" Statistics released last week showed that stockpiles of oil products in the US had risen, an indication that severe supply disruptions may not arise this winter, barring any serious incident. Oil prices have broken records in 2004, topping $50 a barrel at one point, driven up by a welter of worries about unrest in Iraq and Saudi Arabia, rising demand and supply bottlenecks. London\\'s International Petroleum Exchange remained closed for the Christmas holiday.']\n",
            "Summarized Text 43: [\"Light crude oil futures fell $2.86 to $41.32 a barrel on the New York Mercantile Exchange. US crude is still 30% more expensive than at the beginning of 2004, boosted by growing demand and bottlenecks at refineries. London's International Petroleum Exchange remained closed for the Christmas holiday.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 43/112 [01:01<01:38,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 44: ['Edu describes tunnel fracas  Arsenal\\'s Edu has lifted the lid on the scenes that followed Manchester United\\'s win over the Gunners.  The Brazilian confirmed tempers had flared but could shed no light on reports that food was thrown at United boss Sir Alex Ferguson. \"I saw people being pulled apart, people pushing, pointing and shouting,\" he told Uefa\\'s official website. \"The United players were trying to wind us up about the result but I didn\\'t see any soup being thrown at anyone.\" However, Edu tried to play down the incidents, adding: \"There was nothing that I haven\\'t seen in Brazilian derbies. \"Derby matches in Brazil are worse. I like to play in games like this with this intense rivalry.\" But Edu was highly critical of the ferocity of some of United\\'s challenges during the game, particularly on Jose Antonio Reyes. \"I think we were a lot fairer in the tackles than United,\" he said. \"Reyes was being kicked all over the park - they were beating up the boy and Gary Neville was tackling in such a way that he should have been sent off.\" Following the game, the Football Association said it would look into events in the tunnel. It also charged Ruud van Nistelrooy with serious foul play while Arsenal boss Arsene Wenger has been asked to explain comments he made about the referee.']\n",
            "Summarized Text 44: [\"Edu describes tunnel fracas that followed Manchester United's win over the Gunners. The Brazilian confirmed tempers had flared but could shed no light on reports that food was thrown at United boss Sir Alex Ferguson. Edu was highly critical of the ferocity of some of United's challenges during the game.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 44/112 [01:02<01:32,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 45: ['Robots learn \\'robotiquette\\' rules  Robots are learning lessons on \"robotiquette\" - how to behave socially - so they can mix better with humans.  By playing games, like pass-the-parcel, a University of Hertfordshire team is finding out how future robot companions should react in social situations. The study\\'s findings will eventually help humans develop a code of social behaviour in human-robot interaction. The work is part of the European Cogniron robotics project, and was on show at London\\'s Science Museum.  \"We are assuming a situation in which a useful human companion robot already exists,\" said Professor Kerstin Dautenhahn, project leader at Hertfordshire. \"Our mission is to look at how such a robot should be programmed to respect personal spaces of humans.\"  The research also focuses on human perception of robots, including how they should look, and how a robot can learn new skills by imitating a human demonstrator. \"Without such studies, you will build robots which might not respect the fact that humans are individuals, have preferences and come from different cultural backgrounds,\" Professor Dautenhahn told BBC News Online. \"And I want robots to treat humans as human beings, and not like other robots,\" she added.  In most situations, a companion robot will eventually have to deal not only with one person, but also with groups of people. To find out how they would react, the Hertfordshire Cogniron team taught one robot to play pass-the-parcel with children.  Showing off its skills at the Science Museum, the unnamed robot had to select, approach, and ask different children to pick up a parcel with a gift, moving it arm as a pointer and its camera as an eye. It even used speech to give instructions and play music. However, according to researchers, it will still take many years to build a robot which would make full use of the \"robotiquette\" for human interaction. \"If you think of a robot as a companion for the human being, you can think of 20 years into the future,\" concluded Professor Dautenhahn. \"It might take even longer because it is very, very hard to develop such a robot.\"  You can hear more on this story on the BBC World Service\\'s Go Digital programme.']\n",
            "Summarized Text 45: [\"Researchers at the University of Hertfordshire are teaching robots 'robotiquette' They hope the lessons will help humans develop a code of social behaviour in human-robot interaction. The work is part of the European Cogniron robotics project, and was on show at London's Science Museum.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 45/112 [01:03<01:30,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 46: ['Podcasts mark rise of DIY radio  An Apple iPod or other digital music players can hold anything up to 10,000 songs, which is a lot of space to fill.  But more and more iPod owners are filling that space with audio content created by an unpredictable assortment of producers. It is called \"podcasting\" and its strongest proponent is former MTV host and VJ (video jockey) Adam Curry. Podcasting takes its name from the Apple iPod, although you do not need an iPod to create one or to listen to a podcast. A podcast is basically an internet-based radio show which podcasters create, usually in the comfort of their own home. They need only a microphone, a PC, and some editing software. They then upload their shows to the internet and others can download and listen to them, all for free. Using technology based on XML computer code and RSS - Really Simple Syndication - listeners can subscribe to podcasts collected automatically in a bit of software, which Mr Curry has pioneered. The latest MP3 files of shows can then be picked up by a music playing device automatically.  Mr Curry records, hosts, edits and produce a daily, 40 minute podcast called The Daily Source Code. He wants to make podcasting \"the Next Big Thing\" and says it is an extension of his childhood love of radio gadgetry. \"I was always into technologies and wires,\" he explains. \"My parents gave me the Radio Shack 101 project kit, which allows you to build an AM transmitter and subsequently an FM transmitter. \"I had my mom drive me around the block, see how far it would reach on the car radio.\"  Mr Curry is American, but he grew up in the Netherlands where he hosted illegal, pirate radio shows in the Dutch capital. He tried university in the US, and ended up back in Holland where he hosted a music video show. He spent the next seven years in New York where he worked at MTV hosting the Top 20 Video Countdown, but spent most of his hours tinkering with this new thing called the internet. \"At a certain point in 1995, I was driving in on a Friday afternoon, beautiful blue sky, one of those beautiful days thinking, this is so stupid. \"You know, I\\'m going do the Top 20 Countdown, take the cheque, go home, and sit on the internet until three in the morning. \"So, after I finished the show, I quit. I said, on air, it\\'s been great, I\\'ve been here for seven years at that point, there\\'s something on the internet, I\\'ve got to go find it, and I\\'ll see you later.\"  But Mr Curry\\'s technology and broadcast interests started to gel a couple of years ago when computer storage was growing exponentially and high-speed internet connections were becoming more widely available. The MP3 format also meant that people could create and upload audio more cheaply and efficiently than ever before.  Most importantly, Mr Curry says, people across the globe were bored with the radio they were hearing. \"Listen to 99% of the radio that you hear today, it\\'s radio voices, and it\\'s fake, it\\'s just fake.\" He wanted to make it easier for people to find \"real voices\" on the internet. He wanted software that would automatically download new audio content directly onto players like, iPods. Mr Curry is not a computer programmer, so he asked others to create one for him. No one did, so he tried to write one himself. He finished it a few months ago and says it \"totally sucked.\" He put it up on the net as open source software and now dozens of coders and audio junkies are refining it; the result is a work in progress called \"ipodder\". Doug Kaye, a California-based podcaster, praises the former MTV VJ for what he has done. \"Adam created a simple script that solved what we call the last mile problem. Ipodder takes audio from the web and brings it all the way down to the MP3 player,\" he explains. \"People can wake up in the morning, pick up their iPods as they go to work or before they go exercise, and discover that there\\'s all this new content automatically put onto their players.\" It is created an explosion in podcasting content and podcasters are springing up in Australia, Finland, Brazil, even Malaysia. One couple broadcasts theirs, The Dawn and Drew Show, from Wisconsin in the US, sometimes even from the comfort of their own bed. Topics range from the comfort of their bed, to the latest films or music and have thousands of listeners.  Already, websites are springing up that point listeners in the right direction of good podcasts.  Chris McIntyre runs Podcast Alley and says that there are good sites out there but that not everyone has the technological know-how to simply listen. \"If I were to tell my mom, or my mother-in-law to copy an XML or RSS file to their podcast aggregator, they would think I was speaking a foreign language,\" Mr McIntyre says. Along with technical challenges, there may be legal challenges to podcasters who air their favourite, albeit copyrighted, music. Some in podcasting also worry that too much attention may turn what they see as the \"anti-radio\" into something that is more like conventional broadcasting. Already there is interest in podcasting from the corporate world. Heineken is doing its own podcast now, and so is Playboy. For his part, Adam Curry\\'s pressing ahead with his own vision of what podcasting should be. He loves doing The Daily Source Code because it is about introducing good music and cool ideas to new audiences. He has even been called the Ed Sullivan or Johnny Carson of podcasting which, he says, \"is a badge I\\'ll wear with great honour. \"To be the Johnny Carson, or Ed Sullivan of anything is wonderful. And you know what? You don\\'t need a hell of a lot of talent. \"You just have to be nice, have your ears open, and let people shine. And that\\'s good for me.\"  Clark Boyd is technology correspondent for The World, a BBC World Service and WGBH-Boston co-production.']\n",
            "Summarized Text 46: ['Former MTV video jockey Adam Curry is behind the rise of podcasting. A podcast is an internet-based radio show which podcasters create. They upload their shows to the internet and others can download and listen to them. Mr Curry records, hosts, edits and produces a daily, 40 minute podcast.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 46/112 [01:05<01:38,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 47: ['Apple sues to stop product leaks  Computer firm Apple has issued a lawsuit to prevent online leaks of information about future products.  The lawsuit, against an unidentified individual, comes just weeks before the MacWorld conference in San Francisco, used to showcase new products. The complaint said an \"unidentified individual... has recently misappropriated and disseminated confidential information\". The lawsuit was filed with the Santa Clara California Superior Court. Apple is famously secretive about its future product launches while Apple users are equally famous for speculating about new technology from the company. Fans have speculated in recent weeks about the possibility of a new type of iPod being announced at the MacWorld conference.  Apple said in the seven-page complaint, filed on 13 December, that it did not know the \"true names or capacities, whether individual, associate, corporate or otherwise,\" of the defendants. The company said it would amend the complaint once they had discovered the names of those who had allegedly leaked information. It is not the first time Apple has sued people who have posted information about future products on the internet. In December 2002, Apple sued a former contractor who allegedly posted online drawings, images and engineering details of the company\\'s PowerMac G4 computer. In a statement, Apple said of the current lawsuit: \"Apple has filed a civil complaint against unnamed individuals who we believe stole our trade secrets and posted detailed information about an unannounced Apple product on the internet.\"']\n",
            "Summarized Text 47: [\"Apple sues to stop online leaks of information about future products. The lawsuit, against an unidentified individual, comes just weeks before the MacWorld conference. Apple is famously secretive about its future product launches. In December 2002, Apple sued a former contractor who allegedly posted online drawings, images and engineering details of the company's PowerMac G4 computer.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 47/112 [01:06<01:34,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 48: [\"Chinese exports rise 25% in 2004  Exports from China leapt during 2004 over the previous year as the country continued to show breakneck growth.  The spurt put China's trade surplus - a sore point with some of its trading partners - at a six-year high. It may also increase pressure on China to relax the peg joining its currency, the yuan, with the weakening dollar. The figures released by the Ministry of Commerce come as China's tax chief confirmed that growth had topped 9% in 2004 for the second year in a row. State Administration of Taxation head Xie Xuren said a tightening of controls on tax evasion had combined with the rapid expansion to produce a 25.7% rise in tax revenues to 2.572 trillion yuan ($311bn; Â£165bn).  According to the Ministry of Commerce, China's exports totalled $63.8bn in December, taking the annual total up 35.4% to $593.4bn. With imports rising a similar amount, the deficit rose to $43.4bn. The increased tax take comes despite healthy tax rebates for many exporters totalling 420bn yuan in 2004, according to Mr Xie. China's exporting success has made the trade deficit of the United States soar even further and made trade with China a sensitive political issue in Washington. The peg keeping the yuan around 8.30 to the dollar is often blamed by US lawmakers for job losses at home. A US report issued on Tuesday on behalf of a Congressionally-mandated panel said almost 1.5 million posts disappeared between 1989 and 2003. The pace accelerated in the final three years of the period, said the report for the US-China Economic and Security Review Commission, moving out of labour-intensive industries and into more hi-tech sectors. The US's overall trade deficit with China was $124bn in 2003, and is expected to rise to about $150bn for 2004.\"]\n",
            "Summarized Text 48: [\"Chinese exports rise 25% in 2004 over the previous year. Spurt put China's trade surplus - a sore point with some of its trading partners - at a six-year high. It may also increase pressure on China to relax the peg joining its currency, the yuan, with the weakening dollar.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 48/112 [01:08<01:29,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 49: ['French boss to leave EADS  The French co-head of European defence and aerospace group EADS Philippe Camus is to leave his post.  Mr Camus said in a statement that he has accepted the invitation to return full-time to the Lagardere group, which owns 30% of EADS. \"I will give up my role as soon as the board of directors asks me to do so,\" he said. Airbus head Noel Forgeard is now set to replace Mr Camus, bringing the company\\'s power struggle to an end. Fighting between Mr Camus and Mr Forgeard has hit the headlines in France and analysts feared that this fighting could destabilise the defence and aerospace group. French finance minister Herve Gaymard is on record as saying that he \"deplored\" the infighting at the company. The company should now be able put this dispute behind it, with the departure of Mr Camus and with the clear support given to Mr Forgeard by the Lagardere group, the main French shareholder of EADS. The other main shareholders of EADS are the French government (15%) , who also support Mr Forgeard, and Germany\\'s DaimlerChrysler (30%). Rainer Hertrich, the German co-head of EADS will also step down when his contract expires next year.  Mr Camus recently came under pressure as it became clear that the A380 superjumbo was running over budget. EADS - Airbus\\' majority owner - admitted earlier this week that the project was running 1.45bn euros (Â£1bn; $1.9bn) over budget. But Mr Forgeard has denied this, telling French media that there is no current overrun in the budget. \"But for the sake of transparency, we told our shareholders last week that if we look at the forecast for total costs of the project up to 2010, there is a risk that we will go over by around 10%, which is about 1bn euros (Â£686m; $1.32bn),\" he told France\\'s LCI Television. Due to enter service in 2006, the A380 will replace the Boeing 747 jumbo as the world\\'s biggest passenger aircraft.']\n",
            "Summarized Text 49: ['French co-head of European defence and aerospace group EADS Philippe Camus is to leave his post. Mr Camus said in a statement that he has accepted the invitation to return full-time to the Lagardere group, which owns 30% of EADS. Airbus head Noel Forgeard is now set to replace him.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 49/112 [01:09<01:29,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 50: ['Text message record smashed  UK mobile owners continue to break records with their text messaging, with latest figures showing that 26 billion texts were sent in total in 2004.  The figures collected by the Mobile Data Association (MDA) showed that 2.4 billion were fired off in December alone, the highest monthly total ever. That was 26% more than in December 2003. The records even surpassed the MDA\\'s own predictions, it said. Every day 78 million messages are sent and there are no signs of a slow down. Before December\\'s bumper text record, the previous highest monthly total was in October 2004, when 2.3 billion were sent. Text messaging is set to smash more records in 2005 too, said the MDA, with forecasts suggesting a total of 30 billion for the year.  Even though mobiles are becoming increasingly sophisticated with much more multimedia applications, texting is still one of the most useful functions of mobiles. People are using SMS to do much more too. Booking cinema tickets, text voting, and news or sports text alerts are growing popular. Mobile owners have also given the chance to donate to the Disasters Emergency Committee\\'s (DEC) Asian Tsunami fund by texting \"Donate\" to a simple short code number. Looking further ahead in the year, the MDA\\'s chairman Mike Short, has predicted that more people will go online through their mobiles, estimating 15 billion WAP page impressions. Handsets with GPRS capability - an \"always on\" net connection - will rise to 75%, while 3G mobile ownership growing to five million by the end of 2005. These third generation mobiles offer a high-speed connection which means more data like video can be received on the phone. Globally, mobile phone sales passed 167 million in the third quarter of 2004, according to a recent report from analysts Gartner. That was 26% more than the previous year. It is predicted that there would be two billion handsets in use worldwide by the end of 2005.']\n",
            "Summarized Text 50: ['2.4 billion texts were sent in December alone, the highest monthly total ever. Every day 78 million messages are sent and there are no signs of a slow down. Globally, mobile phone sales passed 167 million in the third quarter of 2004. It is predicted that there would be two billion handsets in use by the end of 2005.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 50/112 [01:11<01:27,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 51: ['Godzilla gets Hollywood fame star  Movie monster Godzilla has received a star on Hollywood\\'s Walk of Fame, honouring both his 50th birthday and the launch of his 28th film.  An actor dressed as the giant creature breathed smoke over photographers on Monday as Godzilla received the 2,271st star on Hollywood Boulevard. \"Godzilla should thank you for this historical and monumental star,\" said Final Wars producer Shogo Tomiyama. \"But unfortunately, he cannot speak English,\" he added. Hollywood\\'s honorary mayor, Johnny Grant, said: \"I do hereby proclaim this Godzilla Day in Hollywood.  \"He\\'s loose, he\\'s wild, and I\\'m getting the hell out of here,\" he added. The premiere of Godzilla: Final Wars at Grauman\\'s Chinese Theatre followed the ceremony on Hollywood Boulevard. The monster was joined by co-stars including Japanese pop star and actor Masahiro Matsuoka. Director Ryuhei Kitamura said it may not be Godzilla\\'s final outing, as it has been billed. \"That\\'s what the producers say. But the producer\\'s a liar,\" he said. \"[Godzilla\\'s] been working for the last 50 years. So, I think Godzilla just deserves a vacation.\" And producer Shogo Tomiyama added: \"So long as Godzilla can fascinate people, I believe he will be resurrected by new generations of filmmakers in the future.\" Godzilla first appeared in 1954 as a prehistoric lizard woken by atomic bomb tests.']\n",
            "Summarized Text 51: ['Godzilla received the 2,271st star on Hollywood Boulevard on Monday. Hollywood\\'s honorary mayor, Johnny Grant, said: \"He\\'s loose, he\\'s wild, and I\\'m getting the hell out of here\" The premiere of Godzilla: Final Wars at Grauman\\'s Chinese Theatre followed.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 51/112 [01:12<01:21,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 52: ['Christmas sales worst since 1981  UK retail sales fell in December, failing to meet expectations and making it by some counts the worst Christmas since 1981.  Retail sales dropped by 1% on the month in December, after a 0.6% rise in November, the Office for National Statistics (ONS) said. The ONS revised the annual 2004 rate of growth down from the 5.9% estimated in November to 3.2%. A number of retailers have already reported poor figures for December. Clothing retailers and non-specialist stores were the worst hit with only internet retailers showing any significant growth, according to the ONS.  The last time retailers endured a tougher Christmas was 23 years previously, when sales plunged 1.7%.  The ONS echoed an earlier caution from Bank of England governor Mervyn King not to read too much into the poor December figures. Some analysts put a positive gloss on the figures, pointing out that the non-seasonally-adjusted figures showed a performance comparable with 2003. The November-December jump last year was roughly comparable with recent averages, although some way below the serious booms seen in the 1990s. And figures for retail volume outperformed measures of actual spending, an indication that consumers are looking for bargains, and retailers are cutting their prices.  However, reports from some High Street retailers highlight the weakness of the sector. Morrisons, Woolworths, House of Fraser, Marks & Spencer and Big Food all said that the festive period was disappointing.  And a British Retail Consortium survey found that Christmas 2004 was the worst for 10 years. Yet, other retailers - including HMV, Monsoon, Jessops, Body Shop and Tesco - reported that festive sales were well up on last year. Investec chief economist Philip Shaw said he did not expect the poor retail figures to have any immediate effect on interest rates. \"The retail sales figures are very weak, but as Bank of England governor Mervyn King indicated last night, you don\\'t really get an accurate impression of Christmas trading until about Easter,\" said Mr Shaw. \"Our view is the Bank of England will keep its powder dry and wait to see the big picture.\"']\n",
            "Summarized Text 52: ['Retail sales dropped by 1% on the month in December, after a 0.6% rise in November. Clothing retailers and non-specialist stores were the worst hit. The last time retailers endured a tougher Christmas was 23 years previously, when sales plunged 1.7%.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 52/112 [01:13<01:18,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 53: ['\\'No-one can define new hunt ban\\'  The new law banning hunting with dogs is \"so poorly drafted\" no-one can define the offence, pro-hunt MPs say.  The accusation came after it emerged a Devon man had been told he could use his four dogs to \"chase away unwanted animals\" from his farm. Because he did not intend to kill deer or foxes it was not hunting. Lib Dem MP Lembit Opik said ministers had invented a new category of hunting - chasing away - and asked how police were supposed to interpret the rules.  North Devon landowner Giles Bradshaw was put in touch with the Middle Way Group, of which Mr Opik is a co-chairman, after he had been in contact with the rural affairs ministry, Defra. He had asked whether his technique of using his four dogs to frighten off deer and foxes would be outlawed under the Hunting Act. Mr Bradshaw was initially told it was an offence - prompting him to complain. The Middle Way group also said Mr Bradshaw would be put in a position where he would have to buy a rifle to shoot animals that would have previously gone free. In a later conversation Mr Bradshaw was told that according to Defra\\'s lawyers chasing away unwanted animals was \"not in fact hunting as described in the Hunting Act 2004 therefore you would not be committing an offence\".  Mr Opik said: \"Hunting with dogs and flushing are not defined in the Hunting Act. \"Now Defra have also invented a completely new category of hunting - \\'chasing away\\' which isn\\'t even covered by the Act. \"However, all these activities involve the use of dogs to chase wild mammals. \"How is the village bobby who sees a group of people with dogs supposed to distinguish between illegal hunting, exempt hunting, drag hunting, unintentional hunting, a hunt exercising hounds or simply chasing away?\" Tory MP Peter Luff, another co-chairman of Middle Way, said that the legislation was \"so poorly drafted nobody appears able to properly define the offence\".  \"It is no wonder the government desperately wants to move on from this disastrous law. However, I seriously doubt the countryside will be that accommodating.\" Mike Hobday, of the League Against Cruel Sports, said: \"There is no confusion, it is a matter of simple common sense. \"If Mr Bradshaw is setting his dogs to chase wild animals then he is hunting them and that will be a criminal offence. \"If all the dogs are doing is barking at the deer, then nobody can define that as hunting.\"']\n",
            "Summarized Text 53: ['Lib Dem MP Lembit Opik said ministers had invented a new category of hunting. North Devon landowner Giles Bradshaw was told he could use his four dogs to \"chase away unwanted animals\" from his farm. Because he did not intend to kill deer or foxes it was not hunting.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 53/112 [01:14<01:20,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 54: ['Soaring oil \\'hits world economy\\'  The soaring cost of oil has hit global economic growth, although world\\'s major economies should weather the storm of price rises, according to the OECD.  In its latest bi-annual report, the OECD cut its growth predictions for the world\\'s main industrialised regions. US growth would reach 4.4% in 2004, but fall to 3.3% next year from a previous estimate of 3.7%, the OECD said. However, the Paris-based economics think tank said it believed the global economy could still regain momentum.  Forecasts for Japanese growth were also scaled back to 4.0% from 4.4% this year and 2.1% from 2.8% in 2005. But the outlook was worst for the 12-member eurozone bloc, with already sluggish growth forecasts slipping to 1.8% from 2.0% this year and 1.9% from 2.4% in 2005, the OECD said. Overall, the report forecast total growth of 3.6% in 2004 for the 30 member countries of the OECD, slipping to 2.9% next year before recovering to 3.1% in 2006. \"There are nonetheless good reasons to believe that despite recent oil price turbulence the world economy will regain momentum in a not-too-distant future,\" said Jean-Philippe Cotis, the OECD\\'s chief economist. The price of crude is about 50% higher than it was at the start of 2004, but down on the record high of $55.67 set in late October.  A dip in oil prices and improving jobs prospects would improve consumer confidence and spending, the OECD said. \"The oil shock is not enormous by historical standards - we have seen worse in the seventies. If the oil price does not rise any further, then we think the shock can be absorbed within the next few quarters,\" Vincent Koen, a senior economist with the OECD, told the BBC\\'s World Business Report. \"The recovery that was underway, and has been interrupted a bit by the oil shock this year, would then regain momentum in the course of 2005.\" China\\'s booming economy and a \"spectacular comeback\" in Japan - albeit one that has faltered in recent months - would help world economic recovery, the OECD said. \"Supported by strong balance sheets and high profits, the recovery of business investment should continue in North America and start in earnest in Europe,\" it added. However, the report warned: \"It remains to be seen whether continental Europe will play a strong supportive role through a marked upswing of final domestic demand.\" The OECD highlighted current depressed household expenditure in Germany and the eurozone\\'s over-reliance on export-led growth.']\n",
            "Summarized Text 54: [\"OECD cut its growth predictions for the world's main industrialised regions. US growth would reach 4.4% in 2004, but fall to 3.3% next year. Forecasts for Japanese growth were also scaled back to 4.0% this year. The outlook was worst for the 12-member eurozone bloc.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 54/112 [01:16<01:21,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 55: ['Hillbillies singer Scoggins dies  Country and Western musician Jerry Scoggins has died in Los Angeles at the age of 93, his family has said.  Scoggins was best remembered for singing the theme tune to popular US TV show The Beverly Hillbillies. The Texan-born singer approached the producers of the programme with theme tune The Ballad of Jed Clampett for the pilot which was screened in 1962. The show, which told the story of a poor man striking oil and moving to Beverly Hills, ran until 1971.  Scoggins\\' daugher Jane Kelly Misel said that her father never tired of the song and would sing it at least once a day. \"He\\'d sing it at birthdays and anniversaries and variety shows. He never stopped performing it,\" she said. When a film version of The Beverly Hillbillies was made in 1993, Scoggins came out of retirement to perform the theme tune. Scoggins sang the lyrics while bluegrass stars Lester Flatt and Earl Scruggs played guitar and banjo.']\n",
            "Summarized Text 55: ['Jerry Scoggins was best remembered for singing the theme tune to The Beverly Hillbillies. The Texan-born singer approached the producers of the programme with theme tune The Ballad of Jed Clampett for the pilot in 1962. The show, which told the story of a poor man striking oil and moving to Beverly Hills, ran until 1971.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 55/112 [01:17<01:18,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 56: ['Kilroy unveils immigration policy  Ex-chatshow host Robert Kilroy-Silk has attacked UK policy on immigration saying Britain\\'s open door approach is hitting low wage \"indigenous\" workers.  The Veritas leader said the only people to benefit from immigrants from places like Poland were employers, landlords, members of the \\'metropolitan elite\\'. The MEP said his party would only admit foreigners who were required because they had specific skills to offer. And he argued asylum cost Â£2bn a year for 14,000 successful applicants.  Mr Kilroy-Silk said that worked out at Â£143,000 per successful asylum seeker. He said Veritas wanted to grant an amnesty for all those in Britain claiming asylum and who have children and deport everyone else. Britain should take its fair share of asylum seekers under the United Nations Convention on Human Rights, he argued. And Mr Kilroy-Silk said he wanted to spend an extra Â£500m a year to help provide for refugees abroad.']\n",
            "Summarized Text 56: ['Kilroy unveils immigration policy. Ex-chatshow host Robert Kilroy-Silk has attacked UK policy on immigration. He said Britain\\'s open door approach is hitting low wage \"indigenous\" workers. Veritas leader said the only people to benefit from immigrants from places like Poland were employers, landlords, members of the\\'metropolitan elite\\'']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 56/112 [01:19<01:15,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 57: ['Candidate resigns over BNP link  A prospective candidate for the UK Independence Party (UKIP) has resigned after admitting a \"brief attachment\" to the British National Party(BNP).  Nicholas Betts-Green, who had been selected to fight the Suffolk Coastal seat, quit after reports in a newspaper that he attended a BNP meeting. The former teacher confirmed he had attended the meeting but said that was the only contact he had with the group. Mr Betts-Green resigned after being questioned by the party\\'s leadership. A UKIP spokesman said Mr Betts-Green\\'s resignation followed disclosures in the East Anglian Daily Times last month about his attendance at a BNP meeting. \"He did once attend a BNP meeting. He did not like what he saw and heard and will take no further part of it,\" the spokesman added. A meeting of Suffolk Coastal UKIP members is due to be held next week to discuss a replacement. Mr Betts-Green, of Woodbridge, Suffolk, has also resigned as UKIP\\'s branch chairman.']\n",
            "Summarized Text 57: ['Nicholas Betts-Green had been selected to fight the Suffolk Coastal seat. He quit after reports in a newspaper that he attended a BNP meeting. The former teacher confirmed he had attended the meeting but said that was the only contact he had with the group. A meeting of Suffolk Coastal UKIP members is due to be held next week.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 57/112 [01:20<01:12,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 58: ['Asylum children to face returns  The UK government is planning to return asylum seeker children without parents to Albania.  The trial scheme, which could start in weeks, may be extended to apply to children from other countries. Children\\'s charities have reacted with alarm, saying the policy amounts to forcible removal and may not guarantee the safety of those affected. But the Home Office says it may be in the children\\'s best interests if it reunites them with their communities.  The pilot, included in the government\\'s five-year immigration plan, aims to return unaccompanied asylum-seeking children from Albania who have failed in their asylum claims.  Since 2002, at least 9,000 under-18s have arrived in the UK to seek asylum without other family members. These children automatically become the responsibility of social services. Up to now, ministers have held back from final removal orders against unaccompanied children until after they are legally adults at 18. At least a dozen Albanian-born teenagers are thought to have been identified for return, according to sources, although there is no public confirmation of numbers. Those selected could either be returned to their families, should they be traced, or placed in the care of other Albanian authorities. Separate negotiations to establish a family tracing and returns scheme are believed to be underway with another country.  Under the 1989 Children Act, public bodies have a duty to act in the \"best interest\" of a child in their care. Laura Brownlees of Save the Children said there were grave concerns, not least because of the well-documented trafficking of children into crime and prostitution in Albania.  \"If children are going to be returned then there should be proper assessments and decisions on a case by case basis,\" she said. \"We do not think there are structures in place [to receive returning children in Albania]. \\'If these decisions are not in the best interests of the child, then that is a forced removal because the child will not have any choice in the final decision.\" In its five-year immigration plan, announced on Tuesday, the government said it was addressing \"the difficult issue\" of returning unaccompanied asylum seeking children. A spokesman for the Home Office said it was wholly wrong to suggest that the plan was to return children \"and leave them to rot\". \"We are developing a returns programme for unaccompanied asylum-seeking children whose asylum and humanitarian protection claims have been refused,\" said the spokesman. \"We have been exploring how we can establish reception and longer-term care arrangements in countries of origin and believe that it\\'s possible to return children in a way that is in their best interests and is safe and sustainable.  \"We do not believe that it is right, or in keeping with children\\'s legislation, that children who can return should remain in the UK indefinitely separated from their families and communities.\" The spokesman stressed the UK would abide by its international human rights obligations. Only those children who could be provided with a carefully planned reintegration package would be returned, he said. But Andrew Hogg, spokesman for the Medical Foundation for the Care of Victims of Torture, said ministers had so far failed to reassure agencies. \"From what is so far known, we strongly oppose the scheme because the welfare and best interests of the child will not properly be taken into account,\" said Mr Hogg. \"In Albania particularly there is no statutory child care or protection structure. \"The Medical Foundation has many serious concerns, including the assessment process for suitability for return, the degrading of best interests of the child principles and of child welfare, and the lack of safeguards in the chosen countries.\" A spokesman for the Albanian embassy in London said it was the first it had heard of a scheme, but did not rule out that there had been an agreement between the two countries.']\n",
            "Summarized Text 58: [\"Children's charities have reacted with alarm, saying the policy amounts to forcible removal. But the Home Office says it may be in the children's best interests if it reunites them with their communities. At least a dozen Albanian-born teenagers are thought to have been identified for return, according to sources.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 58/112 [01:21<01:16,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 59: ['France Telecom gets Orange boost  Strong growth in subscriptions to mobile phone network Orange has helped boost profits at owner France Telecom.  Orange added more than five million new customers in 2004, leading to a 10% increase in its revenues. Increased take-up of broadband telecoms services also boosted France Telecom\\'s profits, which showed a 5.5% rise to 18.3bn euros ($23.4bn; Â£12.5bn). France Telecom is to spend 578m euros on buying out minority shareholders in data services provider Equant.  France Telecom, one of the world\\'s largest telecoms and internet service providers, saw its full-year sales rise 2.2% to 47.2bn euros in 2004.  Orange enjoyed strong growth outside France and the United Kingdom - its core markets - swelling its subscriber base to 5.4 million. France Telecom\\'s broadband customers also increased, rising to 5.1 million across Europe by the end of the year. The firm said it had met its main strategic objectives of growing its individual businesses and further reducing its large debt. An ill-fated expansion drive in the late 1990s saw France Telecom\\'s debt soar to 72bn euros by 2002. However, this has now been reduced to 43.9bn euros. \"Our results for 2004 allow us to improve our financial structure while focusing on the innovation that drives our strategy,\" said chief executive Thierry Breton.  Looking ahead, the company forecast like-for-like sales growth of between 3% and 5% over the next three years. France Telecom is consolidating its interest in Equant, which provides telecoms and data services to businesses. Subject to approval by shareholders of the two firms, it will buy the shares in Equant it does not already own. France Telecom said it would fund the deal by selling an 8% stake in telephone directory company PagesJaunes.']\n",
            "Summarized Text 59: [\"Orange added more than five million new customers in 2004. Increased take-up of broadband telecoms services also boosted France Telecom's profits. France Telecom is to spend 578m euros on buying out minority shareholders in data services provider Equant. The company forecast like-for-like sales growth of between 3% and 5% over the next three years.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 59/112 [01:23<01:15,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 60: [\"Survey confirms property slowdown  Government figures have confirmed a widely reported slowdown of the UK's housing market in late 2004.  House prices were 11.8% higher on the year in the last quarter of 2004, down from 16.3% in the July-to-September quarter, the Land Registry said. The average house price in England and Wales was Â£182,920, down from Â£187,971 in July-September. The volume of sales between October and December dropped by nearly a quarter from the same period in 2003. The government figures are the first official confirmation of falls in the market at the end of 2004. Land Registry figures are less up to date than those of banks and building societies, since they record completions not mortgage approvals. However, the figures are viewed as the most accurate measure of house prices as they include all property transactions, including cash sales.  The cost of buying a home fell in seven out of 10 regions between the third and fourth quarters of 2004.  The biggest annual gains were made in Wales, where house prices were up by 23% in the fourth quarter. House prices rose the slowest in Greater London, being up by 6%. In the capital, the volume of sales fell by 23% from 36,185 in 2003 to 28,041 for the same period in 2004. There was also a decline in the number of million-pound properties sold in the capital, with 436 properties over Â£1m sold compared to 469 for the same period in 2003. Although the figures point to a slowdown in the market, the most recent surveys from Nationwide and Halifax have indicated the market may be undergoing a revival. After registering falls at the back end of 2004, Halifax said house prices rose by 0.8% in January and Nationwide reported a rise of 0.4% in the first month of the year. Members of the Bank of England's rate-setting committee will make their latest decision on interest rates on Thursday.\"]\n",
            "Summarized Text 60: ['House prices were 11.8% higher on the year in the last quarter of 2004, down from 16.3% in the July-to-September quarter. The volume of sales between October and December dropped by nearly a quarter from the same period in 2003. The cost of buying a home fell in seven out of 10 regions between third and fourth quarters of 2004.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 60/112 [01:24<01:14,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 61: ['Vodafone appoints new Japan boss  Vodafone has drafted in its UK chief executive William Morrow to take charge of its troubled Japanese operation.  Mr Morrow will succeed Shiro Tsuda as president of Vodafone KK, Japan\\'s number three mobile operator, in April. Mr Tsuda, who will become chairman, was appointed president only two months ago but the business has struggled since then, losing customers in January. Vodafone had pinned its hopes on the launch of its 3G phones in November but demand for them has been slow.  While it has more than 15 million customers in Japan, Vodafone has found it difficult to satisfy Japan\\'s technologically demanding mobile users. It suffered a net loss of more than 58,000 customers in January, its second monthly reverse in the last year. \"Vodafone is going to need to put a lot of money into Japan if it wants to rebuild the business,\" Tetsuro Tsusaka, a telecoms analyst with Deutsche Bank, told Reuters. \"I do not know if it will be worth it for them to spend that kind of money just for Japan.\"']\n",
            "Summarized Text 61: [\"William Morrow will succeed Shiro Tsuda as president of Vodafone KK in April. Mr Tsuda, who will become chairman, was appointed president only two months ago. The business has struggled since then, losing customers in January. It has found it difficult to satisfy Japan's technologically demanding mobile users.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 61/112 [01:26<01:09,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 62: ['UK\\'s National Gallery in the pink  The National Gallery, home to some of the UK\\'s greatest artworks, has seen a big jump in visitor numbers.  Five million visitors made the London gallery - which houses treasures like Raphael\\'s Madonna of the Pinks - the UK\\'s most visited museum in 2004. It recorded a 13.8% rise in numbers and was the country\\'s second most visited tourist attraction, behind Blackpool Pleasure Beach. Charles Saumarez Smith, the gallery\\'s director, said he was \"delighted\". He said the number of visitors through the doors had boosted figures to pre-11 September 2001 levels. Mr Saumarez Smith added that the pedestrianisation of Trafalgar Square, where the gallery is located, and strong temporary collections throughout 2004 had led to the strong performance.  \"Our 2004 exhibition programme of El Greco, Russian Landscape in the Age of Tolstoy and Raphael: From Urbino to Rome was particularly strong and exceeded all targets,\" he said. \"The exceptional quality of the paintings in our permanent collection is also huge draw for the public. \"The expectations of today\\'s visitors are higher than ever and we have kept pace with their demands.\" Mr Saumarez Smith said he was confident the gallery could maintain the attendance. \"With important exhibitions of the work of Caravaggio, Stubbs and Rubens in place for 2005, I am confident that the gallery is set for another highly successful year,\" he added. The figures were prepared by the Association of Leading Visitor Attractions (Alva).  It found that the figures had been boosted by an increase in Europeans travelling to the UK on budget airlines. Popular cultural tourist spots such as the Tate Modern and the Natural History Museum all recorded increases of more than 10% in visitor numbers compared with 2003. But for legal or confidentiality reasons some Alva members did not submit figures for 2004, including Buckingham Palace, Windsor Castle, Madame Tussauds and Alton Towers. Alva director Robin Broke said: \"Visits from Western Europe were up by 10% and from North America by some 9% compared to 2003, while numbers from the rest of the world rose 20%. \"European figures were helped by the rapid growth of low-cost flights to Britain from Europe, especially from new EU countries.\"']\n",
            "Summarized Text 62: [\"Five million visitors made the London gallery the UK's most visited museum in 2004. It recorded a 13.8% rise in numbers and was the country's second most visited tourist attraction, behind Blackpool Pleasure Beach. Figures boosted by an increase in Europeans travelling to the UK on budget airlines.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 62/112 [01:27<01:08,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 63: ['Versace art portfolio up for sale  The art collection of murdered fashion designer Gianni Versace could fetch up to Â£9m ($17m) when it is auctioned in New York and London later this year.  Among the pictures for sale are works by Roy Lichtenstein, Andy Warhol and Henri Matisse. The collection was housed at Versace\\'s six-storey New York townhouse. The 51-year-old designer was shot outside his Florida home in 1997 by suspected serial killer Andrew Cunanan, who later killed himself. The auction, at Sotheby\\'s, will feature 45 contemporary, impressionist and 19th Century paintings. One of the highlights of the sale is Roy Lichtenstein\\'s Blue Nude which has been given an estimate of Â£1.8m ($3.4m).  Tobias Meyer, Sotheby\\'s worldwide head of contemporary art, said: \"This collection reflects Mr Versace\\'s wide-ranging taste and impeccable eye, and many of the works were commissioned directly from the artists. \"Outstanding later examples from champions of the Pop movement, such as Roy Lichtenstein, are juxtaposed with masterpieces from the most visible artists of the 1980\\'s, including Jean-Michel Basquiat and the collaborative genius of Basquiat and Warhol, as well as Francesco Clemente.\" Much of the collection will be offered for sale at three auctions in New York in June, with smaller contemporary paintings going under the hammer in London on 22 and 23 June. A sale of Versace\\'s furniture and artworks sold in 2001fetched Â£5.5m ($10.3m).']\n",
            "Summarized Text 63: [\"Gianni Versace was shot dead outside his Florida home in 1997. His art collection will be auctioned in New York and London later this year. Among the pictures for sale are works by Roy Lichtenstein, Andy Warhol and Henri Matisse. The auction, at Sotheby's, will feature 45 contemporary, impressionist and 19th Century paintings.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 63/112 [01:28<01:07,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 64: ['G7 backs Africa debt relief plan  G7 finance ministers have backed plans to write off up to 100% of the debts of some of the world\\'s poorest countries.  UK chancellor Gordon Brown said the London meeting of the world\\'s seven richest nations would be remembered as \"the 100% debt relief summit\". Some 37 countries could benefit after a case-by-case review by bodies including the World Bank and the IMF, he said. But the US says it cannot support Mr Brown\\'s International Finance Facility to boost aid to developing countries. BBC correspondents said the meeting had produced some movement towards the UK\\'s ambitions, but much work was needed. Mr Brown said it was a major breakthrough for the international organisations to offer up to 100% multilateral debt relief - \"the vast bulk\" of money owed by the poorest countries.  \"We could be at the beginning of the final stage of the process where the debts that were owed by the poorest countries, built up over 20 or 30 years, debts that are simply unpayable in the real world, are finally taken care of,\" he said. He added: \"It is the richest countries hearing the voices of the poor.\" But he said they would insist on government reforms and the need for transparency, tackling corruption and openness from both the poorest and richest nations. BBC correspondent Patrick Bartlett said while it was an agreement in principle, the organisations involved now have to look at how it would work in practice. Oxfam senior policy adviser Max Lawson welcomed the statement and said G7 ministers had \"passed the first hurdle of 2005\".  But he added: \"They need to move quickly to turn their proposals into real change for the world\\'s poorest. \"Two million children will die needlessly between now and the next meeting in April. If rich countries are going to keep their promises to tackle obscene poverty they need deliver - and deliver quickly.\" Talks are continuing on how to finance increased overseas development assistance. The International Monetary Fund (IMF) is to look at a proposal to use its gold supplies to help the debt relief effort when it meets in April. Mr Brown said G7 ministers had agreed to defer debt interest payments and repayments for some countries affected by the tsunami until the end of 2005. But UK plans for an International Finance Facility (IFF) to help deal with debt in the developing world have not been agreed. Mr Brown wanted to provide $10bn (Â£5.38bn) a year over a decade, using G7 backing so the money could be borrowed up front on financial markets.  It is a key element of his proposals for a modern version of the Marshall Plan, which brought US aid to rebuild Europe after World War II, for the developing world. Mr Brown said it was \"winning support every day\" and said a programme had been agreed to draw up more details in time for the G8 summit in July. But US Treasury Under-Secretary John Taylor said the US could not support the IFF because of its \"legislative process\". \"The US is completely committed to poverty reduction and providing financing to do that,\" he said. \"But this particular mechanism does not work for the United States. It works for other countries, and that is fine.\" Earlier, he told BBC Radio 4\\'s Today programme the US had increased support for Africa in the past four years from $1.1bn per year to $4.6bn per year. But South Africa Finance Minister Trevor Manuel told the BBC\\'s Talking Point programme what was needed was one approach, with all wealthy nations on board. He said much of the money pledged by the US had not yet been dispensed.  The UK has made poverty in the poorest nations a key theme for its 2005 presidency of the Group of Eight (G8), which comprises the G7 and Russia. The G8 countries will meet at Gleneagles in Scotland. At a dinner on Friday night, former South African president Nelson Mandela backed Mr Brown\\'s plan when he urged the finance chiefs to write-off African debt and provide an extra $50bn (Â£26.69bn) a year in aid for the next decade. Talks also centred on the impact of the rising economies of China and India, the US budget and trade deficits, how the US, Europe and Japan can act to boost global economic growth, and HIV/Aids. G7 ministers called for more flexibility in international exchange rates and said \"excess volatility\" would impede economic growth. Representatives from China, India, Russia, South Africa and Brazil were invited to attend some of the sessions. A G8 summit is set to take place in July.']\n",
            "Summarized Text 64: [\"G7 finance ministers back plans to write off up to 100% of the debts of some of the world's poorest countries. Some 37 countries could benefit after a case-by-case review by bodies including the World Bank and the IMF. UK plans for an International Finance Facility to help deal with debt in the developing world have not been agreed.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 64/112 [01:30<01:14,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 65: ['Lennon brands Rangers favourites  Celtic\\'s Neil Lennon admits Rangers could be considered \"slight favourites\" for the Old Firm CIS Cup clash, but insists his side can still win.  Lennon concedes Rangers are in good form at the moment, but they have failed to beat Celtic in their last seven meetings. \"Rangers are on the up and have been on a good run in recent weeks,\" he said. \"But it\\'s a game we believe we\\'re capable of winning if we play our best,\" he told the Evening Times. \"All the boys are looking forward to it because they are brilliant games to be involved in. \"Without playing at the top of our game, we have still been winning matches. \"At the minute, we are at the top of the league and still in with a chance of staying in Europe, so I don\\'t think it is the crisis people have been trying to make out. \"Of course, it is a concern when you are losing goals, because we have been notorious for being a team that is hard to beat and keeping clean sheets, but hopefully we are over that wee run. \"Considering we lost Henrik Larsson at the end of last season, we have still been scoring a lot of goals, which is pleasing.\"']\n",
            "Summarized Text 65: ['Celtic host Rangers in the Old Firm CIS Cup on Tuesday night. Neil Lennon admits Rangers could be considered \"slight favourites\" but insists his side can still win. Rangers have failed to beat Celtic in their last seven meetings, but Lennon insists they are on the up.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 65/112 [01:31<01:07,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 66: ['Elvis fans hold birthday bash  Elvis fans around the world have been marking the legendary singer\\'s 70th birthday on Saturday.  A three-day Elvis convention took place in Blackpool, England, over the weekend with the aim of finding the best European Elvis impersonator. His Graceland, Tennessee, home was the focus for US celebrations with four days of events including a concert by the Memphis Symphony Orchestra. Elvis\\' single Jailhouse Rock became the UK\\'s number one on Sunday. Fans in France celebrated with a tribute concert by Elvis cover bands and a special exhibition of memorabilia is on display in Bonn, Germany.  Jailhouse Rock is now the 999th number one single in UK pop history. Record company SonyBMG are releasing Elvis\\' 18 number one singles at the rate of one a week in Britain, complete with original artwork and a collector\\'s box. Hit single One Night will follow next week - with the chance of becoming the 1,000th number one as interest surrounding Elvis\\' birthday grows. HMV spokesman Gennaro Castaldo said: \"It would be a fantastic and truly fitting way to celebrate Elvis\\' landmark birthday.\"']\n",
            "Summarized Text 66: [\"Elvis fans around the world have been marking the legendary singer's 70th birthday. A three-day Elvis convention took place in Blackpool, England, over the weekend. Graceland, Tennessee, was the focus for US celebrations with four days of events. Elvis' single Jailhouse Rock became the UK's number one on Sunday.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 66/112 [01:33<01:03,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 67: ['US consumer confidence up  Consumers\\' confidence in the state of the US economy is at its highest for five months and they are optimistic about 2005, an influential survey says.  The feel-good factor among US consumers rose in December for the first time since July according to new data. The Conference Board survey of 5,000 households pointed to renewed optimism about job creation and economic growth. US retailers have reported strong sales over the past 10 days after a slow start to the crucial festive season.  According to figures also released on Tuesday, sales in shopping malls in the week to 25 December were 4.3% higher than in 2003 following a last minute rush. Wal-Mart, the largest US retailer, has said its December sales are expected to be better than previously forecast because of strong post-Christmas sales.  It is expecting annual sales growth of between 1% and 3% for the month. Consumer confidence figures are considered a key economic indicator because consumer spending accounts for about two thirds of all economic activity in the United States. \"The continuing economic expansion, combined with job growth, has consumers ending this year on a high note,\" said Lynn Franco, director of the Conference Board\\'s consumer research centre. \"And consumers\\' outlook suggests that the economy will continue to expand in the first half of next year.\" The overall US economy has performed strongly in recent months, prompting the Federal Reserve to increase interest rates five times since June.']\n",
            "Summarized Text 67: ['US retailers have reported strong sales over the past 10 days after a slow start to the crucial festive season. Wal-Mart, the largest US retailer, has said its December sales are expected to be better than previously forecast. Consumer confidence figures are considered a key economic indicator because consumer spending accounts for about two thirds of all economic activity.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 67/112 [01:34<01:00,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 68: [\"Ukraine steel sell-off 'illegal'  The controversial sell-off of a Ukrainian steel mill to a relative of the former president was illegal, a court has ruled.  The mill, Krivorizhstal, was sold in June 2004 for $800m (Â£424m) - well below other offers. President Viktor Yushchenko, elected in December, is planning to revisit many of Ukraine's recent privatisations. Krivorizhstal is one of dozens of firms which he says were sold cheaply to friends of the previous administration.  On Wednesday, Prime Minister Yulia Tymoshenko said as many as 3,000 firms could be included on the list of firms whose sale was being reviewed.  Mr Yushchenko had previously said the list would be limited to 30-40 enterprises. More than 90,000 businesses in all, from massive corporations to tiny shopfronts, have been sold off since 1992, as the command economy built up when Ukraine was part of the Soviet Union was dismantled. Analysts have suggested that the government needs to avoid the impression of an open-ended list, so as to preserve investor confidence.  Thursday's ruling by a district court in Perchesk overturned a previous decision in a lower court permitting the sale. The consortium which won the auction for the mill was created by Viktor Pinchuk, son-in-law of former-President Leonid Kuchma, and Rinat Akhmetov, the country's richest man. The next step is for the supreme court to annul the sale altogether, opening the way for Krivorizhstal to be resold. Mr Yushchenko has suggested a fair valuation could be as much as $3bn. One of the foreign bidders who lost out, steel giant LNM, told BBC News that it would be interested in any renewed sale.\"]\n",
            "Summarized Text 68: [\"Krivorizhstal was sold in June 2004 for $800m (Â£424m) - well below other offers. President Viktor Yushchenko is planning to revisit many of Ukraine's recent privatisations. He says dozens of firms were sold cheaply to friends of the previous administration.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 68/112 [01:35<00:58,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 69: ['Tutu\\'s Guantanamo release call  Archbishop Desmond Tutu has called for the release of the remaining inmates at Guantanamo Bay and terror suspects detained without trial in the UK.  His comments follow news that all four Britons held by the US in the Cuban camp will be freed within weeks. The South African archbishop said detentions without trial were \"unacceptable\" and \"distressing\". Twelve foreign nationals are being held indefinitely without trial in the UK under anti-terror laws. Referring to the detentions in Cuba, Archbishop Tutu told BBC News: \"It is utterly unacceptable. \"The rule of law is in order to ensure that those who have power don\\'t use their power arbitrarily and every person retains their human rights until you have proven conclusively that so-and-so is in fact guilty.\"  Moazzam Begg, from Birmingham, and Martin Mubanga, Richard Belmar and Feroz Abbasi, from London, have been held by the US at Guantanamo Bay for almost three years. On Tuesday Foreign Secretary Jack Straw told the Commons that the US had agreed to release the four after \"intensive and complex discussions\" over security. The Britons were detained as part of the US-led \"war on terror\". The archbishop added: \"Whilst we are saying thank you that these have been released, what is happening to those left behind? \"We in South Africa used to have a dispensation that detained people without trial and the world quite rightly condemned that as unacceptable.  \"Now if it was unacceptable then how come it can be acceptable to Britain and the United States. It is so, so deeply distressing.\" Following Mr Straw\\'s announcement, lawyer Louise Christian, who represents Mr Abbasi and Mr Mubanga, said the government should have acted sooner. Foreign nationals detained in the UK are being held at Belmarsh and Woodhill prisons. In December the House of Lords, the UK\\'s highest court, ruled that the anti-terror measures broke human rights laws. But the men are still behind bars.  Archbishop Tutu criticised the measures, saying: \"I am opposed to any arbitrary detention that is happening, even in Britain.\" Shami Chakrabarti, director of civil rights group Liberty, has called on the government to \"practise what it preaches\" and either free or charge the detained men. But the Home Office defended the measures. A spokesman said: \"These individuals cannot currently be prosecuted because some evidence, such as that provided by third parties, cannot safely be disclosed in criminal proceedings without putting others at risk. \"It is also currently the case that intelligence gained from covert intercepts cannot be used in a court of law.\"']\n",
            "Summarized Text 69: ['Archbishop Desmond Tutu says detentions without trial are \"unacceptable\" 12 foreign nationals are being held indefinitely without trial in the UK under anti-terror laws. All four Britons held by the US in the Cuban camp will be freed within weeks. In December the House of Lords, the UK\\'s highest court, ruled that the anti- terror measures broke human rights laws.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 69/112 [01:37<01:00,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 70: ['Fit-again Betsen in France squad  France have brought flanker Serge Betsen back into their squad to face England at Twickenham on Sunday.  But the player, who missed the victory over Scotland through injury, must attend a disciplinary hearing on Wednesday after being cited by Wasps. \"Serge has a good case so we are confident he will play,\" said France coach Bernard Laporte. The inexperienced Nicolas Mas, Jimmy Marlu and Jean-Philippe Grandclaude are also included in a 22-man squad. The trio have been called up after Pieter de Villiers, Ludovic Valbon and Aurelien Rougerie all picked up injuries in France\\'s 16-9 win on Saturday.  Laporte said he was confident that Betsen would be cleared by the panel investigating his alleged trip that broke Wasps centre Stuart Abbott\\'s leg. \"If he was to be suspended, we would call up Imanol Harinordoquy or Thomas Lievremont,\" said Laporte, who has dropped Patrick Tabacco. \"We missed Serge badly against Scotland. He has now recovered from his thigh injury and played on Saturday with Biarritz.\" France\\'s regular back-row combination of Betsen, Harinordoquy and Olivier Magne were all missing from France\\'s side at the weekend because of injury. Laporte is expected to announce France\\'s starting line-up on Wednesday.  Forwards: Nicolas Mas, Sylvain Marconnet, Olivier Milloud, William Servat, Sebastien Bruno, Fabien Pelous, Jerome Thion, Gregory Lamboley, Serge Betsen, Julien Bonnaire, Sebastien Chabal, Yannick Nyanga. Backs: Dimitri Yachvili, Pierre Mignoni, Frederic Michalak, Yann Delaigue, Damien Traille, Brian Liebenberg, Jean-Philippe Grandclaude, Christophe Dominici, Jimmy Marlu, Pepito Elhorga.']\n",
            "Summarized Text 70: [\"Betsen missed victory over Scotland through injury. The flanker must attend a disciplinary hearing on Wednesday after being cited by Wasps. The inexperienced Nicolas Mas, Jimmy Marlu and Jean-Philippe Grandclaude are also included in a 22-man squad. Laporte is expected to announce France's starting line-up on Wednesday.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 70/112 [01:38<00:59,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 71: ['Strike threat over pension plans  Millions of public service workers could strike if ministers scrap their final salary pension scheme and make them work longer, warn union leaders.  The Cabinet Office has confirmed it is reviewing the current pension system, prompting unions representing 4.5m workers to threaten united action. They believe the plans include raising the mandatory retirement age for public service workers from 60 to 65. The government says unions will be consulted before any changes are made.  It is thought the proposed overhaul, due on Thursday, could mean pensions could be based on a \"career average\" salary. For each year served, staff currently get one eightieth of their highest salary in the final three years. Ministers will be anxious to avoid mass strike action in the lead-up to the next general election, which is widely expected next May. In a statement on Sunday, the Cabinet Office said it was reviewing the Civil Service Pension Scheme, and hoped to announce proposals soon. \"Unions will of course be consulted about any proposed changes. \"Public sector pension schemes need to remain affordable and sustainable. People are living longer and pensions are getting more expensive. \"To maintain the long-term affordability of our pension scheme, the government announced in its Green Paper on pensions that pension age would rise from 60 to 65.\" On Monday, Tony Blair\\'s official spokesman declined to say whether the prime minister backed the plans. He said: \"What\\'s important is that there\\'s a process going on, it\\'s out for consultation at the moment, let\\'s wait for that process to complete itself.\"  There is already widespread anger over the chancellor\\'s plans to get rid of more than 100,000 civil servants. Now public service unions are united against the plans and the Trades Union Congress is discussing the issue next Monday. Dave Prentis, general secretary of Unison, said changes to pension provisions for workers in the public sector would mean they had to pay in more but would still face a raw deal. \"Members working in the NHS or for local government have never had high pay or city bonuses, but they could look forward to a decent pension - now all that is being taken away,\" he said. \"What really riles me is the breathtaking hypocrisy of MPs who recently voted themselves the best pension scheme in Europe, but say they can\\'t afford it for anyone else. \"This is a position that Unison cannot accept and will oppose. It will lead to conflict between Unison and the government, if not this year then next.\"  Mr Prentis said workers did not want to go on strike and called for talks between unions and the highest level of government. Mark Serwotka, from the Public and Commercial Services union said there should be a co-ordinated one day strike unless there was a government rethink. The Fire Brigades Union said the government was planning to cut ill health retirement benefits for firefighters and other measures to chip away at pensions. Pensions officer Paul Woolstenholmes said: \"The pensions of millions of public sector workers are under threat - apart from MPs and judges who have the most generous pensions arrangements in the country.\"']\n",
            "Summarized Text 71: ['Cabinet Office confirms it is reviewing the current pension system. Unions representing 4.5m workers threaten united action. They believe plans include raising mandatory retirement age from 60 to 65. Ministers will be anxious to avoid mass strike action in lead-up to election.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 71/112 [01:40<00:58,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 72: ['Brown hits back in Blair rift row  Gordon Brown has criticised a union leader who said conflict between himself and Tony Blair was harming the workings of government.  Jonathan Baume, of the top civil servants\\' union, spoke of \"competing agendas\" between Mr Brown and Mr Blair. But the chancellor said Mr Baume was never at meetings between himself and the prime minister so could not judge. He said the union leader was trying to block civil service reform which threatened his members\\' jobs. It suited the purpose of Mr Baume\\'s union, the First Division Association, to suggest there were two agendas battling against each other because the union was trying to resist the planned reforms, Mr Brown told BBC Radio 4\\'s Today programme.  Under the plans, unveiled in the Gershon report, some 84,000 civil servants jobs will be axed or changed and the savings ploughed back into frontline services. Mr Brown said: \"To be honest I don\\'t think you can rely on his [Mr Baume\\'s] judgement on this matter when it comes to the decisions that the government are making. \"Mr Blair and I are making exactly the same decisions on civil service reforms. We are determined to go on with the Gershon reforms.\" He also said that as Mr Baume was never present at meetings between himself and the prime minister, he was not in a position to judge. On Wednesday, ahead of the Chancellor\\'s pre-Budget report, Mr Baume told BBC News there were sometimes \"conflicting and competing agendas for government\" between Number 10 and the Treasury.  What the chancellor wanted was \"not by any means what Alan Milburn and the prime minister want to see\", Mr Baume said. \"Government departments get their money from the Treasury on the basis of public service agreements they sign up to, but at the same time the prime minister also has an agenda and that\\'s not necessarily the same as the Treasury\\'s and the prime minister is of course a very powerful figure in any government. \"He also sends instructions and messages and directions to departments about how he would like each secretary of state and each department to implement a policy agenda. \"The problem is that on many occasions these two don\\'t add up and individual cabinet ministers as well as departments have to make sense of this battle.\" Number 10 said ministers were interested in governing and not a \"soap opera\" about Mr Blair and Mr Brown. Tory shadow chancellor Oliver Letwin said: \"The battle Royal that the top civil servants are now reporting on between the chancellor and Tony Blair is preventing them both from getting on with the business of getting taxpayers value for money.\"']\n",
            "Summarized Text 72: ['Jonathan Baume, of the top civil servants\\' union, spoke of \"competing agendas\" But the chancellor said Mr Baume was never at meetings between himself and the prime minister so could not judge. He said the union leader was trying to block civil service reform which threatened his members\\' jobs.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 72/112 [01:41<00:56,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 73: ['Solutions to net security fears  Fake bank e-mails, or phishing, and stories about ID theft are damaging the potential of using the net for online commerce, say e-business experts.  Trust in online security is falling as a result. Almost 70% of those asked in a poll said that net firms are not doing enough to protect people. The survey of more than 1,000 people reported that 43% were not willing to hand over personal information online. It is worrying for shopaholics and firms who want to exploit the net. More people are becoming aware of online security issues but they have little confidence that companies are doing enough to counter the threats, said security firm RSA, which carried out the poll. An estimated 12 million Britons now use the net as a way of managing their financial affairs. Security experts say that scare stories and the vulnerabilities dogging e-commerce and e-banking are being taken seriously - by banks in particular.  \"I don\\'t think the threat is overplayed,\" Barry Beal, global security manager for Capgemini, told the BBC News website. He added: \"The challenge for banks is to provide the customer with something that improves security but balances that with usability.\" Ensuring extra security measures are in place protects them too, as well as the individual, and it is up to both parties to make sure they do what is necessary to prevent fraud, he said. \"Card issuers will keep us informed of types of attacks and what procedure to take to protect ourselves. If we do that, they will indemnify us,\" he said. Many believe using login details like usernames and passwords are simply not good enough anymore though. One of the biggest challenges to improving security online is how to authenticate an individual\\'s identity. Several security companies have developed methods which complement or replace passwords, which are easily compromised and easy to forget. Last year, a street survey found that more than 70% of people would reveal their password for a bar of chocolate.  On average, people have to remember four different passwords. Some resort to using the same one for all their online accounts. Those who use several passwords often write them down and hide them in a desk or in a document on their computer. In a separate survey by RSA, 80% said they were fed up with passwords and would like a better way to login to work computer systems. For many, the ideal is a single online identity that can be validated once with a series of passwords and questions, or some biometric measurement like a fingerprint or iris scan with a token like a smartcard.  Activcard is just one of the many companies, like RSA Security, which has been trying to come up with just that. RSA has a deal with internet provider AOL that lets people pay monthly for a one-time passcode generation service. Users get a physical token which automatically generates a code which stays active for 60 seconds. Many companies use a token-based method already for employees to access networks securely already. Activcard\\'s method is more complex. It is currently trailing its one-time passcode generation technology with UK banks. Steve Ash, from Activcard, told the BBC News website there are two parts to the process of identification. The most difficult is to ascertain whether an individual is who they say they are when they are online.  \"The end solution is to provide a method where you combine something the user knows with something they have and present those both.\" The method it has developed makes use of the chip embedded in bank cards and a special card reader which can generate unique codes that are active for a specified amount of time. This can be adjusted at any time and can be active for as little as 30 seconds before it changes. It combines that with usual usernames and passwords, as well as other security questions. \"You take the card, put it in the reader, enter your pin number, and a code is given. \"If you wanted then to transfer funds, for instance, you would have to have the code to authorise the transaction.\" The clever bit happens back at the bank\\'s secure servers. The code is validated by the bank\\'s systems, matching the information they expect with the customer\\'s unique key. \"Each individual gets a key which is unique to them. It is a 2048-bit long number that is virtually impossible to crack,\" said Mr Ash. It means that in a typical security attack, explains Mr Ash, even if password information is captured by a scammer using keystroke software or just through spoof websites, they need the passcode. \"By the time they go back [to use the information], the code has expired, so they can\\'t prove who they are,\" according to Mr Ash. In the next few years, Mr Ash predicts that this kind of method will be commonplace before we see biometric authentication that is acceptable for widespread use. \"PCs will have readers built into them, the cost of readers will be very cheap, and more people will have the cards.\" The gadgets we carry around, like personal digital assistants (PDAs) and mobiles, could also have integrated card reader technology in them. \"The PDA or phone method is a possible alternative as people are always carrying phones around,\" he said.']\n",
            "Summarized Text 73: ['Fake bank e-mails, or phishing, are damaging the potential of the net. Almost 70% of those asked in a poll said that net firms are not doing enough to protect people. An estimated 12 million Britons now use the net as a way of managing their financial affairs.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 73/112 [01:43<01:00,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 74: ['Beckham relief as Real go through  David Beckham expressed his relief at Real Madrid\\'s passage to the Champions League knockout phase.  After Real\\'s 3-0 win at Roma, the England skipper admitted another season of under-achievement would not be tolerated at the Bernabeu stadium. Beckham said: \"It\\'s expected of Madrid to get through, but it\\'s a relief for the club and players to have won. \"We lost momentum last season but we cannot afford to to go another season without winning anything.\" Real\\'s finish as runners-up in their Champions League group means they cannot face his old club Manchester United in the next round. But Real could be drawn against other Premiership hopefuls, Arsenal or Chelsea, who won their respective groups. \"It\\'s going to be great whoever we play, even if we don\\'t get either of the two English teams.\"']\n",
            "Summarized Text 74: ['Beckham relief as Real go through  Champions League knockout phase. England skipper admitted another season of under-achievement would not be tolerated at the Bernabeu stadium. Real could be drawn against other Premiership hopefuls, Arsenal or Chelsea, who won their respective groups.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 74/112 [01:44<00:53,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 75: ['Cash gives way to flexible friend  Spending on credit and debit cards has overtaken cash spending in the UK for the first time.  The moment that plastic finally toppled cash happened at 10.38am on Wednesday, according to the Association for Payment Clearing Services (Apacs) Apacs chose school teacher Helen Carroll, from Portsmouth, to make the historic transaction. The switch over took place as she paid for her groceries in the supermarket chain Tesco\\'s Cromwell Road branch.  Mrs Carroll was born in the same year that plastic cards first appeared in the UK. \"I pay for most things with my debit card, with occasional purchases on one of my credit cards,\" said Mrs Carroll, who teaches at Peel Common Infants School in Gosport.  Spending patterns for the year and estimates for December led Apacs to conclude that 10.38am was the time that plastic would finally rule the roost. Shoppers in the UK are expected to put Â£269bn on plastic cards during the whole of 2004, compared with Â£268bn paid with cash, Apacs said. When the first plastic cards appeared in the UK in June 1966, issued by Barclaycard, but only a handful of retailers accepted them and very few customers held them. \"But in less than 40 years, plastic has become our most popular way to pay, due to the added security and flexibility it offers,\" said Apacs spokeswoman Jemma Smith. \"The key driver has been the introduction of debit cards, which now account for two-thirds of plastic card transactions and are used by millions of us every day.\"']\n",
            "Summarized Text 75: ['Spending on credit and debit cards has overtaken cash spending in the UK for the first time. The moment that plastic toppled cash happened at 10.38am on Wednesday, according to the Association for Payment Clearing Services (Apacs) Apacs chose school teacher Helen Carroll, from Portsmouth, to make the historic transaction.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 75/112 [01:45<00:50,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 76: [\"O'Driscoll out of Scotland game  Ireland captain Brian O'Driscoll has been ruled out of Saturday's RBS Six Nations clash against Scotland.  O'Driscoll was originally named in the starting line-up but has failed to recover from the hamstring injury he picked up in the win over Italy. His replacement will be named after training on Friday morning. Fellow centre Gordon D'Arcy is also struggling with a hamstring injury and he will undergo a fitness test on Friday to see if he can play.  Kevin Maggs would be an obvious replacement at centre while Shane Horgan could also be moved from wing. Ulster wing Tommy Bowe could also be asked to travel with the squad to Scotland as a precautionary measure. The only other change to the Ireland side sees Wasps flanker Johnny O'Connor replacing Denis Leamy. O'Connor will be winning his third cap after making his debut in the victory over South Africa last November.  : Murphy, Horgan, TBC, D'Arcy, Hickie, O'Gara, Stringer, Corrigan, Byrne, Hayes, O'Kelly, O'Connell, S Easterby, O'Connor, Foley.  : Sheahan, Horan, O'Callaghan, Miller, G Easterby, Humphreys, Dempsey.\"]\n",
            "Summarized Text 76: [\"Brian O'Driscoll has failed to recover from a hamstring injury he picked up in the win over Italy. His replacement will be named after training on Friday morning. Kevin Maggs would be an obvious replacement at centre while Shane Horgan could also be moved from wing. Johnny O'Connor will be winning his third cap for Ireland.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 76/112 [01:47<00:49,  1.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 77: [\"Man Utd through after Exeter test  Manchester United avoided an FA Cup upset by edging past Exeter City in their third round replay.  Cristiano Ronaldo scored the opener, slipping the ball between Paul Jones' legs after just nine minutes. United wasted a host of chances to make it safe as Jones made some great saves, but Wayne Rooney put the tie beyond doubt late on with a cool finish. Exeter had chances of their own, Sean Devine twice volleying wide and Andrew Taylor forcing Tim Howard to save. United boss Sir Alex Ferguson was taking few chances after their 0-0 draw in the first game and he handed starts to Paul Scholes and Ryan as well as Ronaldo and Rooney. Exeter began brightly with Devine and Steve Flack seeing plenty of the ball, but it did not take United long to assert their authority and the hosts soon found themselves a goal down. Scholes played a lovely pass in to Ronaldo on the left-hand side of the six-yard box and the Portuguese winger slid the ball between the legs of Jones to open the scoring.  United sensed a chance to finish the tie as a contest early on and Ronaldo blazed over before Jones saved well from Scholes and then Rooney. The visitors' pressure by now was incessant and Rooney had another shot blocked while Ronaldo slammed well over the bar again from a good position. Just before the break Giggs had a golden chance to double the advantage, but the Welshman dragged a left-foot effort badly wide from 10 yards. In stoppage time Exeter created their best chance as Alex Jeannin swung in a cross from the left that Devine managed to flick goalwards, but the ball flew wide of Howard's goal. The Grecians came out after the break in determined fashion and Howard had to show safe hands to collect two searching crosses into the United box. Rooney looked like he might have sealed the result with a turn and shot but the ball stuck in the St James Park mud and Jones raced back to gather on the goalline. Moments later Devine had the chance to make himself a hero, but he could only volley Jeannin's brilliant cross wide of Howard's goal after being left unmarked six yards out. After Rooney had completely messed up a free-kick 20 yards out Taylor showed him how it should be done, his stunning drive from distance forcing a flying stop from Howard. The home crowd were baying for a goal and they did get the ball into the net only for Devine's low effort to be ruled out for an obvious offside. The persistent Rooney eventually rounded Jones with three minutes to go and slotted into an empty net to book a home tie with Middlesbrough in the fourth round.  Jones, Hiley, Sawyer, Gaia, Jeannin, Moxey, Taylor (Martin 89), Ampadu (Afful 69), Clay, Flack (Edwards 74), Devine. Subs Not Used: Rice, Todd.  Ampadu, Clay.  Howard, Phil Neville, Gary Neville, O'Shea, Fortune, Giggs (Saha 70), Miller (Fletcher 66), Scholes, Djemba-Djemba (Silvestre 80), Ronaldo, Rooney. Subs Not Used: Ricardo, Bellion.  Ronaldo 9, Rooney 87.  9,033.  P Dowd (Staffordshire).\"]\n",
            "Summarized Text 77: ['Cristiano Ronaldo opened the scoring after just nine minutes. Wayne Rooney put the tie beyond doubt late on with a cool finish. Sean Devine twice volleying wide and Andrew Taylor forcing Tim Howard to save. United wasted a host of chances to make it safe as Jones made some great saves.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 77/112 [01:48<00:49,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 78: ['Casino Royale is next Bond movie  Casino Royale, author Ian Fleming\\'s first James Bond book, is to be the next Bond film, with Goldeneye director Martin Campbell behind the camera.  It will be the 21st James Bond film to hit the big screen, and speculation has been rife over who will play the lead. Casino Royale was turned into a spoof spy movie by John Huston in 1967, with David Niven in the lead role. Pierce Brosnan led the past four Bond films but said producers axed him after offering him the chance to return. Among the favourites to take over the coveted role are Scottish actor Dougray Scott, Oscar nominee Clive Owen and Australian star Hugh Jackman. Producers say no decision has yet been made on who will become the seventh actor, including Niven, to play Bond on film. Kill Bill director Quentin Tarantino had talked of wanting to take on the Casino Royale project, and said he had spoken to Brosnan about it.  Shooting on Casino Royale is expected to begin once Campbell has finished work on The Legend of Zorro, a sequel to The Mask of Zorro, starring Catherine Zeta Jones and Antonio Banderas. Producers Barbara Broccoli and Michael G Wilson expect the film to be released in 2006.  The script will once again be developed by Neal Purvis and Robert Wade who have both worked on two previous Bond movies. Fleming\\'s book saw the introduction of Bond pitted against a Russian spy in a game of baccarat. Simultaneously, a woman arrives on the scene to take his eye off the game. The novel is one of Fleming\\'s most violent and sadistic stories, with 007 suffering a savage beating from his nemesis Le Chiffre. In addition to the 1967 film, it was also adapted for television in 1954 with actor Barry Nelson as an Americanised \"Jimmy\" Bond. MGM Vice Chairman Chris McGurk said: \"Martin (Campbell) is an incredibly exciting film-maker. Goldeneye was a wonderful movie and helped reinvigorate the Bond franchise. We\\'re thrilled to have him back to direct the newest Bond.\" New Zealand-born Campbell moved to the UK in 1966 and directed TV series such as The Professionals, Minder and Bergerac. His film credits include Edge of Darkness, Vertical Limit and Beyond Borders, which starred Angelina Jolie and Clive Owen.']\n",
            "Summarized Text 78: [\"Casino Royale is author Ian Fleming's first James Bond book. It will be the 21st James Bond film to hit the big screen. Goldeneye director Martin Campbell will be behind the camera. The script will be developed by Neal Purvis and Robert Wade. No decision has yet been made on who will play the lead.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 78/112 [01:50<00:48,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "news Text 79: ['Feta cheese battle reaches court  A row over whether only Greece should be allowed to label its cheese feta has reached the European Court of Justice.  The Danish and German governments are challenging a European Commission ruling which said Greece should have sole rights to use the name. The Commission\\'s decision gave the same legal protection to feta as to Italian Parma ham and French Champagne. But critics of the judgement say feta is a generic term, with the cheese produced widely outside Greece.  The Commission\\'s controversial 2002 ruling gave \"protected designation of origin\" status to feta cheese made in Greece, effectively restricting the use of the feta name to producers there.  From 2007 onwards, Greek firms will have the exclusive use of the feta label and producers elsewhere in Europe must find another name to describe their products. The German and Danish governments argue that feta does not relate to a specific geographical area and that their firms have been producing and exporting the cheese for years. \"In our opinion it is a generic designation and we do not have any other name or term for this type of cheese,\" Hans Arne Kristiansen, a spokesman for the Danish Dairy Board, told the BBC. Denmark is Europe\\'s second largest producer of feta after Greece - producing about 30,000 tonnes a year - and exports its products to Greece. It is concerned that the ruling could threaten the production of other cheeses in Denmark such as brie. \"It would cost millions if we wanted to introduce a new designation,\" Mr Kristiansen said. \"That is just one of the costs.\"  The case will also have a major impact on Britain\\'s sole feta producer, Yorkshire company Shepherds Purse Cheeses.  Judy Bell, the company\\'s founder, said it would cost a huge amount to rebrand its product. \"If we lose we will have to go through a massive re-merchandising process and reorganisation,\" she said. \"We have never tried to pull the wool over anyone\\'s eyes - it\\'s very clear from the label that it\\'s Yorkshire feta.\" The original decision was a victory for Greece, where feta cheese is believed to have been produced for about 6,000 years. Feta is a soft white cheese made from sheep or goat\\'s milk, and is an essential ingredient in Greek cuisine. Greece makes 115,000 tonnes, mainly for domestic consumption. The Court is expected to reach a verdict in the case in the autumn.']\n",
            "Summarized Text 79: ['The Danish and German governments are challenging a European Commission ruling. The Commission said Greece should have sole rights to use the name. Critics say feta is a generic term, with the cheese produced widely outside Greece. The Court is expected to reach a verdict in the case in the autumn.']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bed5908306af40509e39ec366c87c2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d7ce3a46b3f423689d75ecd844f2530",
              "IPY_MODEL_0ff98051fabc4003a11c2b412d1de122",
              "IPY_MODEL_5108e6c975214e40b8ad74d14f9d2ceb"
            ],
            "layout": "IPY_MODEL_a3cad6b75863496ab3f6ade4b46ac1aa"
          }
        },
        "6d7ce3a46b3f423689d75ecd844f2530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa92a5d9f258469b8c6c34a745a3b659",
            "placeholder": "​",
            "style": "IPY_MODEL_a896372101a64135aa01d5d9f1f8ba83",
            "value": "vocab.json: 100%"
          }
        },
        "0ff98051fabc4003a11c2b412d1de122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10614a7b6431466faad49b702530d335",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20e2c97a023748dd92d89acdef09e66e",
            "value": 898823
          }
        },
        "5108e6c975214e40b8ad74d14f9d2ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbf5cc97fd174e34988340681f81ea3b",
            "placeholder": "​",
            "style": "IPY_MODEL_749b69f9049e401a8949045a91811074",
            "value": " 899k/899k [00:00&lt;00:00, 3.63MB/s]"
          }
        },
        "a3cad6b75863496ab3f6ade4b46ac1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa92a5d9f258469b8c6c34a745a3b659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a896372101a64135aa01d5d9f1f8ba83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10614a7b6431466faad49b702530d335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e2c97a023748dd92d89acdef09e66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbf5cc97fd174e34988340681f81ea3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "749b69f9049e401a8949045a91811074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09f363234e524cb0af8df25fa4c5d72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd39327be2f04ae4b8d582b5ebb2e79e",
              "IPY_MODEL_34bd2274169f46dfa91c746171e7ad57",
              "IPY_MODEL_5eb59dc464b744818f79951df6e077d3"
            ],
            "layout": "IPY_MODEL_a49002afbb66496fbef9ea24f2a9fdad"
          }
        },
        "bd39327be2f04ae4b8d582b5ebb2e79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d98e4e8ffe044fbb61a4a55dc10aaa1",
            "placeholder": "​",
            "style": "IPY_MODEL_d08d96a69d3f4221aec2daeb3e2a1ae8",
            "value": "merges.txt: 100%"
          }
        },
        "34bd2274169f46dfa91c746171e7ad57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f09972e4c5b4194bcef2128bd786698",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0479125e43604229b88476337c01c5c4",
            "value": 456318
          }
        },
        "5eb59dc464b744818f79951df6e077d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abdc5d6d3c8b4ce99a9135f0cb957d0d",
            "placeholder": "​",
            "style": "IPY_MODEL_289b97abadba46b19fb6edd34f72e4a0",
            "value": " 456k/456k [00:00&lt;00:00, 2.55MB/s]"
          }
        },
        "a49002afbb66496fbef9ea24f2a9fdad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d98e4e8ffe044fbb61a4a55dc10aaa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d08d96a69d3f4221aec2daeb3e2a1ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f09972e4c5b4194bcef2128bd786698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0479125e43604229b88476337c01c5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abdc5d6d3c8b4ce99a9135f0cb957d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289b97abadba46b19fb6edd34f72e4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80d5ee30893142f38ad7b4c6e7ae9775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_612a6dc7fbf84165b6d22048ee686f8e",
              "IPY_MODEL_3e56d5a481554d5aa17b426c49970799",
              "IPY_MODEL_9c8ecc5fd7a14952b29ff186d49818fb"
            ],
            "layout": "IPY_MODEL_ee5ff25d870e4cc3a69ca1b8de5a59c3"
          }
        },
        "612a6dc7fbf84165b6d22048ee686f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_231fb27d26a840eca0cbb0d1e662ff2b",
            "placeholder": "​",
            "style": "IPY_MODEL_9f3297aab7534b6188244f52538f0527",
            "value": "tokenizer.json: 100%"
          }
        },
        "3e56d5a481554d5aa17b426c49970799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e463d2dd024dadb2b180e1500a1290",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d925aa33f7b6424cb9f02c5956a7a2e6",
            "value": 1355863
          }
        },
        "9c8ecc5fd7a14952b29ff186d49818fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_120e4eae01934212adacb53e38cf953d",
            "placeholder": "​",
            "style": "IPY_MODEL_1158a7d60ed340daa2b11186f5c8bc5d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 19.5MB/s]"
          }
        },
        "ee5ff25d870e4cc3a69ca1b8de5a59c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "231fb27d26a840eca0cbb0d1e662ff2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3297aab7534b6188244f52538f0527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8e463d2dd024dadb2b180e1500a1290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d925aa33f7b6424cb9f02c5956a7a2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "120e4eae01934212adacb53e38cf953d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1158a7d60ed340daa2b11186f5c8bc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c8648d3f41b4a178a6480161eecffac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_001b97f5adda4f7c837705ef128155b0",
              "IPY_MODEL_004a24186f2544bc944f9a4d6d86f273",
              "IPY_MODEL_13a2c0c13ecf42e9b30f7f501f3f2571"
            ],
            "layout": "IPY_MODEL_0491884ec12b4961b87c1a59cea58ccb"
          }
        },
        "001b97f5adda4f7c837705ef128155b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b61342a33c68409baba11777182d8e34",
            "placeholder": "​",
            "style": "IPY_MODEL_6800c12bd4344823ac693c1c51e1e3af",
            "value": "config.json: 100%"
          }
        },
        "004a24186f2544bc944f9a4d6d86f273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce3d62fa44ef4fa089cd0058fc13c9af",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dad7d22251e24a42a3d80ce58ae45f43",
            "value": 1585
          }
        },
        "13a2c0c13ecf42e9b30f7f501f3f2571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cecc6897e344f5e9d6db6050bf21024",
            "placeholder": "​",
            "style": "IPY_MODEL_1baf39dc539c4952a90912a4ab15a3e9",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 149kB/s]"
          }
        },
        "0491884ec12b4961b87c1a59cea58ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b61342a33c68409baba11777182d8e34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6800c12bd4344823ac693c1c51e1e3af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce3d62fa44ef4fa089cd0058fc13c9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad7d22251e24a42a3d80ce58ae45f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cecc6897e344f5e9d6db6050bf21024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1baf39dc539c4952a90912a4ab15a3e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "035ae60252374d7085150739d4737874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b53ec3b79a75496aa0c3ae4ea655f8aa",
              "IPY_MODEL_32d4570dc5bd47dcbb41cbcff1bd8d7a",
              "IPY_MODEL_a3a037c5250a440680b45c79536b2986"
            ],
            "layout": "IPY_MODEL_42ac301f03bf404088957a7553097a48"
          }
        },
        "b53ec3b79a75496aa0c3ae4ea655f8aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5124625edb944eb5a8a0f65243ad7144",
            "placeholder": "​",
            "style": "IPY_MODEL_6ef4b8d6783d4a9ababc8448aafa86e7",
            "value": "model.safetensors: 100%"
          }
        },
        "32d4570dc5bd47dcbb41cbcff1bd8d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f88c823765044c588d2887ae442712d7",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71149297964e45239c65f61196c160ad",
            "value": 1625222120
          }
        },
        "a3a037c5250a440680b45c79536b2986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31da0d3ed9ae4b74a2525c8e7937a924",
            "placeholder": "​",
            "style": "IPY_MODEL_cd4954b587494f8080c868d949955a15",
            "value": " 1.63G/1.63G [00:06&lt;00:00, 244MB/s]"
          }
        },
        "42ac301f03bf404088957a7553097a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5124625edb944eb5a8a0f65243ad7144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef4b8d6783d4a9ababc8448aafa86e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f88c823765044c588d2887ae442712d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71149297964e45239c65f61196c160ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31da0d3ed9ae4b74a2525c8e7937a924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4954b587494f8080c868d949955a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d554bd4c367421b8d01acb6a63d7a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3ea3d838eb842b684e90649ba10f840",
              "IPY_MODEL_94a87508ab9048199907f7a8ab08ba39",
              "IPY_MODEL_6def3522aa5f4ec0a286e484038b7625"
            ],
            "layout": "IPY_MODEL_66c9dcf05c95448ea1c53528c4d230e7"
          }
        },
        "e3ea3d838eb842b684e90649ba10f840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62a2394b2b89437a89a6642d0dad5e45",
            "placeholder": "​",
            "style": "IPY_MODEL_455abd056f264c1f8b325951ed1da922",
            "value": "generation_config.json: 100%"
          }
        },
        "94a87508ab9048199907f7a8ab08ba39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b56c799c22154c5fa70a8b181bb92784",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00ea55c65f5043b3b0df7500dd569242",
            "value": 363
          }
        },
        "6def3522aa5f4ec0a286e484038b7625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eaf6b08b1f14ed6b63979fc139135f4",
            "placeholder": "​",
            "style": "IPY_MODEL_cd3e96f969bf43e097e645696e897dbf",
            "value": " 363/363 [00:00&lt;00:00, 33.3kB/s]"
          }
        },
        "66c9dcf05c95448ea1c53528c4d230e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a2394b2b89437a89a6642d0dad5e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "455abd056f264c1f8b325951ed1da922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b56c799c22154c5fa70a8b181bb92784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00ea55c65f5043b3b0df7500dd569242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0eaf6b08b1f14ed6b63979fc139135f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3e96f969bf43e097e645696e897dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02ef6427c12346caaeb26108fea72a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce934e1fabf74ce6aa7c8e27e56cd9ff",
              "IPY_MODEL_ea1ec34746df45228418875c95a8bd40",
              "IPY_MODEL_d01e02ec1d714db896b769690a27944c"
            ],
            "layout": "IPY_MODEL_91714566a5894db49c9c1831a499e263"
          }
        },
        "ce934e1fabf74ce6aa7c8e27e56cd9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b01013cba11412b9f10e0a1916e0e21",
            "placeholder": "​",
            "style": "IPY_MODEL_d206c204f2e64c479679a4c7a097b515",
            "value": "config.json: 100%"
          }
        },
        "ea1ec34746df45228418875c95a8bd40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84e05229873c45979162a5e71a123617",
            "max": 1154,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd8fa9205e314071aea03e92ac0b7565",
            "value": 1154
          }
        },
        "d01e02ec1d714db896b769690a27944c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e409c1b3ba7f41de982baadd38787b2a",
            "placeholder": "​",
            "style": "IPY_MODEL_b16a1444449b41a693299865b63b1096",
            "value": " 1.15k/1.15k [00:00&lt;00:00, 108kB/s]"
          }
        },
        "91714566a5894db49c9c1831a499e263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b01013cba11412b9f10e0a1916e0e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d206c204f2e64c479679a4c7a097b515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84e05229873c45979162a5e71a123617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd8fa9205e314071aea03e92ac0b7565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e409c1b3ba7f41de982baadd38787b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b16a1444449b41a693299865b63b1096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30326e7ef90548dda1164cd69bf25e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e503661a0a744aeb46a1ad9ae7996b6",
              "IPY_MODEL_47d70bfd3a8c499c906611c4975cb721",
              "IPY_MODEL_6e4a07948bb744c1bcb36d0ce3628c24"
            ],
            "layout": "IPY_MODEL_374e85eefd1241d4aa4821a9e9018af4"
          }
        },
        "9e503661a0a744aeb46a1ad9ae7996b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_518637e08a0448488fcafe5bc2f76870",
            "placeholder": "​",
            "style": "IPY_MODEL_b4f79dba23be455d85d02e87a241f60f",
            "value": "model.safetensors: 100%"
          }
        },
        "47d70bfd3a8c499c906611c4975cb721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0608f1c6f134dc9b7a15a7aa3c6de67",
            "max": 1629437147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_651fd81be92a4b1fb44cbeff70ad6a0c",
            "value": 1629437147
          }
        },
        "6e4a07948bb744c1bcb36d0ce3628c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf67905540c4442db5528512013bddbd",
            "placeholder": "​",
            "style": "IPY_MODEL_7570e0018d5244b79beb6cbbda66bcac",
            "value": " 1.63G/1.63G [00:07&lt;00:00, 256MB/s]"
          }
        },
        "374e85eefd1241d4aa4821a9e9018af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518637e08a0448488fcafe5bc2f76870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f79dba23be455d85d02e87a241f60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0608f1c6f134dc9b7a15a7aa3c6de67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651fd81be92a4b1fb44cbeff70ad6a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf67905540c4442db5528512013bddbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7570e0018d5244b79beb6cbbda66bcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "451fdef93cb34f03aa3cbaa8c3e837d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_496c7244c097421fb7e1aec090ecadf8",
              "IPY_MODEL_981c71dc8ac940ea8abbe00a38867b06",
              "IPY_MODEL_23de10e5256e4b9ab5ed0ffdd66833d1"
            ],
            "layout": "IPY_MODEL_2533e88168a047f4b78eb10435c2ce30"
          }
        },
        "496c7244c097421fb7e1aec090ecadf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca3597ef90114f6ca29462e4e3d681a9",
            "placeholder": "​",
            "style": "IPY_MODEL_b8059b260991433ea7d060b0a47e6698",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "981c71dc8ac940ea8abbe00a38867b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c939ef86a107453bb3a6b020fe708881",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f49b4191735a4aada61bc1ddbfd98857",
            "value": 26
          }
        },
        "23de10e5256e4b9ab5ed0ffdd66833d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a62a0e1ba8e14b7cac4cd30cdfd58d70",
            "placeholder": "​",
            "style": "IPY_MODEL_8d590228478b455998402125d1c7fca0",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.44kB/s]"
          }
        },
        "2533e88168a047f4b78eb10435c2ce30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3597ef90114f6ca29462e4e3d681a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8059b260991433ea7d060b0a47e6698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c939ef86a107453bb3a6b020fe708881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49b4191735a4aada61bc1ddbfd98857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a62a0e1ba8e14b7cac4cd30cdfd58d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d590228478b455998402125d1c7fca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be8b1d56492142aba8789fcf5738a0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41ca3d7279fe491fa1dacedfafa46a5a",
              "IPY_MODEL_2d16c0ea19024b869c1dc81518d2f9f9",
              "IPY_MODEL_ec72de63ed7f4ba9956ebcce77f11bab"
            ],
            "layout": "IPY_MODEL_4b796527db0047c68c619a02fd0b722c"
          }
        },
        "41ca3d7279fe491fa1dacedfafa46a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ccce1e6a344f2f9dce9f749ae87c09",
            "placeholder": "​",
            "style": "IPY_MODEL_c8c0eff9769e451592ffc12320945175",
            "value": "vocab.json: 100%"
          }
        },
        "2d16c0ea19024b869c1dc81518d2f9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51cd2c40b7624fcaaff6bc19abcff282",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2baeaeddac684cb2814a82f3aa72f8d0",
            "value": 898822
          }
        },
        "ec72de63ed7f4ba9956ebcce77f11bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d49d5a8b3a43f59ab59bc3bfc0209a",
            "placeholder": "​",
            "style": "IPY_MODEL_49a2720d01854e349f7367215e87698c",
            "value": " 899k/899k [00:00&lt;00:00, 4.99MB/s]"
          }
        },
        "4b796527db0047c68c619a02fd0b722c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ccce1e6a344f2f9dce9f749ae87c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c0eff9769e451592ffc12320945175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51cd2c40b7624fcaaff6bc19abcff282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2baeaeddac684cb2814a82f3aa72f8d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74d49d5a8b3a43f59ab59bc3bfc0209a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a2720d01854e349f7367215e87698c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42df65d2e6b842709b1eabb5a2438075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9645447f1dd8419db8d98562ac58b474",
              "IPY_MODEL_65a0b5406d9347eab8da89b42ef107ee",
              "IPY_MODEL_e78af2a831574a3982b225bb659fee67"
            ],
            "layout": "IPY_MODEL_adb887efeacd41919240dfb430500064"
          }
        },
        "9645447f1dd8419db8d98562ac58b474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_883cff7b97634e2a89c011d0b5a85a30",
            "placeholder": "​",
            "style": "IPY_MODEL_10b163d77395420d972ad33ae92785ab",
            "value": "merges.txt: 100%"
          }
        },
        "65a0b5406d9347eab8da89b42ef107ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6bb026d0d5748469a643d89ec56309d",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0e3e61fa2074c75a85f366010750d9d",
            "value": 456318
          }
        },
        "e78af2a831574a3982b225bb659fee67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ac1d43e7a964b46b6136cee86deac97",
            "placeholder": "​",
            "style": "IPY_MODEL_4ce94df8274046db942ee5a2e00ee754",
            "value": " 456k/456k [00:00&lt;00:00, 31.2MB/s]"
          }
        },
        "adb887efeacd41919240dfb430500064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883cff7b97634e2a89c011d0b5a85a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b163d77395420d972ad33ae92785ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6bb026d0d5748469a643d89ec56309d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e3e61fa2074c75a85f366010750d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ac1d43e7a964b46b6136cee86deac97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce94df8274046db942ee5a2e00ee754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1829f08568740f397ed397d5000ddde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdffc401ff5145b7824d3fe1971ffb0e",
              "IPY_MODEL_fcd3c2f82f2342d98146dcd8cf178046",
              "IPY_MODEL_a623a59c3f104e9bab2c767b17952527"
            ],
            "layout": "IPY_MODEL_fcb11585d0d94fffae6ada2ad0f40d6a"
          }
        },
        "bdffc401ff5145b7824d3fe1971ffb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e425b1862144ebdb4174281ea2d2eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_3ecd105f1dd549b2aecaba400b7d3030",
            "value": "tokenizer.json: 100%"
          }
        },
        "fcd3c2f82f2342d98146dcd8cf178046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcaa961ea9dc43e380216f089016fdd3",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef404330657a4a39981e9f67bd617567",
            "value": 1355863
          }
        },
        "a623a59c3f104e9bab2c767b17952527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d8f0438e28a4d7ea7a83d3076840c8b",
            "placeholder": "​",
            "style": "IPY_MODEL_3f1e7401b3824a369c1866b20120b7fd",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 7.31MB/s]"
          }
        },
        "fcb11585d0d94fffae6ada2ad0f40d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e425b1862144ebdb4174281ea2d2eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ecd105f1dd549b2aecaba400b7d3030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcaa961ea9dc43e380216f089016fdd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef404330657a4a39981e9f67bd617567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d8f0438e28a4d7ea7a83d3076840c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f1e7401b3824a369c1866b20120b7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}